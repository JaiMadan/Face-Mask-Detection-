{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Classifier (Mask, No Mask, Incorrect Mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics, Classifier and Graphing Packages\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "import seaborn as sns # for confusion matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # to plot image, graph\n",
    "\n",
    "import pickle\n",
    "import time # for computation time assessment\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FEATURES AND LABELS FROM PICKLE\n",
    "\n",
    "# Note: Pickles are mask, no mask, incorrect wear of mask dataset in grayscale\n",
    "# See data pre-processing for more information\n",
    "\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in) # 3D Feature set\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in) # 1D Target set\n",
    "\n",
    "pickle_in = open(\"data.pickle\", \"rb\")\n",
    "data = pickle.load(pickle_in) # 2-D Feature Set, Data matrix will serve as X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Classification Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Samples: 15737\n",
      "# of Without A Mask: 5000\n",
      "# of Incorrectly Worn Mask: 5737\n",
      "# of With A Mask: 5000\n"
     ]
    }
   ],
   "source": [
    "# Dataset class distribution for mask, no mask, incorrect wear of mask\n",
    "\n",
    "print('# of Samples:', len(y))\n",
    "print('# of Without A Mask:', (y == 0).sum())\n",
    "print('# of Incorrectly Worn Mask:', (y == 1).sum())\n",
    "print('# of With A Mask:', (y == 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Numpy to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    P0   P1   P2   P3   P4   P5   P6   P7   P8   P9  ... P4086 P4087 P4088  \\\n",
      "0  205  195  202  136   76   77   56   66   69   59  ...   144    76    52   \n",
      "1   97   97   96   96   93   94   97   94   95   91  ...    54    57    58   \n",
      "2   38   37   29   22   28   30   12   17   22   17  ...    15    10    17   \n",
      "3  248  248  246  249  249  246  244  229  194  193  ...    84    48    48   \n",
      "4  160  147  133  137  142  135  114   98   92   92  ...   111   103   110   \n",
      "\n",
      "  P4089 P4090 P4091 P4092 P4093 P4094 P4095  \n",
      "0    43    42    35    39    43    41    32  \n",
      "1    61    59    66    77    80    83    80  \n",
      "2    28    40    17    19    19    17    19  \n",
      "3    57    40    29    13    15    15    22  \n",
      "4   134   143   144   114   102    65    35  \n",
      "\n",
      "[5 rows x 4096 columns]\n",
      "   Mask_Target\n",
      "0            0\n",
      "1            0\n",
      "2            0\n",
      "3            0\n",
      "4            0\n"
     ]
    }
   ],
   "source": [
    "# Get Column Names\n",
    "cols = []\n",
    "for i in range(0, len(data[0])):\n",
    "    cols.append(\"P\" + str(i))\n",
    "\n",
    "# Convert to Dataframe\n",
    "numpy_data = data\n",
    "X = pd.DataFrame(data=numpy_data, columns=[cols])\n",
    "print(X.head())\n",
    "\n",
    "y = pd.DataFrame(data=y, columns=[\"Mask_Target\"])\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Data Shape: (15737, 4096)\n",
      "Image Data Shape Features: (15737, 4096)\n",
      "Image Data Shape Target: (15737, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape of Feature and Target Sets\n",
    "# There are 15,737 samples\n",
    "# See Data preprocessing for more information\n",
    "\n",
    "print('\\nImage Data Shape:', X.shape) # Feature sets are 64X64 images flatten to a 4096 feature vector\n",
    "print('Image Data Shape Features:', data.shape)\n",
    "print('Image Data Shape Target:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train + Test, random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of our Training data:  12589 \n",
      "Length of our Testing data:  3148\n"
     ]
    }
   ],
   "source": [
    "# Split our data into testing and training.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Print the length and width of our testing data.\n",
    "print('Length of our Training data: ', len(X_train), '\\nLength of our Testing data: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees Classifier\n",
    "Build and Train Decision Trees model, No Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Trees model, No hyperparameter Tuning\n",
    "decision_trees = DecisionTreeClassifier()\n",
    "\n",
    "# Use training data to fit Decision Trees model\n",
    "decision_trees.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict Train Data Labels\n",
    "predictions_set = decision_trees.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict Train Data Labels\n",
    "predictions_set = decision_trees.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"predictions_set1_dt.pickle\", \"wb\")\n",
    "pickle.dump(predictions_set, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics, No Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Score, No Hyperparameter Tuning: 0.8290978398983482')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions_set)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Blues_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score, No Hyperparameter Tuning: {0}'.format(accuracy_score(y_test, predictions_set))\n",
    "plt.title(title,size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Precision: 0.829\n",
      "Decision Trees Recall: 0.829\n",
      "Decision Trees F1 Score: 0.829\n"
     ]
    }
   ],
   "source": [
    "print('Decision Trees Precision: %.3f' % precision_score(y_test, predictions_set, average='micro'))\n",
    "print('Decision Trees Recall: %.3f' % recall_score(y_test, predictions_set, average='micro'))\n",
    "print('Decision Trees F1 Score: %.3f' % f1_score(y_test, predictions_set, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RECALL\n",
    "# CLASS 0: NO MASK\n",
    "# CLASS 1: INCORRECT WEAR OF MASK\n",
    "# CLASS 2: CORRECT WEAR OF MASK\n",
    "\n",
    "print(\"\\nClassification Report\\n\", classification_report(y_test, predictions_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(110.88551900495169, 214.9690909090909, 'X[1944] <= 0.355\\ngini = 0.665\\nsamples = 12589\\nvalue = [3986, 4600, 4003]'),\n",
       " Text(35.994346432190646, 210.02727272727273, 'X[3292] <= 0.41\\ngini = 0.34\\nsamples = 4798\\nvalue = [253, 3822, 723]'),\n",
       " Text(19.19948237810625, 205.08545454545455, 'X[3548] <= 0.68\\ngini = 0.583\\nsamples = 587\\nvalue = [175, 87, 325]'),\n",
       " Text(10.73430101840335, 200.14363636363635, 'X[3744] <= 0.198\\ngini = 0.52\\nsamples = 521\\nvalue = [173, 33, 315]'),\n",
       " Text(4.811245867445069, 195.20181818181817, 'X[2780] <= 0.676\\ngini = 0.237\\nsamples = 159\\nvalue = [14, 7, 138]'),\n",
       " Text(3.7983520006145284, 190.26, 'X[1703] <= 0.218\\ngini = 0.179\\nsamples = 152\\nvalue = [14, 1, 137]'),\n",
       " Text(3.291905067199258, 185.3181818181818, 'X[4000] <= 0.255\\ngini = 0.335\\nsamples = 72\\nvalue = [14, 1, 57]'),\n",
       " Text(2.025787733661082, 180.37636363636364, 'X[3659] <= 0.245\\ngini = 0.228\\nsamples = 62\\nvalue = [7, 1, 54]'),\n",
       " Text(1.012893866830541, 175.43454545454546, 'X[3745] <= 0.192\\ngini = 0.044\\nsamples = 44\\nvalue = [1, 0, 43]'),\n",
       " Text(0.5064469334152705, 170.49272727272728, 'gini = 0.0\\nsamples = 41\\nvalue = [0, 0, 41]'),\n",
       " Text(1.5193408002458115, 170.49272727272728, 'X[3932] <= 0.137\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(1.012893866830541, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(2.025787733661082, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(3.038681600491623, 175.43454545454546, 'X[1187] <= 0.312\\ngini = 0.512\\nsamples = 18\\nvalue = [6, 1, 11]'),\n",
       " Text(2.5322346670763523, 170.49272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(3.5451285339068934, 170.49272727272728, 'X[1840] <= 0.586\\ngini = 0.153\\nsamples = 12\\nvalue = [0, 1, 11]'),\n",
       " Text(3.038681600491623, 165.5509090909091, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11]'),\n",
       " Text(4.051575467322164, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(4.558022400737435, 180.37636363636364, 'X[1176] <= 0.533\\ngini = 0.42\\nsamples = 10\\nvalue = [7, 0, 3]'),\n",
       " Text(4.051575467322164, 175.43454545454546, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(5.0644693341527045, 175.43454545454546, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(4.304798934029799, 185.3181818181818, 'gini = 0.0\\nsamples = 80\\nvalue = [0, 0, 80]'),\n",
       " Text(5.824139734275611, 190.26, 'X[3826] <= 0.051\\ngini = 0.245\\nsamples = 7\\nvalue = [0, 6, 1]'),\n",
       " Text(5.31769280086034, 185.3181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(6.330586667690881, 185.3181818181818, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(16.65735616936163, 195.20181818181817, 'X[1431] <= 0.324\\ngini = 0.563\\nsamples = 362\\nvalue = [159, 26, 177]'),\n",
       " Text(9.828235801590093, 190.26, 'X[1761] <= 0.214\\ngini = 0.492\\nsamples = 243\\nvalue = [146, 4, 93]'),\n",
       " Text(7.343480534521422, 185.3181818181818, 'X[740] <= 0.196\\ngini = 0.071\\nsamples = 27\\nvalue = [1, 0, 26]'),\n",
       " Text(6.837033601106151, 180.37636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(7.849927467936692, 180.37636363636364, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 0, 26]'),\n",
       " Text(12.312991068658764, 185.3181818181818, 'X[2647] <= 0.41\\ngini = 0.453\\nsamples = 216\\nvalue = [145, 4, 67]'),\n",
       " Text(8.862821334767233, 180.37636363636364, 'X[1690] <= 0.408\\ngini = 0.349\\nsamples = 163\\nvalue = [127, 2, 34]'),\n",
       " Text(8.356374401351962, 175.43454545454546, 'X[2415] <= 0.292\\ngini = 0.3\\nsamples = 155\\nvalue = [127, 2, 26]'),\n",
       " Text(6.647116001075425, 170.49272727272728, 'X[1200] <= 0.284\\ngini = 0.375\\nsamples = 12\\nvalue = [3, 0, 9]'),\n",
       " Text(6.140669067660155, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(7.1535629344906955, 165.5509090909091, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(10.065632801628501, 170.49272727272728, 'X[2423] <= 0.867\\ngini = 0.234\\nsamples = 143\\nvalue = [124, 2, 17]'),\n",
       " Text(8.166456801321237, 165.5509090909091, 'X[1185] <= 0.329\\ngini = 0.174\\nsamples = 136\\nvalue = [123, 1, 12]'),\n",
       " Text(6.90033946778306, 160.60909090909092, 'X[1259] <= 0.275\\ngini = 0.5\\nsamples = 26\\nvalue = [16, 1, 9]'),\n",
       " Text(5.887445600952519, 155.66727272727275, 'X[1101] <= 0.131\\ngini = 0.198\\nsamples = 18\\nvalue = [16, 0, 2]'),\n",
       " Text(5.3809986675372485, 150.72545454545457, 'X[1391] <= 0.159\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(4.874551734121979, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(5.887445600952519, 145.78363636363636, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(6.39389253436779, 150.72545454545457, 'gini = 0.0\\nsamples = 15\\nvalue = [15, 0, 0]'),\n",
       " Text(7.913233334613601, 155.66727272727275, 'X[997] <= 0.229\\ngini = 0.219\\nsamples = 8\\nvalue = [0, 1, 7]'),\n",
       " Text(7.406786401198331, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(8.419680268028872, 150.72545454545457, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(9.432574134859413, 160.60909090909092, 'X[1935] <= 0.022\\ngini = 0.053\\nsamples = 110\\nvalue = [107, 0, 3]'),\n",
       " Text(8.926127201444142, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(9.939021068274682, 155.66727272727275, 'X[916] <= 0.014\\ngini = 0.018\\nsamples = 108\\nvalue = [107, 0, 1]'),\n",
       " Text(9.432574134859413, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(10.445468001689953, 150.72545454545457, 'gini = 0.0\\nsamples = 107\\nvalue = [107, 0, 0]'),\n",
       " Text(11.964808801935765, 165.5509090909091, 'X[4074] <= 0.633\\ngini = 0.449\\nsamples = 7\\nvalue = [1, 1, 5]'),\n",
       " Text(11.458361868520495, 160.60909090909092, 'X[3520] <= 0.475\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(10.951914935105224, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(11.964808801935765, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(12.471255735351036, 160.60909090909092, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(9.369268268182504, 175.43454545454546, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(15.763160802550294, 180.37636363636364, 'X[232] <= 0.48\\ngini = 0.496\\nsamples = 53\\nvalue = [18, 2, 33]'),\n",
       " Text(14.497043469012118, 175.43454545454546, 'X[159] <= 0.12\\ngini = 0.268\\nsamples = 33\\nvalue = [3, 2, 28]'),\n",
       " Text(13.484149602181576, 170.49272727272728, 'X[2610] <= 0.229\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(12.977702668766305, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(13.990596535596847, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(15.509937335842658, 170.49272727272728, 'X[395] <= 0.88\\ngini = 0.067\\nsamples = 29\\nvalue = [1, 0, 28]'),\n",
       " Text(15.003490402427389, 165.5509090909091, 'gini = 0.0\\nsamples = 28\\nvalue = [0, 0, 28]'),\n",
       " Text(16.01638426925793, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(17.029278136088468, 175.43454545454546, 'X[110] <= 0.661\\ngini = 0.375\\nsamples = 20\\nvalue = [15, 0, 5]'),\n",
       " Text(16.5228312026732, 170.49272727272728, 'gini = 0.0\\nsamples = 14\\nvalue = [14, 0, 0]'),\n",
       " Text(17.53572506950374, 170.49272727272728, 'X[3189] <= 0.225\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 0, 5]'),\n",
       " Text(17.029278136088468, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(18.04217200291901, 165.5509090909091, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(23.486476537133168, 190.26, 'X[3037] <= 0.533\\ngini = 0.456\\nsamples = 119\\nvalue = [13, 22, 84]'),\n",
       " Text(21.33407707011827, 185.3181818181818, 'X[3424] <= 0.708\\ngini = 0.265\\nsamples = 87\\nvalue = [8, 5, 74]'),\n",
       " Text(20.067959736580093, 180.37636363636364, 'X[1557] <= 0.198\\ngini = 0.178\\nsamples = 81\\nvalue = [8, 0, 73]'),\n",
       " Text(19.05506586974955, 175.43454545454546, 'X[2296] <= 0.624\\ngini = 0.48\\nsamples = 10\\nvalue = [6, 0, 4]'),\n",
       " Text(18.548618936334282, 170.49272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(19.56151280316482, 170.49272727272728, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(21.080853603410635, 175.43454545454546, 'X[1431] <= 0.335\\ngini = 0.055\\nsamples = 71\\nvalue = [2, 0, 69]'),\n",
       " Text(20.574406669995362, 170.49272727272728, 'X[982] <= 0.349\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 0, 5]'),\n",
       " Text(20.067959736580093, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(21.080853603410635, 165.5509090909091, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(21.587300536825904, 170.49272727272728, 'gini = 0.0\\nsamples = 64\\nvalue = [0, 0, 64]'),\n",
       " Text(22.600194403656445, 180.37636363636364, 'X[3851] <= 0.614\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 5, 1]'),\n",
       " Text(22.093747470241173, 175.43454545454546, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(23.106641337071714, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(25.638876004148067, 185.3181818181818, 'X[1959] <= 0.402\\ngini = 0.596\\nsamples = 32\\nvalue = [5, 17, 10]'),\n",
       " Text(24.62598213731753, 180.37636363636364, 'X[2531] <= 0.786\\ngini = 0.111\\nsamples = 17\\nvalue = [0, 16, 1]'),\n",
       " Text(24.119535203902256, 175.43454545454546, 'gini = 0.0\\nsamples = 16\\nvalue = [0, 16, 0]'),\n",
       " Text(25.132429070732798, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(26.651769870978608, 180.37636363636364, 'X[3134] <= 0.284\\ngini = 0.524\\nsamples = 15\\nvalue = [5, 1, 9]'),\n",
       " Text(26.14532293756334, 175.43454545454546, 'X[488] <= 0.355\\ngini = 0.278\\nsamples = 6\\nvalue = [5, 1, 0]'),\n",
       " Text(25.638876004148067, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(26.651769870978608, 170.49272727272728, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(27.15821680439388, 175.43454545454546, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(27.66466373780915, 200.14363636363635, 'X[2021] <= 0.567\\ngini = 0.307\\nsamples = 66\\nvalue = [2, 54, 10]'),\n",
       " Text(26.651769870978608, 195.20181818181817, 'X[3429] <= 0.171\\ngini = 0.101\\nsamples = 57\\nvalue = [1, 54, 2]'),\n",
       " Text(26.14532293756334, 190.26, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(27.15821680439388, 190.26, 'X[1708] <= 0.061\\ngini = 0.036\\nsamples = 55\\nvalue = [1, 54, 0]'),\n",
       " Text(26.651769870978608, 185.3181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(27.66466373780915, 185.3181818181818, 'gini = 0.0\\nsamples = 54\\nvalue = [0, 54, 0]'),\n",
       " Text(28.67755760463969, 195.20181818181817, 'X[3954] <= 0.773\\ngini = 0.198\\nsamples = 9\\nvalue = [1, 0, 8]'),\n",
       " Text(28.17111067122442, 190.26, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(29.18400453805496, 190.26, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(52.789210486275046, 205.08545454545455, 'X[1959] <= 0.453\\ngini = 0.204\\nsamples = 4211\\nvalue = [78, 3735, 398]'),\n",
       " Text(42.550506616519584, 200.14363636363635, 'X[3235] <= 0.473\\ngini = 0.109\\nsamples = 3704\\nvalue = [41, 3492, 171]'),\n",
       " Text(33.36219173873094, 195.20181818181817, 'X[1431] <= 0.349\\ngini = 0.548\\nsamples = 152\\nvalue = [13, 87, 52]'),\n",
       " Text(30.450121871593137, 190.26, 'X[2157] <= 0.402\\ngini = 0.532\\nsamples = 51\\nvalue = [12, 7, 32]'),\n",
       " Text(28.67755760463969, 185.3181818181818, 'X[2348] <= 0.508\\ngini = 0.19\\nsamples = 29\\nvalue = [1, 2, 26]'),\n",
       " Text(28.17111067122442, 180.37636363636364, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 0, 26]'),\n",
       " Text(29.18400453805496, 180.37636363636364, 'X[1781] <= 0.3\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(28.67755760463969, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(29.690451471470233, 175.43454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(32.222686138546585, 185.3181818181818, 'X[2138] <= 0.488\\ngini = 0.624\\nsamples = 22\\nvalue = [11, 5, 6]'),\n",
       " Text(31.209792271716044, 180.37636363636364, 'X[2962] <= 0.657\\ngini = 0.391\\nsamples = 15\\nvalue = [11, 4, 0]'),\n",
       " Text(30.70334533830077, 175.43454545454546, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0]'),\n",
       " Text(31.716239205131313, 175.43454545454546, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(33.23558000537712, 180.37636363636364, 'X[149] <= 0.059\\ngini = 0.245\\nsamples = 7\\nvalue = [0, 1, 6]'),\n",
       " Text(32.729133071961854, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(33.74202693879239, 175.43454545454546, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(36.274261605868745, 190.26, 'X[2069] <= 0.329\\ngini = 0.333\\nsamples = 101\\nvalue = [1, 80, 20]'),\n",
       " Text(34.75492080562294, 185.3181818181818, 'X[1959] <= 0.137\\ngini = 0.466\\nsamples = 27\\nvalue = [0, 10, 17]'),\n",
       " Text(34.24847387220767, 180.37636363636364, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9, 0]'),\n",
       " Text(35.26136773903821, 180.37636363636364, 'X[3408] <= 0.165\\ngini = 0.105\\nsamples = 18\\nvalue = [0, 1, 17]'),\n",
       " Text(34.75492080562294, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(35.767814672453476, 175.43454545454546, 'gini = 0.0\\nsamples = 17\\nvalue = [0, 0, 17]'),\n",
       " Text(37.79360240611456, 185.3181818181818, 'X[2773] <= 0.91\\ngini = 0.103\\nsamples = 74\\nvalue = [1, 70, 3]'),\n",
       " Text(37.28715547269929, 180.37636363636364, 'X[2337] <= 0.206\\ngini = 0.054\\nsamples = 72\\nvalue = [1, 70, 1]'),\n",
       " Text(36.78070853928402, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(37.79360240611456, 175.43454545454546, 'X[1694] <= 0.878\\ngini = 0.028\\nsamples = 71\\nvalue = [0, 70, 1]'),\n",
       " Text(37.28715547269929, 170.49272727272728, 'gini = 0.0\\nsamples = 70\\nvalue = [0, 70, 0]'),\n",
       " Text(38.30004933952983, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(38.30004933952983, 180.37636363636364, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(51.73882149430823, 195.20181818181817, 'X[3422] <= 0.845\\ngini = 0.08\\nsamples = 3552\\nvalue = [28, 3405, 119]'),\n",
       " Text(49.69238516741464, 190.26, 'X[3173] <= 0.914\\ngini = 0.069\\nsamples = 3525\\nvalue = [28, 3400, 97]'),\n",
       " Text(47.118853313873274, 185.3181818181818, 'X[1564] <= 0.324\\ngini = 0.064\\nsamples = 3514\\nvalue = [28, 3399, 87]'),\n",
       " Text(43.49113040703635, 180.37636363636364, 'X[3104] <= 0.586\\ngini = 0.297\\nsamples = 374\\nvalue = [21, 310, 43]'),\n",
       " Text(41.08550747331382, 175.43454545454546, 'X[3354] <= 0.661\\ngini = 0.659\\nsamples = 60\\nvalue = [17, 19, 24]'),\n",
       " Text(39.31294320636037, 170.49272727272728, 'X[3108] <= 0.441\\ngini = 0.497\\nsamples = 38\\nvalue = [14, 1, 23]'),\n",
       " Text(38.30004933952983, 165.5509090909091, 'X[1468] <= 0.894\\ngini = 0.153\\nsamples = 12\\nvalue = [11, 0, 1]'),\n",
       " Text(37.79360240611456, 160.60909090909092, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0]'),\n",
       " Text(38.8064962729451, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(40.32583707319091, 165.5509090909091, 'X[1371] <= 0.124\\ngini = 0.269\\nsamples = 26\\nvalue = [3, 1, 22]'),\n",
       " Text(39.81939013977564, 160.60909090909092, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(40.83228400660618, 160.60909090909092, 'X[539] <= 0.133\\ngini = 0.083\\nsamples = 23\\nvalue = [0, 1, 22]'),\n",
       " Text(40.32583707319091, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(41.33873094002145, 155.66727272727275, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 0, 22]'),\n",
       " Text(42.85807174026726, 170.49272727272728, 'X[1568] <= 0.616\\ngini = 0.31\\nsamples = 22\\nvalue = [3, 18, 1]'),\n",
       " Text(42.351624806851994, 165.5509090909091, 'X[3898] <= 0.084\\ngini = 0.1\\nsamples = 19\\nvalue = [0, 18, 1]'),\n",
       " Text(41.845177873436725, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(42.85807174026726, 160.60909090909092, 'gini = 0.0\\nsamples = 18\\nvalue = [0, 18, 0]'),\n",
       " Text(43.36451867368253, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(45.896753340758885, 175.43454545454546, 'X[2593] <= 0.79\\ngini = 0.137\\nsamples = 314\\nvalue = [4, 291, 19]'),\n",
       " Text(44.88385947392835, 170.49272727272728, 'X[1273] <= 0.006\\ngini = 0.073\\nsamples = 292\\nvalue = [4, 281, 7]'),\n",
       " Text(44.37741254051308, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(45.390306407343616, 165.5509090909091, 'X[1949] <= 0.81\\ngini = 0.061\\nsamples = 290\\nvalue = [4, 281, 5]'),\n",
       " Text(44.88385947392835, 160.60909090909092, 'X[3300] <= 0.818\\ngini = 0.048\\nsamples = 288\\nvalue = [4, 281, 3]'),\n",
       " Text(44.37741254051308, 155.66727272727275, 'X[3165] <= 0.908\\ngini = 0.041\\nsamples = 287\\nvalue = [4, 281, 2]'),\n",
       " Text(43.8709656070978, 150.72545454545457, 'X[2626] <= 0.006\\ngini = 0.035\\nsamples = 286\\nvalue = [3, 281, 2]'),\n",
       " Text(43.36451867368253, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(44.37741254051308, 145.78363636363636, 'X[2542] <= 0.029\\ngini = 0.028\\nsamples = 285\\nvalue = [2, 281, 2]'),\n",
       " Text(43.8709656070978, 140.84181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(44.88385947392835, 140.84181818181818, 'X[1309] <= 0.939\\ngini = 0.021\\nsamples = 284\\nvalue = [1, 281, 2]'),\n",
       " Text(44.37741254051308, 135.9, 'X[2388] <= 0.098\\ngini = 0.014\\nsamples = 283\\nvalue = [0, 281, 2]'),\n",
       " Text(43.36451867368253, 130.95818181818183, 'X[1809] <= 0.086\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(42.85807174026726, 126.01636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(43.8709656070978, 126.01636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(45.390306407343616, 130.95818181818183, 'X[3207] <= 0.006\\ngini = 0.007\\nsamples = 281\\nvalue = [0, 280, 1]'),\n",
       " Text(44.88385947392835, 126.01636363636364, 'X[851] <= 0.269\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(44.37741254051308, 121.07454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(45.390306407343616, 121.07454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(45.896753340758885, 126.01636363636364, 'gini = 0.0\\nsamples = 279\\nvalue = [0, 279, 0]'),\n",
       " Text(45.390306407343616, 135.9, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(44.88385947392835, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(45.390306407343616, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(45.896753340758885, 160.60909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(46.90964720758943, 170.49272727272728, 'X[3561] <= 0.435\\ngini = 0.496\\nsamples = 22\\nvalue = [0, 10, 12]'),\n",
       " Text(46.403200274174154, 165.5509090909091, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 10, 0]'),\n",
       " Text(47.4160941410047, 165.5509090909091, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12]'),\n",
       " Text(50.746576220710196, 180.37636363636364, 'X[2970] <= 0.945\\ngini = 0.032\\nsamples = 3140\\nvalue = [7, 3089, 44]'),\n",
       " Text(49.73368235387966, 175.43454545454546, 'X[3295] <= 0.135\\ngini = 0.03\\nsamples = 3135\\nvalue = [7, 3088, 40]'),\n",
       " Text(49.22723542046439, 170.49272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(50.24012928729493, 170.49272727272728, 'X[3971] <= 0.006\\ngini = 0.028\\nsamples = 3132\\nvalue = [7, 3088, 37]'),\n",
       " Text(48.46756502034148, 165.5509090909091, 'X[3942] <= 0.506\\ngini = 0.358\\nsamples = 30\\nvalue = [0, 23, 7]'),\n",
       " Text(47.96111808692621, 160.60909090909092, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 22, 0]'),\n",
       " Text(48.97401195375675, 160.60909090909092, 'X[3060] <= 0.018\\ngini = 0.219\\nsamples = 8\\nvalue = [0, 1, 7]'),\n",
       " Text(48.46756502034148, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(49.48045888717202, 155.66727272727275, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(52.01269355424837, 165.5509090909091, 'X[2151] <= 0.951\\ngini = 0.024\\nsamples = 3102\\nvalue = [7, 3065, 30]'),\n",
       " Text(50.999799687417834, 160.60909090909092, 'X[2725] <= 0.043\\ngini = 0.022\\nsamples = 3099\\nvalue = [7, 3064, 28]'),\n",
       " Text(50.493352754002565, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(51.5062466208331, 155.66727272727275, 'X[2842] <= 0.061\\ngini = 0.022\\nsamples = 3098\\nvalue = [6, 3064, 28]'),\n",
       " Text(50.999799687417834, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(52.01269355424837, 150.72545454545457, 'X[2271] <= 0.129\\ngini = 0.021\\nsamples = 3097\\nvalue = [5, 3064, 28]'),\n",
       " Text(51.5062466208331, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(52.51914048766364, 145.78363636363636, 'X[2710] <= 0.975\\ngini = 0.02\\nsamples = 3096\\nvalue = [5, 3064, 27]'),\n",
       " Text(52.01269355424837, 140.84181818181818, 'X[2662] <= 0.961\\ngini = 0.02\\nsamples = 3095\\nvalue = [5, 3064, 26]'),\n",
       " Text(51.5062466208331, 135.9, 'X[3166] <= 0.943\\ngini = 0.019\\nsamples = 3094\\nvalue = [5, 3064, 25]'),\n",
       " Text(50.999799687417834, 130.95818181818183, 'X[1507] <= 0.225\\ngini = 0.019\\nsamples = 3093\\nvalue = [5, 3064, 24]'),\n",
       " Text(47.4160941410047, 126.01636363636364, 'X[2016] <= 0.38\\ngini = 0.254\\nsamples = 63\\nvalue = [3, 54, 6]'),\n",
       " Text(46.403200274174154, 121.07454545454546, 'X[1617] <= 0.263\\ngini = 0.48\\nsamples = 10\\nvalue = [0, 4, 6]'),\n",
       " Text(45.896753340758885, 116.13272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(46.90964720758943, 116.13272727272728, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(48.42898800783524, 121.07454545454546, 'X[3750] <= 0.72\\ngini = 0.107\\nsamples = 53\\nvalue = [3, 50, 0]'),\n",
       " Text(47.92254107441997, 116.13272727272728, 'gini = 0.0\\nsamples = 50\\nvalue = [0, 50, 0]'),\n",
       " Text(48.93543494125051, 116.13272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(54.58350523383097, 126.01636363636364, 'X[3428] <= 0.892\\ngini = 0.013\\nsamples = 3030\\nvalue = [2, 3010, 18]'),\n",
       " Text(52.531999491832394, 121.07454545454546, 'X[2420] <= 0.941\\ngini = 0.012\\nsamples = 3025\\nvalue = [2, 3007, 16]'),\n",
       " Text(49.94832880808105, 116.13272727272728, 'X[2202] <= 0.98\\ngini = 0.009\\nsamples = 2964\\nvalue = [2, 2951, 11]'),\n",
       " Text(47.81966904106999, 111.1909090909091, 'X[1575] <= 0.127\\ngini = 0.008\\nsamples = 2962\\nvalue = [2, 2950, 10]'),\n",
       " Text(45.081690307293684, 106.24909090909091, 'X[2907] <= 0.68\\ngini = 0.197\\nsamples = 37\\nvalue = [1, 33, 3]'),\n",
       " Text(44.068796440463146, 101.30727272727273, 'X[1330] <= 0.547\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(43.56234950704788, 96.36545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(44.575243373878415, 96.36545454545455, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(46.09458417412423, 101.30727272727273, 'X[3360] <= 0.427\\ngini = 0.057\\nsamples = 34\\nvalue = [0, 33, 1]'),\n",
       " Text(45.58813724070895, 96.36545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(46.6010311075395, 96.36545454545455, 'gini = 0.0\\nsamples = 33\\nvalue = [0, 33, 0]'),\n",
       " Text(50.557647774846295, 106.24909090909091, 'X[1383] <= 0.978\\ngini = 0.005\\nsamples = 2925\\nvalue = [1, 2917, 7]'),\n",
       " Text(49.06995990793894, 101.30727272727273, 'X[1708] <= 0.02\\ngini = 0.005\\nsamples = 2920\\nvalue = [0, 2913, 7]'),\n",
       " Text(47.613924974370036, 96.36545454545455, 'X[3206] <= 0.186\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 4, 1]'),\n",
       " Text(47.10747804095477, 91.42363636363638, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(48.120371907785305, 91.42363636363638, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(50.525994841507845, 96.36545454545455, 'X[3577] <= 0.002\\ngini = 0.004\\nsamples = 2915\\nvalue = [0, 2909, 6]'),\n",
       " Text(49.13326577461585, 91.42363636363638, 'X[2763] <= 0.518\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 4, 1]'),\n",
       " Text(48.62681884120058, 86.4818181818182, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(49.63971270803112, 86.4818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(51.91872390839983, 91.42363636363638, 'X[3540] <= 0.002\\ngini = 0.003\\nsamples = 2910\\nvalue = [0, 2905, 5]'),\n",
       " Text(50.65260657486166, 86.4818181818182, 'X[1120] <= 0.69\\ngini = 0.245\\nsamples = 7\\nvalue = [0, 6, 1]'),\n",
       " Text(50.14615964144639, 81.54000000000002, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(51.15905350827693, 81.54000000000002, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(53.18484124193802, 86.4818181818182, 'X[4095] <= 0.002\\ngini = 0.003\\nsamples = 2903\\nvalue = [0, 2899, 4]'),\n",
       " Text(52.17194737510747, 81.54000000000002, 'X[1937] <= 0.369\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 4, 1]'),\n",
       " Text(51.6655004416922, 76.59818181818181, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(52.67839430852274, 76.59818181818181, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(54.197735108768555, 81.54000000000002, 'X[1692] <= 0.225\\ngini = 0.002\\nsamples = 2898\\nvalue = [0, 2895, 3]'),\n",
       " Text(53.691288175353286, 76.59818181818181, 'X[2330] <= 0.822\\ngini = 0.041\\nsamples = 145\\nvalue = [0, 142, 3]'),\n",
       " Text(53.18484124193802, 71.65636363636364, 'X[3803] <= 0.794\\ngini = 0.014\\nsamples = 143\\nvalue = [0, 142, 1]'),\n",
       " Text(52.67839430852274, 66.71454545454546, 'gini = 0.0\\nsamples = 142\\nvalue = [0, 142, 0]'),\n",
       " Text(53.691288175353286, 66.71454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(54.197735108768555, 71.65636363636364, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(54.704182042183824, 76.59818181818181, 'gini = 0.0\\nsamples = 2753\\nvalue = [0, 2753, 0]'),\n",
       " Text(52.04533564175365, 101.30727272727273, 'X[767] <= 0.908\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4, 0]'),\n",
       " Text(51.53888870833838, 96.36545454545455, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(52.55178257516892, 96.36545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(52.07698857509211, 111.1909090909091, 'X[3095] <= 0.676\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(51.57054164167684, 106.24909090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(52.58343550850738, 106.24909090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(55.11567017558373, 116.13272727272728, 'X[2597] <= 0.786\\ngini = 0.15\\nsamples = 61\\nvalue = [0, 56, 5]'),\n",
       " Text(54.10277630875319, 111.1909090909091, 'X[1959] <= 0.429\\ngini = 0.036\\nsamples = 54\\nvalue = [0, 53, 1]'),\n",
       " Text(53.59632937533792, 106.24909090909091, 'gini = 0.0\\nsamples = 53\\nvalue = [0, 53, 0]'),\n",
       " Text(54.60922324216846, 106.24909090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(56.128564042414276, 111.1909090909091, 'X[1387] <= 0.659\\ngini = 0.49\\nsamples = 7\\nvalue = [0, 3, 4]'),\n",
       " Text(55.622117108999, 106.24909090909091, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(56.635010975829545, 106.24909090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(56.635010975829545, 121.07454545454546, 'X[4034] <= 0.261\\ngini = 0.48\\nsamples = 5\\nvalue = [0, 3, 2]'),\n",
       " Text(56.128564042414276, 116.13272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(57.141457909244814, 116.13272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(52.01269355424837, 130.95818181818183, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(52.51914048766364, 135.9, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(53.02558742107892, 140.84181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(53.02558742107892, 160.60909090909092, 'X[2850] <= 0.894\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(52.51914048766364, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(53.532034354494186, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(51.75947008754074, 175.43454545454546, 'X[1346] <= 0.416\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 1, 4]'),\n",
       " Text(51.253023154125465, 170.49272727272728, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(52.26591702095601, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(52.26591702095601, 185.3181818181818, 'X[2789] <= 0.696\\ngini = 0.165\\nsamples = 11\\nvalue = [0, 1, 10]'),\n",
       " Text(51.75947008754074, 180.37636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(52.77236395437128, 180.37636363636364, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 0, 10]'),\n",
       " Text(53.78525782120182, 190.26, 'X[3296] <= 0.453\\ngini = 0.302\\nsamples = 27\\nvalue = [0, 5, 22]'),\n",
       " Text(53.27881088778655, 185.3181818181818, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(54.29170475461709, 185.3181818181818, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 0, 22]'),\n",
       " Text(63.02791435603051, 200.14363636363635, 'X[1896] <= 0.355\\ngini = 0.564\\nsamples = 507\\nvalue = [37, 243, 227]'),\n",
       " Text(57.9634450218778, 195.20181818181817, 'X[1768] <= 0.28\\ngini = 0.236\\nsamples = 204\\nvalue = [7, 177, 20]'),\n",
       " Text(55.8110455548629, 190.26, 'X[3353] <= 0.735\\ngini = 0.614\\nsamples = 34\\nvalue = [5, 15, 14]'),\n",
       " Text(55.30459862144763, 185.3181818181818, 'X[1306] <= 0.241\\ngini = 0.525\\nsamples = 22\\nvalue = [5, 3, 14]'),\n",
       " Text(54.79815168803236, 180.37636363636364, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(55.8110455548629, 180.37636363636364, 'X[2848] <= 0.229\\ngini = 0.291\\nsamples = 17\\nvalue = [0, 3, 14]'),\n",
       " Text(55.30459862144763, 175.43454545454546, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(56.31749248827817, 175.43454545454546, 'gini = 0.0\\nsamples = 14\\nvalue = [0, 0, 14]'),\n",
       " Text(56.31749248827817, 185.3181818181818, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 12, 0]'),\n",
       " Text(60.1158444888927, 190.26, 'X[3295] <= 0.812\\ngini = 0.091\\nsamples = 170\\nvalue = [2, 162, 6]'),\n",
       " Text(58.84972715535452, 185.3181818181818, 'X[3425] <= 0.449\\ngini = 0.048\\nsamples = 165\\nvalue = [2, 161, 2]'),\n",
       " Text(57.836833288523984, 180.37636363636364, 'X[267] <= 0.418\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(57.330386355108715, 175.43454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(58.34328022193925, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(59.86262102218507, 180.37636363636364, 'X[2018] <= 0.912\\ngini = 0.012\\nsamples = 162\\nvalue = [0, 161, 1]'),\n",
       " Text(59.3561740887698, 175.43454545454546, 'gini = 0.0\\nsamples = 161\\nvalue = [0, 161, 0]'),\n",
       " Text(60.369067955600336, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(61.381961822430874, 185.3181818181818, 'X[1322] <= 0.608\\ngini = 0.32\\nsamples = 5\\nvalue = [0, 1, 4]'),\n",
       " Text(60.875514889015605, 180.37636363636364, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(61.88840875584615, 180.37636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(68.09238369018321, 195.20181818181817, 'X[1566] <= 0.625\\ngini = 0.476\\nsamples = 303\\nvalue = [30, 66, 207]'),\n",
       " Text(64.80047862298396, 190.26, 'X[1958] <= 0.392\\ngini = 0.248\\nsamples = 195\\nvalue = [14, 13, 168]'),\n",
       " Text(63.40774955609196, 185.3181818181818, 'X[3104] <= 0.873\\ngini = 0.32\\nsamples = 10\\nvalue = [0, 8, 2]'),\n",
       " Text(62.90130262267669, 180.37636363636364, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8, 0]'),\n",
       " Text(63.914196489507226, 180.37636363636364, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(66.19320768987595, 185.3181818181818, 'X[2775] <= 0.365\\ngini = 0.188\\nsamples = 185\\nvalue = [14, 5, 166]'),\n",
       " Text(64.92709035633777, 180.37636363636364, 'X[1894] <= 0.629\\ngini = 0.569\\nsamples = 24\\nvalue = [10, 2, 12]'),\n",
       " Text(63.914196489507226, 175.43454545454546, 'X[2973] <= 0.557\\ngini = 0.278\\nsamples = 12\\nvalue = [10, 0, 2]'),\n",
       " Text(63.40774955609196, 170.49272727272728, 'gini = 0.0\\nsamples = 10\\nvalue = [10, 0, 0]'),\n",
       " Text(64.4206434229225, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(65.93998422316831, 175.43454545454546, 'X[1764] <= 0.52\\ngini = 0.278\\nsamples = 12\\nvalue = [0, 2, 10]'),\n",
       " Text(65.43353728975305, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(66.44643115658359, 170.49272727272728, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 0, 10]'),\n",
       " Text(67.45932502341412, 180.37636363636364, 'X[1960] <= 0.343\\ngini = 0.084\\nsamples = 161\\nvalue = [4, 3, 154]'),\n",
       " Text(66.95287808999885, 175.43454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(67.9657719568294, 175.43454545454546, 'X[1510] <= 0.798\\ngini = 0.061\\nsamples = 159\\nvalue = [4, 1, 154]'),\n",
       " Text(67.45932502341412, 170.49272727272728, 'X[2340] <= 0.973\\ngini = 0.049\\nsamples = 158\\nvalue = [4, 0, 154]'),\n",
       " Text(66.95287808999885, 165.5509090909091, 'X[1810] <= 0.72\\ngini = 0.037\\nsamples = 157\\nvalue = [3, 0, 154]'),\n",
       " Text(66.44643115658359, 160.60909090909092, 'X[3617] <= 0.088\\ngini = 0.025\\nsamples = 156\\nvalue = [2, 0, 154]'),\n",
       " Text(65.93998422316831, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(66.95287808999885, 155.66727272727275, 'X[2525] <= 0.225\\ngini = 0.013\\nsamples = 155\\nvalue = [1, 0, 154]'),\n",
       " Text(66.44643115658359, 150.72545454545457, 'X[3147] <= 0.184\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(65.93998422316831, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(66.95287808999885, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(67.45932502341412, 150.72545454545457, 'gini = 0.0\\nsamples = 153\\nvalue = [0, 0, 153]'),\n",
       " Text(67.45932502341412, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(67.9657719568294, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(68.47221889024466, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(71.38428875738246, 190.26, 'X[1956] <= 0.61\\ngini = 0.607\\nsamples = 108\\nvalue = [16, 53, 39]'),\n",
       " Text(69.99155969049048, 185.3181818181818, 'X[2841] <= 0.553\\ngini = 0.318\\nsamples = 53\\nvalue = [2, 43, 8]'),\n",
       " Text(69.4851127570752, 180.37636363636364, 'X[3617] <= 0.637\\ngini = 0.43\\nsamples = 11\\nvalue = [2, 1, 8]'),\n",
       " Text(68.97866582365994, 175.43454545454546, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(69.99155969049048, 175.43454545454546, 'X[2502] <= 0.296\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(69.4851127570752, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(70.49800662390575, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(70.49800662390575, 180.37636363636364, 'gini = 0.0\\nsamples = 42\\nvalue = [0, 42, 0]'),\n",
       " Text(72.77701782427447, 185.3181818181818, 'X[3159] <= 0.437\\ngini = 0.584\\nsamples = 55\\nvalue = [14, 10, 31]'),\n",
       " Text(71.51090049073629, 180.37636363636364, 'X[2589] <= 0.937\\ngini = 0.142\\nsamples = 13\\nvalue = [12, 0, 1]'),\n",
       " Text(71.00445355732101, 175.43454545454546, 'gini = 0.0\\nsamples = 12\\nvalue = [12, 0, 0]'),\n",
       " Text(72.01734742415155, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(74.04313515781264, 180.37636363636364, 'X[2008] <= 0.382\\ngini = 0.431\\nsamples = 42\\nvalue = [2, 10, 30]'),\n",
       " Text(73.0302412909821, 175.43454545454546, 'X[2325] <= 0.353\\ngini = 0.142\\nsamples = 26\\nvalue = [2, 0, 24]'),\n",
       " Text(72.52379435756683, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(73.53668822439737, 170.49272727272728, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 0, 24]'),\n",
       " Text(75.05602902464318, 175.43454545454546, 'X[1510] <= 0.718\\ngini = 0.469\\nsamples = 16\\nvalue = [0, 10, 6]'),\n",
       " Text(74.5495820912279, 170.49272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(75.56247595805846, 170.49272727272728, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 10, 0]'),\n",
       " Text(185.77669157771274, 210.02727272727273, 'X[1183] <= 0.531\\ngini = 0.583\\nsamples = 7791\\nvalue = [3733, 778, 3280]'),\n",
       " Text(116.95511580017195, 205.08545454545455, 'X[1880] <= 0.535\\ngini = 0.453\\nsamples = 2114\\nvalue = [470, 161, 1483]'),\n",
       " Text(101.55447999976364, 200.14363636363635, 'X[3103] <= 0.731\\ngini = 0.608\\nsamples = 930\\nvalue = [321, 145, 464]'),\n",
       " Text(92.15850456907683, 195.20181818181817, 'X[2658] <= 0.508\\ngini = 0.525\\nsamples = 749\\nvalue = [315, 26, 408]'),\n",
       " Text(84.00193930942386, 190.26, 'X[3932] <= 0.261\\ngini = 0.504\\nsamples = 458\\nvalue = [266, 10, 182]'),\n",
       " Text(79.36082795867299, 185.3181818181818, 'X[1115] <= 0.408\\ngini = 0.277\\nsamples = 106\\nvalue = [14, 3, 89]'),\n",
       " Text(78.09471062513481, 180.37636363636364, 'X[1878] <= 0.198\\ngini = 0.101\\nsamples = 76\\nvalue = [3, 1, 72]'),\n",
       " Text(77.08181675830426, 175.43454545454546, 'X[3270] <= 0.251\\ngini = 0.625\\nsamples = 4\\nvalue = [2, 1, 1]'),\n",
       " Text(76.575369824889, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(77.58826369171953, 170.49272727272728, 'X[3753] <= 0.424\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(77.08181675830426, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(78.09471062513481, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(79.10760449196535, 175.43454545454546, 'X[2965] <= 0.651\\ngini = 0.027\\nsamples = 72\\nvalue = [1, 0, 71]'),\n",
       " Text(78.60115755855007, 170.49272727272728, 'gini = 0.0\\nsamples = 71\\nvalue = [0, 0, 71]'),\n",
       " Text(79.61405142538061, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(80.62694529221116, 180.37636363636364, 'X[2324] <= 0.453\\ngini = 0.54\\nsamples = 30\\nvalue = [11, 2, 17]'),\n",
       " Text(80.12049835879588, 175.43454545454546, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12]'),\n",
       " Text(81.13339222562642, 175.43454545454546, 'X[1496] <= 0.265\\ngini = 0.537\\nsamples = 18\\nvalue = [11, 2, 5]'),\n",
       " Text(80.62694529221116, 170.49272727272728, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0]'),\n",
       " Text(81.6398391590417, 170.49272727272728, 'X[3673] <= 0.453\\ngini = 0.408\\nsamples = 7\\nvalue = [0, 2, 5]'),\n",
       " Text(81.13339222562642, 165.5509090909091, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(82.14628609245696, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(88.64305066017474, 185.3181818181818, 'X[1769] <= 0.525\\ngini = 0.417\\nsamples = 352\\nvalue = [252, 7, 93]'),\n",
       " Text(85.64393522635618, 180.37636363636364, 'X[1631] <= 0.267\\ngini = 0.351\\nsamples = 315\\nvalue = [246, 7, 62]'),\n",
       " Text(83.15917995928751, 175.43454545454546, 'X[2778] <= 0.235\\ngini = 0.366\\nsamples = 29\\nvalue = [7, 0, 22]'),\n",
       " Text(82.65273302587224, 170.49272727272728, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(83.66562689270278, 170.49272727272728, 'X[3760] <= 0.155\\ngini = 0.153\\nsamples = 24\\nvalue = [2, 0, 22]'),\n",
       " Text(83.15917995928751, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(84.17207382611805, 165.5509090909091, 'gini = 0.0\\nsamples = 22\\nvalue = [0, 0, 22]'),\n",
       " Text(88.12869049342486, 175.43454545454546, 'X[1367] <= 0.461\\ngini = 0.282\\nsamples = 286\\nvalue = [239, 7, 40]'),\n",
       " Text(86.64100262651749, 170.49272727272728, 'X[2189] <= 0.816\\ngini = 0.215\\nsamples = 266\\nvalue = [234, 4, 28]'),\n",
       " Text(85.18496769294859, 165.5509090909091, 'X[3164] <= 0.757\\ngini = 0.173\\nsamples = 255\\nvalue = [231, 4, 20]'),\n",
       " Text(83.7922386260566, 160.60909090909092, 'X[2258] <= 0.402\\ngini = 0.134\\nsamples = 249\\nvalue = [231, 0, 18]'),\n",
       " Text(82.52612129251843, 155.66727272727275, 'X[1744] <= 0.329\\ngini = 0.498\\nsamples = 17\\nvalue = [8, 0, 9]'),\n",
       " Text(82.01967435910315, 150.72545454545457, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(83.03256822593369, 150.72545454545457, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(85.05835595959478, 155.66727272727275, 'X[614] <= 0.824\\ngini = 0.075\\nsamples = 232\\nvalue = [223, 0, 9]'),\n",
       " Text(84.04546209276423, 150.72545454545457, 'X[1980] <= 0.006\\ngini = 0.051\\nsamples = 228\\nvalue = [222, 0, 6]'),\n",
       " Text(83.53901515934896, 145.78363636363636, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(84.5519090261795, 145.78363636363636, 'X[1115] <= 0.135\\ngini = 0.035\\nsamples = 226\\nvalue = [222, 0, 4]'),\n",
       " Text(84.04546209276423, 140.84181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(85.05835595959478, 140.84181818181818, 'X[3802] <= 0.171\\ngini = 0.026\\nsamples = 225\\nvalue = [222, 0, 3]'),\n",
       " Text(84.5519090261795, 135.9, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(85.56480289301004, 135.9, 'X[3285] <= 0.696\\ngini = 0.018\\nsamples = 224\\nvalue = [222, 0, 2]'),\n",
       " Text(84.5519090261795, 130.95818181818183, 'X[559] <= 0.665\\ngini = 0.009\\nsamples = 222\\nvalue = [221, 0, 1]'),\n",
       " Text(84.04546209276423, 126.01636363636364, 'gini = 0.0\\nsamples = 213\\nvalue = [213, 0, 0]'),\n",
       " Text(85.05835595959478, 126.01636363636364, 'X[3914] <= 0.518\\ngini = 0.198\\nsamples = 9\\nvalue = [8, 0, 1]'),\n",
       " Text(84.5519090261795, 121.07454545454546, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(85.56480289301004, 121.07454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(86.57769675984058, 130.95818181818183, 'X[1743] <= 0.288\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(86.07124982642532, 126.01636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(87.08414369325585, 126.01636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(86.07124982642532, 150.72545454545457, 'X[488] <= 0.859\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(85.56480289301004, 145.78363636363636, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(86.57769675984058, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(86.57769675984058, 160.60909090909092, 'X[4091] <= 0.073\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 4, 2]'),\n",
       " Text(86.07124982642532, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(87.08414369325585, 155.66727272727275, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(88.09703756008639, 165.5509090909091, 'X[3482] <= 0.553\\ngini = 0.397\\nsamples = 11\\nvalue = [3, 0, 8]'),\n",
       " Text(87.59059062667113, 160.60909090909092, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(88.60348449350167, 160.60909090909092, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(89.6163783603322, 170.49272727272728, 'X[3482] <= 0.504\\ngini = 0.555\\nsamples = 20\\nvalue = [5, 3, 12]'),\n",
       " Text(89.10993142691693, 165.5509090909091, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12]'),\n",
       " Text(90.12282529374748, 165.5509090909091, 'X[167] <= 0.537\\ngini = 0.469\\nsamples = 8\\nvalue = [5, 3, 0]'),\n",
       " Text(89.6163783603322, 160.60909090909092, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(90.62927222716274, 160.60909090909092, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(91.64216609399328, 180.37636363636364, 'X[1575] <= 0.324\\ngini = 0.272\\nsamples = 37\\nvalue = [6, 0, 31]'),\n",
       " Text(91.13571916057802, 175.43454545454546, 'X[3002] <= 0.563\\ngini = 0.444\\nsamples = 9\\nvalue = [6, 0, 3]'),\n",
       " Text(90.62927222716274, 170.49272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(91.64216609399328, 170.49272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(92.14861302740856, 175.43454545454546, 'gini = 0.0\\nsamples = 28\\nvalue = [0, 0, 28]'),\n",
       " Text(100.31506982872979, 190.26, 'X[3047] <= 0.527\\ngini = 0.365\\nsamples = 291\\nvalue = [49, 16, 226]'),\n",
       " Text(96.32680022808454, 185.3181818181818, 'X[2587] <= 0.618\\ngini = 0.508\\nsamples = 110\\nvalue = [38, 5, 67]'),\n",
       " Text(94.42762422777727, 180.37636363636364, 'X[3998] <= 0.408\\ngini = 0.524\\nsamples = 70\\nvalue = [37, 2, 31]'),\n",
       " Text(93.1615068942391, 175.43454545454546, 'X[3040] <= 0.263\\ngini = 0.363\\nsamples = 23\\nvalue = [3, 2, 18]'),\n",
       " Text(92.65505996082383, 170.49272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(93.66795382765437, 170.49272727272728, 'X[3032] <= 0.698\\ngini = 0.18\\nsamples = 20\\nvalue = [0, 2, 18]'),\n",
       " Text(93.1615068942391, 165.5509090909091, 'gini = 0.0\\nsamples = 18\\nvalue = [0, 0, 18]'),\n",
       " Text(94.17440076106963, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(95.69374156131545, 175.43454545454546, 'X[391] <= 0.073\\ngini = 0.4\\nsamples = 47\\nvalue = [34, 0, 13]'),\n",
       " Text(95.18729462790019, 170.49272727272728, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(96.20018849473072, 170.49272727272728, 'X[3490] <= 0.349\\ngini = 0.255\\nsamples = 40\\nvalue = [34, 0, 6]'),\n",
       " Text(95.18729462790019, 165.5509090909091, 'X[3428] <= 0.286\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 0, 5]'),\n",
       " Text(94.68084769448491, 160.60909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(95.69374156131545, 160.60909090909092, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(97.21308236156126, 165.5509090909091, 'X[3492] <= 0.816\\ngini = 0.059\\nsamples = 33\\nvalue = [32, 0, 1]'),\n",
       " Text(96.70663542814599, 160.60909090909092, 'gini = 0.0\\nsamples = 32\\nvalue = [32, 0, 0]'),\n",
       " Text(97.71952929497654, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(98.2259762283918, 180.37636363636364, 'X[3559] <= 0.147\\ngini = 0.184\\nsamples = 40\\nvalue = [1, 3, 36]'),\n",
       " Text(97.71952929497654, 175.43454545454546, 'X[2911] <= 0.586\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3, 0]'),\n",
       " Text(97.21308236156126, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(98.2259762283918, 170.49272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(98.73242316180708, 175.43454545454546, 'gini = 0.0\\nsamples = 36\\nvalue = [0, 0, 36]'),\n",
       " Text(104.30333942937504, 185.3181818181818, 'X[1439] <= 0.629\\ngini = 0.221\\nsamples = 181\\nvalue = [11, 11, 159]'),\n",
       " Text(103.03722209583687, 180.37636363636364, 'X[1033] <= 0.873\\ngini = 0.144\\nsamples = 170\\nvalue = [9, 4, 157]'),\n",
       " Text(102.02432822900633, 175.43454545454546, 'X[413] <= 0.841\\ngini = 0.114\\nsamples = 167\\nvalue = [8, 2, 157]'),\n",
       " Text(101.51788129559107, 170.49272727272728, 'X[3229] <= 0.816\\ngini = 0.093\\nsamples = 165\\nvalue = [6, 2, 157]'),\n",
       " Text(99.74531702863761, 165.5509090909091, 'X[3237] <= 0.32\\ngini = 0.06\\nsamples = 161\\nvalue = [5, 0, 156]'),\n",
       " Text(98.73242316180708, 160.60909090909092, 'X[526] <= 0.414\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 0, 2]'),\n",
       " Text(98.2259762283918, 155.66727272727275, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(99.23887009522234, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(100.75821089546815, 160.60909090909092, 'X[3136] <= 0.978\\ngini = 0.025\\nsamples = 156\\nvalue = [2, 0, 154]'),\n",
       " Text(100.25176396205289, 155.66727272727275, 'X[2312] <= 0.014\\ngini = 0.013\\nsamples = 155\\nvalue = [1, 0, 154]'),\n",
       " Text(99.74531702863761, 150.72545454545457, 'X[3157] <= 0.28\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(99.23887009522234, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(100.25176396205289, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(100.75821089546815, 150.72545454545457, 'gini = 0.0\\nsamples = 153\\nvalue = [0, 0, 153]'),\n",
       " Text(101.26465782888343, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(103.2904455625445, 165.5509090909091, 'X[339] <= 0.229\\ngini = 0.625\\nsamples = 4\\nvalue = [1, 2, 1]'),\n",
       " Text(102.78399862912924, 160.60909090909092, 'X[3633] <= 0.531\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(102.27755169571397, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(103.2904455625445, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(103.79689249595978, 160.60909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(102.5307751624216, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(104.05011596266742, 175.43454545454546, 'X[3140] <= 0.859\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(103.54366902925214, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(104.55656289608268, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(105.56945676291322, 180.37636363636364, 'X[104] <= 0.612\\ngini = 0.529\\nsamples = 11\\nvalue = [2, 7, 2]'),\n",
       " Text(105.06300982949796, 175.43454545454546, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(106.0759036963285, 175.43454545454546, 'X[2340] <= 0.627\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 0, 2]'),\n",
       " Text(105.56945676291322, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(106.58235062974377, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(110.95045543045048, 195.20181818181817, 'X[732] <= 0.484\\ngini = 0.471\\nsamples = 181\\nvalue = [6, 119, 56]'),\n",
       " Text(108.10169142998957, 190.26, 'X[1760] <= 0.247\\ngini = 0.247\\nsamples = 119\\nvalue = [1, 102, 16]'),\n",
       " Text(107.59524449657431, 185.3181818181818, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(108.60813836340485, 185.3181818181818, 'X[3294] <= 0.482\\ngini = 0.15\\nsamples = 111\\nvalue = [1, 102, 8]'),\n",
       " Text(107.59524449657431, 180.37636363636364, 'X[171] <= 0.076\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 0, 4]'),\n",
       " Text(107.08879756315903, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(108.10169142998957, 175.43454545454546, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(109.62103223023539, 180.37636363636364, 'X[4035] <= 0.01\\ngini = 0.073\\nsamples = 106\\nvalue = [0, 102, 4]'),\n",
       " Text(109.11458529682012, 175.43454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(110.12747916365066, 175.43454545454546, 'X[3427] <= 0.802\\ngini = 0.038\\nsamples = 104\\nvalue = [0, 102, 2]'),\n",
       " Text(109.62103223023539, 170.49272727272728, 'X[4053] <= 0.033\\ngini = 0.019\\nsamples = 103\\nvalue = [0, 102, 1]'),\n",
       " Text(109.11458529682012, 165.5509090909091, 'X[2087] <= 0.531\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(108.60813836340485, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(109.62103223023539, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(110.12747916365066, 165.5509090909091, 'gini = 0.0\\nsamples = 101\\nvalue = [0, 101, 0]'),\n",
       " Text(110.63392609706592, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(113.79921943091136, 190.26, 'X[2722] <= 0.531\\ngini = 0.502\\nsamples = 62\\nvalue = [5, 17, 40]'),\n",
       " Text(112.15326689731174, 185.3181818181818, 'X[2049] <= 0.22\\ngini = 0.338\\nsamples = 15\\nvalue = [1, 12, 2]'),\n",
       " Text(111.64681996389648, 180.37636363636364, 'X[1429] <= 0.251\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(111.1403730304812, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(112.15326689731174, 175.43454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(112.65971383072701, 180.37636363636364, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 12, 0]'),\n",
       " Text(115.445171964511, 185.3181818181818, 'X[1809] <= 0.696\\ngini = 0.328\\nsamples = 47\\nvalue = [4, 5, 38]'),\n",
       " Text(114.17905463097283, 180.37636363636364, 'X[1767] <= 0.198\\ngini = 0.176\\nsamples = 42\\nvalue = [3, 1, 38]'),\n",
       " Text(113.16616076414228, 175.43454545454546, 'X[2126] <= 0.275\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(112.65971383072701, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(113.67260769755755, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(115.19194849780337, 175.43454545454546, 'X[3438] <= 0.041\\ngini = 0.05\\nsamples = 39\\nvalue = [1, 0, 38]'),\n",
       " Text(114.68550156438809, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(115.69839543121863, 170.49272727272728, 'gini = 0.0\\nsamples = 38\\nvalue = [0, 0, 38]'),\n",
       " Text(116.71128929804918, 180.37636363636364, 'X[1934] <= 0.839\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4, 0]'),\n",
       " Text(116.2048423646339, 175.43454545454546, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(117.21773623146444, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(132.35575160058028, 200.14363636363635, 'X[1620] <= 0.198\\ngini = 0.243\\nsamples = 1184\\nvalue = [149, 16, 1019]'),\n",
       " Text(125.06766369940114, 195.20181818181817, 'X[1805] <= 0.535\\ngini = 0.506\\nsamples = 147\\nvalue = [54, 5, 88]'),\n",
       " Text(121.77575863220189, 190.26, 'X[1067] <= 0.514\\ngini = 0.384\\nsamples = 99\\nvalue = [20, 4, 75]'),\n",
       " Text(119.7499708985408, 185.3181818181818, 'X[3493] <= 0.782\\ngini = 0.187\\nsamples = 69\\nvalue = [4, 3, 62]'),\n",
       " Text(118.73707703171026, 180.37636363636364, 'X[1557] <= 0.414\\ngini = 0.116\\nsamples = 65\\nvalue = [4, 0, 61]'),\n",
       " Text(118.230630098295, 175.43454545454546, 'X[2323] <= 0.112\\ngini = 0.061\\nsamples = 63\\nvalue = [2, 0, 61]'),\n",
       " Text(117.72418316487972, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(118.73707703171026, 170.49272727272728, 'X[2784] <= 0.247\\ngini = 0.032\\nsamples = 62\\nvalue = [1, 0, 61]'),\n",
       " Text(118.230630098295, 165.5509090909091, 'X[2365] <= 0.053\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(117.72418316487972, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(118.73707703171026, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(119.24352396512553, 165.5509090909091, 'gini = 0.0\\nsamples = 60\\nvalue = [0, 0, 60]'),\n",
       " Text(119.24352396512553, 175.43454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(120.76286476537135, 180.37636363636364, 'X[3549] <= 0.686\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 3, 1]'),\n",
       " Text(120.25641783195607, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(121.26931169878661, 175.43454545454546, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(123.80154636586296, 185.3181818181818, 'X[1179] <= 0.384\\ngini = 0.527\\nsamples = 30\\nvalue = [16, 1, 13]'),\n",
       " Text(122.78865249903242, 180.37636363636364, 'X[358] <= 0.173\\ngini = 0.165\\nsamples = 11\\nvalue = [0, 1, 10]'),\n",
       " Text(122.28220556561715, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(123.2950994324477, 175.43454545454546, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 0, 10]'),\n",
       " Text(124.8144402326935, 180.37636363636364, 'X[1573] <= 0.641\\ngini = 0.266\\nsamples = 19\\nvalue = [16, 0, 3]'),\n",
       " Text(124.30799329927824, 175.43454545454546, 'gini = 0.0\\nsamples = 16\\nvalue = [16, 0, 0]'),\n",
       " Text(125.32088716610878, 175.43454545454546, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(128.3595687666004, 190.26, 'X[1723] <= 0.533\\ngini = 0.424\\nsamples = 48\\nvalue = [34, 1, 13]'),\n",
       " Text(127.34667489976985, 185.3181818181818, 'X[3800] <= 0.408\\ngini = 0.224\\nsamples = 39\\nvalue = [34, 0, 5]'),\n",
       " Text(126.84022796635459, 180.37636363636364, 'X[1485] <= 0.549\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 0, 5]'),\n",
       " Text(126.33378103293931, 175.43454545454546, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(127.34667489976985, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(127.85312183318513, 180.37636363636364, 'gini = 0.0\\nsamples = 33\\nvalue = [33, 0, 0]'),\n",
       " Text(129.37246263343093, 185.3181818181818, 'X[473] <= 0.171\\ngini = 0.198\\nsamples = 9\\nvalue = [0, 1, 8]'),\n",
       " Text(128.86601570001568, 180.37636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(129.8789095668462, 180.37636363636364, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(139.6438395017594, 195.20181818181817, 'X[1556] <= 0.171\\ngini = 0.185\\nsamples = 1037\\nvalue = [95, 11, 931]'),\n",
       " Text(133.93048503416838, 190.26, 'X[3992] <= 0.457\\ngini = 0.498\\nsamples = 56\\nvalue = [22, 1, 33]'),\n",
       " Text(131.90469730050728, 185.3181818181818, 'X[1174] <= 0.488\\ngini = 0.225\\nsamples = 31\\nvalue = [4, 0, 27]'),\n",
       " Text(130.89180343367676, 180.37636363636364, 'X[3910] <= 0.906\\ngini = 0.071\\nsamples = 27\\nvalue = [1, 0, 26]'),\n",
       " Text(130.38535650026148, 175.43454545454546, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 0, 26]'),\n",
       " Text(131.39825036709203, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(132.91759116733783, 180.37636363636364, 'X[2035] <= 0.576\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(132.41114423392256, 175.43454545454546, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(133.4240381007531, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(135.95627276782946, 185.3181818181818, 'X[3165] <= 0.635\\ngini = 0.422\\nsamples = 25\\nvalue = [18, 1, 6]'),\n",
       " Text(134.9433789009989, 180.37636363636364, 'X[2129] <= 0.39\\ngini = 0.111\\nsamples = 17\\nvalue = [16, 1, 0]'),\n",
       " Text(134.43693196758363, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(135.44982583441418, 175.43454545454546, 'gini = 0.0\\nsamples = 16\\nvalue = [16, 0, 0]'),\n",
       " Text(136.96916663465998, 180.37636363636364, 'X[484] <= 0.704\\ngini = 0.375\\nsamples = 8\\nvalue = [2, 0, 6]'),\n",
       " Text(136.46271970124474, 175.43454545454546, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(137.47561356807526, 175.43454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(145.35719396935042, 190.26, 'X[477] <= 0.265\\ngini = 0.156\\nsamples = 981\\nvalue = [73, 10, 898]'),\n",
       " Text(140.26107170185927, 185.3181818181818, 'X[4059] <= 0.41\\ngini = 0.411\\nsamples = 99\\nvalue = [24, 3, 72]'),\n",
       " Text(138.9949543683211, 180.37636363636364, 'X[4094] <= 0.949\\ngini = 0.048\\nsamples = 41\\nvalue = [0, 1, 40]'),\n",
       " Text(138.4885074349058, 175.43454545454546, 'gini = 0.0\\nsamples = 40\\nvalue = [0, 0, 40]'),\n",
       " Text(139.50140130173634, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(141.52718903539744, 180.37636363636364, 'X[2276] <= 0.72\\ngini = 0.523\\nsamples = 58\\nvalue = [24, 2, 32]'),\n",
       " Text(140.5142951685669, 175.43454545454546, 'X[2301] <= 0.645\\ngini = 0.383\\nsamples = 31\\nvalue = [23, 0, 8]'),\n",
       " Text(140.0078482351516, 170.49272727272728, 'X[840] <= 0.682\\ngini = 0.147\\nsamples = 25\\nvalue = [23, 0, 2]'),\n",
       " Text(139.50140130173634, 165.5509090909091, 'gini = 0.0\\nsamples = 23\\nvalue = [23, 0, 0]'),\n",
       " Text(140.5142951685669, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(141.02074210198217, 170.49272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(142.54008290222797, 175.43454545454546, 'X[2073] <= 0.543\\ngini = 0.203\\nsamples = 27\\nvalue = [1, 2, 24]'),\n",
       " Text(142.0336359688127, 170.49272727272728, 'X[3286] <= 0.563\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(141.52718903539744, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(142.54008290222797, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(143.04652983564324, 170.49272727272728, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 0, 24]'),\n",
       " Text(150.45331623684157, 185.3181818181818, 'X[1881] <= 0.347\\ngini = 0.12\\nsamples = 882\\nvalue = [49, 7, 826]'),\n",
       " Text(149.9468693034263, 180.37636363636364, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(150.95976317025685, 180.37636363636364, 'X[1055] <= 0.567\\ngini = 0.114\\nsamples = 879\\nvalue = [49, 4, 826]'),\n",
       " Text(145.83198796942722, 175.43454545454546, 'X[1450] <= 0.159\\ngini = 0.062\\nsamples = 685\\nvalue = [20, 2, 663]'),\n",
       " Text(144.56587063588904, 170.49272727272728, 'X[1550] <= 0.143\\ngini = 0.232\\nsamples = 82\\nvalue = [11, 0, 71]'),\n",
       " Text(143.55297676905852, 165.5509090909091, 'X[207] <= 0.455\\ngini = 0.444\\nsamples = 9\\nvalue = [6, 0, 3]'),\n",
       " Text(143.04652983564324, 160.60909090909092, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(144.0594237024738, 160.60909090909092, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(145.5787645027196, 165.5509090909091, 'X[3166] <= 0.3\\ngini = 0.128\\nsamples = 73\\nvalue = [5, 0, 68]'),\n",
       " Text(145.07231756930432, 160.60909090909092, 'X[3671] <= 0.367\\ngini = 0.473\\nsamples = 13\\nvalue = [5, 0, 8]'),\n",
       " Text(144.56587063588904, 155.66727272727275, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(145.5787645027196, 155.66727272727275, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(146.08521143613487, 160.60909090909092, 'gini = 0.0\\nsamples = 60\\nvalue = [0, 0, 60]'),\n",
       " Text(147.0981053029654, 170.49272727272728, 'X[1885] <= 0.1\\ngini = 0.036\\nsamples = 603\\nvalue = [9, 2, 592]'),\n",
       " Text(146.59165836955015, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(147.60455223638067, 165.5509090909091, 'X[1244] <= 0.973\\ngini = 0.033\\nsamples = 602\\nvalue = [9, 1, 592]'),\n",
       " Text(147.0981053029654, 160.60909090909092, 'X[1311] <= 0.933\\ngini = 0.03\\nsamples = 601\\nvalue = [9, 0, 592]'),\n",
       " Text(146.59165836955015, 155.66727272727275, 'X[803] <= 0.055\\ngini = 0.026\\nsamples = 600\\nvalue = [8, 0, 592]'),\n",
       " Text(146.08521143613487, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(147.0981053029654, 150.72545454545457, 'X[2579] <= 0.075\\ngini = 0.023\\nsamples = 599\\nvalue = [7, 0, 592]'),\n",
       " Text(145.6420703693965, 145.78363636363636, 'X[628] <= 0.384\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(145.13562343598124, 140.84181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(146.14851730281177, 140.84181818181818, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(148.5541402365343, 145.78363636363636, 'X[1299] <= 0.031\\ngini = 0.02\\nsamples = 596\\nvalue = [6, 0, 590]'),\n",
       " Text(147.16141116964232, 140.84181818181818, 'X[152] <= 0.6\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(146.65496423622704, 135.9, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(147.6678581030576, 135.9, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(149.9468693034263, 140.84181818181818, 'X[1615] <= 0.098\\ngini = 0.017\\nsamples = 592\\nvalue = [5, 0, 587]'),\n",
       " Text(148.68075196988812, 135.9, 'X[3392] <= 0.729\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 0, 4]'),\n",
       " Text(148.17430503647284, 130.95818181818183, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(149.1871989033034, 130.95818181818183, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(151.21298663696447, 135.9, 'X[478] <= 0.355\\ngini = 0.014\\nsamples = 587\\nvalue = [4, 0, 583]'),\n",
       " Text(150.20009277013395, 130.95818181818183, 'X[538] <= 0.627\\ngini = 0.12\\nsamples = 47\\nvalue = [3, 0, 44]'),\n",
       " Text(149.69364583671867, 126.01636363636364, 'X[938] <= 0.673\\ngini = 0.043\\nsamples = 45\\nvalue = [1, 0, 44]'),\n",
       " Text(149.1871989033034, 121.07454545454546, 'gini = 0.0\\nsamples = 44\\nvalue = [0, 0, 44]'),\n",
       " Text(150.20009277013395, 121.07454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(150.7065397035492, 126.01636363636364, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(152.22588050379503, 130.95818181818183, 'X[516] <= 0.78\\ngini = 0.004\\nsamples = 540\\nvalue = [1, 0, 539]'),\n",
       " Text(151.71943357037975, 126.01636363636364, 'gini = 0.0\\nsamples = 499\\nvalue = [0, 0, 499]'),\n",
       " Text(152.7323274372103, 126.01636363636364, 'X[2879] <= 0.051\\ngini = 0.048\\nsamples = 41\\nvalue = [1, 0, 40]'),\n",
       " Text(152.22588050379503, 121.07454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(153.23877437062555, 121.07454545454546, 'gini = 0.0\\nsamples = 40\\nvalue = [0, 0, 40]'),\n",
       " Text(147.60455223638067, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(148.11099916979595, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(156.08753837108645, 175.43454545454546, 'X[3173] <= 0.682\\ngini = 0.272\\nsamples = 194\\nvalue = [29, 2, 163]'),\n",
       " Text(153.618609570687, 170.49272727272728, 'X[3742] <= 0.649\\ngini = 0.413\\nsamples = 96\\nvalue = [28, 0, 68]'),\n",
       " Text(151.71943357037975, 165.5509090909091, 'X[3768] <= 0.673\\ngini = 0.259\\nsamples = 72\\nvalue = [11, 0, 61]'),\n",
       " Text(150.45331623684157, 160.60909090909092, 'X[2717] <= 0.159\\ngini = 0.146\\nsamples = 63\\nvalue = [5, 0, 58]'),\n",
       " Text(149.44042237001102, 155.66727272727275, 'X[4087] <= 0.1\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(148.93397543659577, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(149.9468693034263, 150.72545454545457, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(151.46621010367213, 155.66727272727275, 'X[4018] <= 0.81\\ngini = 0.065\\nsamples = 59\\nvalue = [2, 0, 57]'),\n",
       " Text(150.95976317025685, 150.72545454545457, 'X[2878] <= 0.61\\ngini = 0.034\\nsamples = 58\\nvalue = [1, 0, 57]'),\n",
       " Text(150.45331623684157, 145.78363636363636, 'gini = 0.0\\nsamples = 55\\nvalue = [0, 0, 55]'),\n",
       " Text(151.46621010367213, 145.78363636363636, 'X[453] <= 0.218\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(150.95976317025685, 140.84181818181818, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(151.97265703708737, 140.84181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(151.97265703708737, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(152.98555090391793, 160.60909090909092, 'X[2785] <= 0.651\\ngini = 0.444\\nsamples = 9\\nvalue = [6, 0, 3]'),\n",
       " Text(152.47910397050265, 155.66727272727275, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(153.4919978373332, 155.66727272727275, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(155.51778557099428, 165.5509090909091, 'X[2579] <= 0.796\\ngini = 0.413\\nsamples = 24\\nvalue = [17, 0, 7]'),\n",
       " Text(155.011338637579, 160.60909090909092, 'X[3502] <= 0.88\\ngini = 0.105\\nsamples = 18\\nvalue = [17, 0, 1]'),\n",
       " Text(154.50489170416373, 155.66727272727275, 'gini = 0.0\\nsamples = 17\\nvalue = [17, 0, 0]'),\n",
       " Text(155.51778557099428, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(156.02423250440955, 160.60909090909092, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(158.5564671714859, 170.49272727272728, 'X[546] <= 0.286\\ngini = 0.06\\nsamples = 98\\nvalue = [1, 2, 95]'),\n",
       " Text(157.54357330465535, 165.5509090909091, 'X[1565] <= 0.682\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(157.03712637124008, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(158.05002023807063, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(159.56936103831643, 165.5509090909091, 'X[927] <= 0.439\\ngini = 0.021\\nsamples = 96\\nvalue = [0, 1, 95]'),\n",
       " Text(159.06291410490118, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(160.0758079717317, 160.60909090909092, 'gini = 0.0\\nsamples = 95\\nvalue = [0, 0, 95]'),\n",
       " Text(254.59826735525348, 205.08545454545455, 'X[3223] <= 0.727\\ngini = 0.558\\nsamples = 5677\\nvalue = [3263, 617, 1797]'),\n",
       " Text(213.9706146169096, 200.14363636363635, 'X[3934] <= 0.457\\ngini = 0.448\\nsamples = 4240\\nvalue = [2976, 265, 999]'),\n",
       " Text(192.30343988111244, 195.20181818181817, 'X[3034] <= 0.747\\ngini = 0.609\\nsamples = 855\\nvalue = [264, 151, 440]'),\n",
       " Text(183.76209365056388, 190.26, 'X[3678] <= 0.469\\ngini = 0.547\\nsamples = 700\\nvalue = [258, 51, 391]'),\n",
       " Text(176.3651987910338, 185.3181818181818, 'X[4062] <= 0.459\\ngini = 0.416\\nsamples = 415\\nvalue = [91, 21, 303]'),\n",
       " Text(171.25720667354074, 180.37636363636364, 'X[1386] <= 0.394\\ngini = 0.349\\nsamples = 369\\nvalue = [60, 18, 291]'),\n",
       " Text(166.84953570616096, 175.43454545454546, 'X[1563] <= 0.539\\ngini = 0.465\\nsamples = 159\\nvalue = [52, 3, 104]'),\n",
       " Text(164.50721863911534, 170.49272727272728, 'X[2347] <= 0.492\\ngini = 0.518\\nsamples = 105\\nvalue = [51, 2, 52]'),\n",
       " Text(162.10159570539278, 165.5509090909091, 'X[2647] <= 0.657\\ngini = 0.227\\nsamples = 32\\nvalue = [2, 2, 28]'),\n",
       " Text(161.08870183856226, 160.60909090909092, 'X[1974] <= 0.876\\ngini = 0.067\\nsamples = 29\\nvalue = [1, 0, 28]'),\n",
       " Text(160.58225490514698, 155.66727272727275, 'gini = 0.0\\nsamples = 28\\nvalue = [0, 0, 28]'),\n",
       " Text(161.59514877197753, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(163.11448957222333, 160.60909090909092, 'X[414] <= 0.469\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(162.60804263880806, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(163.6209365056386, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(166.91284157283786, 165.5509090909091, 'X[2474] <= 0.778\\ngini = 0.441\\nsamples = 73\\nvalue = [49, 0, 24]'),\n",
       " Text(165.6467242392997, 160.60909090909092, 'X[2138] <= 0.725\\ngini = 0.303\\nsamples = 59\\nvalue = [48, 0, 11]'),\n",
       " Text(164.63383037246913, 155.66727272727275, 'X[2730] <= 0.278\\ngini = 0.113\\nsamples = 50\\nvalue = [47, 0, 3]'),\n",
       " Text(164.1273834390539, 150.72545454545457, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(165.1402773058844, 150.72545454545457, 'gini = 0.0\\nsamples = 47\\nvalue = [47, 0, 0]'),\n",
       " Text(166.65961810613024, 155.66727272727275, 'X[911] <= 0.82\\ngini = 0.198\\nsamples = 9\\nvalue = [1, 0, 8]'),\n",
       " Text(166.15317117271496, 150.72545454545457, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(167.1660650395455, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(168.17895890637604, 160.60909090909092, 'X[411] <= 0.912\\ngini = 0.133\\nsamples = 14\\nvalue = [1, 0, 13]'),\n",
       " Text(167.67251197296076, 155.66727272727275, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 13]'),\n",
       " Text(168.68540583979131, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(169.1918527732066, 170.49272727272728, 'X[1437] <= 0.39\\ngini = 0.072\\nsamples = 54\\nvalue = [1, 1, 52]'),\n",
       " Text(168.68540583979131, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(169.69829970662184, 165.5509090909091, 'X[1706] <= 0.045\\ngini = 0.037\\nsamples = 53\\nvalue = [1, 0, 52]'),\n",
       " Text(169.1918527732066, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(170.20474664003711, 160.60909090909092, 'gini = 0.0\\nsamples = 52\\nvalue = [0, 0, 52]'),\n",
       " Text(175.6648776409205, 175.43454545454546, 'X[2843] <= 0.727\\ngini = 0.2\\nsamples = 210\\nvalue = [8, 15, 187]'),\n",
       " Text(173.40169290722102, 170.49272727272728, 'X[2017] <= 0.167\\ngini = 0.101\\nsamples = 190\\nvalue = [8, 2, 180]'),\n",
       " Text(171.72408744028294, 165.5509090909091, 'X[886] <= 0.073\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(171.21764050686767, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(172.2305343736982, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(175.0792983741591, 165.5509090909091, 'X[2934] <= 0.924\\ngini = 0.082\\nsamples = 188\\nvalue = [7, 1, 180]'),\n",
       " Text(173.24342824052874, 160.60909090909092, 'X[2128] <= 0.086\\ngini = 0.063\\nsamples = 185\\nvalue = [5, 1, 179]'),\n",
       " Text(171.09102877351384, 155.66727272727275, 'X[3432] <= 0.473\\ngini = 0.611\\nsamples = 6\\nvalue = [2, 1, 3]'),\n",
       " Text(170.58458184009856, 150.72545454545457, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(171.59747570692912, 150.72545454545457, 'X[363] <= 0.6\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(171.09102877351384, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(172.1039226403444, 145.78363636363636, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(175.39582770754365, 155.66727272727275, 'X[3871] <= 0.514\\ngini = 0.033\\nsamples = 179\\nvalue = [3, 0, 176]'),\n",
       " Text(174.12971037400547, 150.72545454545457, 'X[3350] <= 0.684\\ngini = 0.022\\nsamples = 177\\nvalue = [2, 0, 175]'),\n",
       " Text(173.11681650717492, 145.78363636363636, 'X[3001] <= 0.006\\ngini = 0.012\\nsamples = 172\\nvalue = [1, 0, 171]'),\n",
       " Text(172.61036957375964, 140.84181818181818, 'X[679] <= 0.604\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 0, 4]'),\n",
       " Text(172.1039226403444, 135.9, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(173.11681650717492, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(173.6232634405902, 140.84181818181818, 'gini = 0.0\\nsamples = 167\\nvalue = [0, 0, 167]'),\n",
       " Text(175.142604240836, 145.78363636363636, 'X[170] <= 0.661\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 0, 4]'),\n",
       " Text(174.63615730742075, 140.84181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(175.64905117425127, 140.84181818181818, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(176.66194504108182, 150.72545454545457, 'X[3819] <= 0.549\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(176.15549810766655, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(177.1683919744971, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(176.91516850778945, 160.60909090909092, 'X[3252] <= 0.994\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(176.40872157437417, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(177.42161544120472, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(177.92806237462, 170.49272727272728, 'X[639] <= 0.165\\ngini = 0.455\\nsamples = 20\\nvalue = [0, 13, 7]'),\n",
       " Text(177.42161544120472, 165.5509090909091, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(178.43450930803527, 165.5509090909091, 'X[2993] <= 0.922\\ngini = 0.133\\nsamples = 14\\nvalue = [0, 13, 1]'),\n",
       " Text(177.92806237462, 160.60909090909092, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 13, 0]'),\n",
       " Text(178.94095624145052, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(181.47319090852687, 180.37636363636364, 'X[1559] <= 0.504\\ngini = 0.474\\nsamples = 46\\nvalue = [31, 3, 12]'),\n",
       " Text(180.96674397511163, 175.43454545454546, 'X[1943] <= 0.424\\ngini = 0.317\\nsamples = 38\\nvalue = [31, 3, 4]'),\n",
       " Text(179.95385010828107, 170.49272727272728, 'X[3165] <= 0.547\\ngini = 0.48\\nsamples = 5\\nvalue = [0, 3, 2]'),\n",
       " Text(179.4474031748658, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(180.46029704169635, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(181.97963784194215, 170.49272727272728, 'X[1374] <= 0.349\\ngini = 0.114\\nsamples = 33\\nvalue = [31, 0, 2]'),\n",
       " Text(181.47319090852687, 165.5509090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(182.48608477535743, 165.5509090909091, 'gini = 0.0\\nsamples = 31\\nvalue = [31, 0, 0]'),\n",
       " Text(181.97963784194215, 175.43454545454546, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(191.15898851009393, 185.3181818181818, 'X[1303] <= 0.52\\ngini = 0.55\\nsamples = 285\\nvalue = [167, 30, 88]'),\n",
       " Text(187.67716584286396, 180.37636363636364, 'X[1878] <= 0.665\\ngini = 0.362\\nsamples = 196\\nvalue = [150, 1, 45]'),\n",
       " Text(185.77798984255668, 175.43454545454546, 'X[2602] <= 0.722\\ngini = 0.219\\nsamples = 161\\nvalue = [141, 1, 19]'),\n",
       " Text(184.00542557560325, 170.49272727272728, 'X[3315] <= 0.033\\ngini = 0.072\\nsamples = 133\\nvalue = [128, 0, 5]'),\n",
       " Text(183.49897864218798, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(184.5118725090185, 165.5509090909091, 'X[2832] <= 0.869\\ngini = 0.03\\nsamples = 130\\nvalue = [128, 0, 2]'),\n",
       " Text(184.00542557560325, 160.60909090909092, 'X[1239] <= 0.094\\ngini = 0.015\\nsamples = 129\\nvalue = [128, 0, 1]'),\n",
       " Text(183.49897864218798, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(184.5118725090185, 155.66727272727275, 'gini = 0.0\\nsamples = 128\\nvalue = [128, 0, 0]'),\n",
       " Text(185.01831944243378, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(187.55055410951013, 170.49272727272728, 'X[1164] <= 0.345\\ngini = 0.533\\nsamples = 28\\nvalue = [13, 1, 14]'),\n",
       " Text(186.5376602426796, 165.5509090909091, 'X[2332] <= 0.298\\ngini = 0.24\\nsamples = 15\\nvalue = [1, 1, 13]'),\n",
       " Text(186.03121330926433, 160.60909090909092, 'X[3009] <= 0.231\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(185.52476637584905, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(186.5376602426796, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(187.04410717609485, 160.60909090909092, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 13]'),\n",
       " Text(188.56344797634068, 165.5509090909091, 'X[2145] <= 0.486\\ngini = 0.142\\nsamples = 13\\nvalue = [12, 0, 1]'),\n",
       " Text(188.0570010429254, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(189.06989490975596, 160.60909090909092, 'gini = 0.0\\nsamples = 12\\nvalue = [12, 0, 0]'),\n",
       " Text(189.5763418431712, 175.43454545454546, 'X[2850] <= 0.345\\ngini = 0.382\\nsamples = 35\\nvalue = [9, 0, 26]'),\n",
       " Text(189.06989490975596, 170.49272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(190.08278877658648, 170.49272727272728, 'X[4063] <= 0.537\\ngini = 0.185\\nsamples = 29\\nvalue = [3, 0, 26]'),\n",
       " Text(189.5763418431712, 165.5509090909091, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 0, 26]'),\n",
       " Text(190.58923571000176, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(194.6408111773239, 180.37636363636364, 'X[1959] <= 0.471\\ngini = 0.624\\nsamples = 89\\nvalue = [17, 29, 43]'),\n",
       " Text(193.1214703770781, 175.43454545454546, 'X[3613] <= 0.553\\ngini = 0.427\\nsamples = 41\\nvalue = [1, 29, 11]'),\n",
       " Text(192.10857651024756, 170.49272727272728, 'X[1878] <= 0.202\\ngini = 0.355\\nsamples = 13\\nvalue = [0, 3, 10]'),\n",
       " Text(191.6021295768323, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(192.61502344366284, 165.5509090909091, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 0, 10]'),\n",
       " Text(194.13436424390866, 170.49272727272728, 'X[1367] <= 0.38\\ngini = 0.135\\nsamples = 28\\nvalue = [1, 26, 1]'),\n",
       " Text(193.6279173104934, 165.5509090909091, 'X[3520] <= 0.1\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(193.1214703770781, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(194.13436424390866, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(194.6408111773239, 165.5509090909091, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 26, 0]'),\n",
       " Text(196.16015197756974, 175.43454545454546, 'X[2329] <= 0.592\\ngini = 0.444\\nsamples = 48\\nvalue = [16, 0, 32]'),\n",
       " Text(195.65370504415446, 170.49272727272728, 'gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(196.66659891098502, 170.49272727272728, 'X[1494] <= 0.267\\ngini = 0.32\\nsamples = 40\\nvalue = [8, 0, 32]'),\n",
       " Text(195.65370504415446, 165.5509090909091, 'X[4047] <= 0.139\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 0, 1]'),\n",
       " Text(195.1472581107392, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(196.16015197756974, 160.60909090909092, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(197.67949277781554, 165.5509090909091, 'X[3206] <= 0.841\\ngini = 0.114\\nsamples = 33\\nvalue = [2, 0, 31]'),\n",
       " Text(197.17304584440026, 160.60909090909092, 'X[62] <= 0.043\\ngini = 0.061\\nsamples = 32\\nvalue = [1, 0, 31]'),\n",
       " Text(196.66659891098502, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(197.67949277781554, 155.66727272727275, 'gini = 0.0\\nsamples = 31\\nvalue = [0, 0, 31]'),\n",
       " Text(198.18593971123082, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(200.844786111661, 190.26, 'X[1436] <= 0.551\\ngini = 0.482\\nsamples = 155\\nvalue = [6, 100, 49]'),\n",
       " Text(198.6923866446461, 185.3181818181818, 'X[1565] <= 0.625\\ngini = 0.31\\nsamples = 39\\nvalue = [4, 3, 32]'),\n",
       " Text(197.67949277781554, 180.37636363636364, 'X[1531] <= 0.839\\ngini = 0.062\\nsamples = 31\\nvalue = [0, 1, 30]'),\n",
       " Text(197.17304584440026, 175.43454545454546, 'gini = 0.0\\nsamples = 30\\nvalue = [0, 0, 30]'),\n",
       " Text(198.18593971123082, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(199.70528051147662, 180.37636363636364, 'X[792] <= 0.567\\ngini = 0.625\\nsamples = 8\\nvalue = [4, 2, 2]'),\n",
       " Text(199.19883357806137, 175.43454545454546, 'X[1101] <= 0.367\\ngini = 0.5\\nsamples = 4\\nvalue = [0, 2, 2]'),\n",
       " Text(198.6923866446461, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(199.70528051147662, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(200.2117274448919, 175.43454545454546, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(202.9971855786759, 185.3181818181818, 'X[1882] <= 0.596\\ngini = 0.279\\nsamples = 116\\nvalue = [2, 97, 17]'),\n",
       " Text(201.73106824513772, 180.37636363636364, 'X[2214] <= 0.935\\ngini = 0.023\\nsamples = 85\\nvalue = [0, 84, 1]'),\n",
       " Text(201.22462131172244, 175.43454545454546, 'gini = 0.0\\nsamples = 84\\nvalue = [0, 84, 0]'),\n",
       " Text(202.23751517855297, 175.43454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(204.26330291221407, 180.37636363636364, 'X[3034] <= 0.794\\ngini = 0.554\\nsamples = 31\\nvalue = [2, 13, 16]'),\n",
       " Text(203.25040904538352, 175.43454545454546, 'X[3363] <= 0.443\\ngini = 0.255\\nsamples = 14\\nvalue = [1, 12, 1]'),\n",
       " Text(202.74396211196824, 170.49272727272728, 'X[2498] <= 0.394\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(202.23751517855297, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(203.25040904538352, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(203.7568559787988, 170.49272727272728, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 12, 0]'),\n",
       " Text(205.2761967790446, 175.43454545454546, 'X[2367] <= 0.125\\ngini = 0.215\\nsamples = 17\\nvalue = [1, 1, 15]'),\n",
       " Text(204.76974984562932, 170.49272727272728, 'X[262] <= 0.506\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(204.26330291221407, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(205.2761967790446, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(205.78264371245987, 170.49272727272728, 'gini = 0.0\\nsamples = 15\\nvalue = [0, 0, 15]'),\n",
       " Text(235.63778935270676, 195.20181818181817, 'X[1580] <= 0.48\\ngini = 0.33\\nsamples = 3385\\nvalue = [2712, 114, 559]'),\n",
       " Text(217.71579958105718, 190.26, 'X[1896] <= 0.394\\ngini = 0.204\\nsamples = 2585\\nvalue = [2291, 25, 269]'),\n",
       " Text(211.1003365133202, 185.3181818181818, 'X[2721] <= 0.598\\ngini = 0.587\\nsamples = 196\\nvalue = [98, 22, 76]'),\n",
       " Text(209.07454877965912, 180.37636363636364, 'X[3238] <= 0.755\\ngini = 0.402\\nsamples = 109\\nvalue = [82, 11, 16]'),\n",
       " Text(208.56810184624385, 175.43454545454546, 'X[1759] <= 0.371\\ngini = 0.315\\nsamples = 101\\nvalue = [82, 3, 16]'),\n",
       " Text(206.79553757929042, 170.49272727272728, 'X[1550] <= 0.49\\ngini = 0.314\\nsamples = 11\\nvalue = [1, 1, 9]'),\n",
       " Text(206.28909064587515, 165.5509090909091, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(207.30198451270567, 165.5509090909091, 'X[1099] <= 0.592\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(206.79553757929042, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(207.80843144612095, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(210.3406661131973, 170.49272727272728, 'X[3612] <= 0.745\\ngini = 0.183\\nsamples = 90\\nvalue = [81, 2, 7]'),\n",
       " Text(209.83421917978202, 165.5509090909091, 'X[2605] <= 0.735\\ngini = 0.131\\nsamples = 87\\nvalue = [81, 2, 4]'),\n",
       " Text(208.8213253129515, 160.60909090909092, 'X[216] <= 0.1\\ngini = 0.069\\nsamples = 84\\nvalue = [81, 0, 3]'),\n",
       " Text(208.31487837953622, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(209.32777224636678, 155.66727272727275, 'X[2452] <= 0.304\\ngini = 0.024\\nsamples = 82\\nvalue = [81, 0, 1]'),\n",
       " Text(208.8213253129515, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(209.83421917978202, 150.72545454545457, 'gini = 0.0\\nsamples = 81\\nvalue = [81, 0, 0]'),\n",
       " Text(210.84711304661258, 160.60909090909092, 'X[709] <= 0.224\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(210.3406661131973, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(211.35355998002785, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(210.84711304661258, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(209.5809957130744, 175.43454545454546, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8, 0]'),\n",
       " Text(213.1261242469813, 180.37636363636364, 'X[3045] <= 0.49\\ngini = 0.475\\nsamples = 87\\nvalue = [16, 11, 60]'),\n",
       " Text(211.86000691344313, 175.43454545454546, 'X[289] <= 0.471\\ngini = 0.26\\nsamples = 13\\nvalue = [11, 0, 2]'),\n",
       " Text(211.35355998002785, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(212.36645384685838, 170.49272727272728, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0]'),\n",
       " Text(214.39224158051948, 175.43454545454546, 'X[744] <= 0.4\\ngini = 0.359\\nsamples = 74\\nvalue = [5, 11, 58]'),\n",
       " Text(213.37934771368893, 170.49272727272728, 'X[1769] <= 0.355\\ngini = 0.444\\nsamples = 15\\nvalue = [0, 10, 5]'),\n",
       " Text(212.87290078027365, 165.5509090909091, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(213.8857946471042, 165.5509090909091, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 10, 0]'),\n",
       " Text(215.40513544735, 170.49272727272728, 'X[3291] <= 0.429\\ngini = 0.186\\nsamples = 59\\nvalue = [5, 1, 53]'),\n",
       " Text(214.89868851393473, 165.5509090909091, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(215.91158238076528, 165.5509090909091, 'X[895] <= 0.002\\ngini = 0.071\\nsamples = 55\\nvalue = [1, 1, 53]'),\n",
       " Text(215.40513544735, 160.60909090909092, 'X[1037] <= 0.659\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(214.89868851393473, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(215.91158238076528, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(216.41802931418056, 160.60909090909092, 'gini = 0.0\\nsamples = 53\\nvalue = [0, 0, 53]'),\n",
       " Text(224.33126264879417, 185.3181818181818, 'X[2350] <= 0.382\\ngini = 0.151\\nsamples = 2389\\nvalue = [2193, 3, 193]'),\n",
       " Text(217.93737011442636, 180.37636363636364, 'X[1630] <= 0.486\\ngini = 0.372\\nsamples = 34\\nvalue = [7, 1, 26]'),\n",
       " Text(216.92447624759583, 175.43454545454546, 'X[1992] <= 0.247\\ngini = 0.375\\nsamples = 8\\nvalue = [6, 0, 2]'),\n",
       " Text(216.41802931418056, 170.49272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(217.43092318101108, 170.49272727272728, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(218.9502639812569, 175.43454545454546, 'X[43] <= 0.061\\ngini = 0.145\\nsamples = 26\\nvalue = [1, 1, 24]'),\n",
       " Text(218.44381704784163, 170.49272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(219.4567109146722, 170.49272727272728, 'X[3880] <= 0.118\\ngini = 0.077\\nsamples = 25\\nvalue = [1, 0, 24]'),\n",
       " Text(218.9502639812569, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(219.96315784808743, 165.5509090909091, 'gini = 0.0\\nsamples = 24\\nvalue = [0, 0, 24]'),\n",
       " Text(230.72515518316195, 180.37636363636364, 'X[2586] <= 0.845\\ngini = 0.133\\nsamples = 2355\\nvalue = [2186, 2, 167]'),\n",
       " Text(226.0405210490707, 175.43454545454546, 'X[1695] <= 0.471\\ngini = 0.112\\nsamples = 2296\\nvalue = [2160, 1, 135]'),\n",
       " Text(221.98894558174854, 170.49272727272728, 'X[2590] <= 0.482\\ngini = 0.458\\nsamples = 90\\nvalue = [58, 0, 32]'),\n",
       " Text(220.976051714918, 165.5509090909091, 'X[2722] <= 0.643\\ngini = 0.124\\nsamples = 45\\nvalue = [42, 0, 3]'),\n",
       " Text(220.4696047815027, 160.60909090909092, 'gini = 0.0\\nsamples = 42\\nvalue = [42, 0, 0]'),\n",
       " Text(221.48249864833326, 160.60909090909092, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(223.00183944857906, 165.5509090909091, 'X[2923] <= 0.606\\ngini = 0.458\\nsamples = 45\\nvalue = [16, 0, 29]'),\n",
       " Text(222.4953925151638, 160.60909090909092, 'X[2123] <= 0.437\\ngini = 0.483\\nsamples = 27\\nvalue = [16, 0, 11]'),\n",
       " Text(221.98894558174854, 155.66727272727275, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(223.00183944857906, 155.66727272727275, 'X[1191] <= 0.386\\ngini = 0.266\\nsamples = 19\\nvalue = [16, 0, 3]'),\n",
       " Text(222.4953925151638, 150.72545454545457, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(223.50828638199434, 150.72545454545457, 'gini = 0.0\\nsamples = 16\\nvalue = [16, 0, 0]'),\n",
       " Text(223.50828638199434, 160.60909090909092, 'gini = 0.0\\nsamples = 18\\nvalue = [0, 0, 18]'),\n",
       " Text(230.09209651639284, 170.49272727272728, 'X[2803] <= 0.861\\ngini = 0.09\\nsamples = 2206\\nvalue = [2102, 1, 103]'),\n",
       " Text(227.5598618493165, 165.5509090909091, 'X[2157] <= 0.357\\ngini = 0.077\\nsamples = 2166\\nvalue = [2079, 1, 86]'),\n",
       " Text(227.05341491590124, 160.60909090909092, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(228.06630878273177, 160.60909090909092, 'X[1897] <= 0.865\\ngini = 0.073\\nsamples = 2161\\nvalue = [2079, 1, 81]'),\n",
       " Text(226.0405210490707, 155.66727272727275, 'X[2449] <= 0.406\\ngini = 0.064\\nsamples = 2132\\nvalue = [2062, 1, 69]'),\n",
       " Text(224.5211802488249, 150.72545454545457, 'X[1206] <= 0.492\\ngini = 0.568\\nsamples = 13\\nvalue = [6, 1, 6]'),\n",
       " Text(224.01473331540961, 145.78363636363636, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(225.02762718224014, 145.78363636363636, 'X[530] <= 0.251\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1, 0]'),\n",
       " Text(224.5211802488249, 140.84181818181818, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(225.53407411565541, 140.84181818181818, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(227.5598618493165, 150.72545454545457, 'X[1816] <= 0.9\\ngini = 0.058\\nsamples = 2119\\nvalue = [2056, 0, 63]'),\n",
       " Text(227.05341491590124, 145.78363636363636, 'X[3672] <= 0.071\\ngini = 0.055\\nsamples = 2116\\nvalue = [2056, 0, 60]'),\n",
       " Text(226.54696798248597, 140.84181818181818, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(227.5598618493165, 140.84181818181818, 'X[3223] <= 0.696\\ngini = 0.052\\nsamples = 2113\\nvalue = [2056, 0, 57]'),\n",
       " Text(225.4074623823016, 135.9, 'X[2261] <= 0.943\\ngini = 0.037\\nsamples = 2004\\nvalue = [1966, 0, 38]'),\n",
       " Text(224.39456851547106, 130.95818181818183, 'X[3685] <= 0.916\\ngini = 0.034\\nsamples = 2000\\nvalue = [1965, 0, 35]'),\n",
       " Text(223.8881215820558, 126.01636363636364, 'X[1487] <= 0.798\\ngini = 0.032\\nsamples = 1998\\nvalue = [1965, 0, 33]'),\n",
       " Text(222.4953925151638, 121.07454545454546, 'X[310] <= 0.927\\ngini = 0.03\\nsamples = 1992\\nvalue = [1962, 0, 30]'),\n",
       " Text(221.2292751816256, 116.13272727272728, 'X[2088] <= 0.951\\ngini = 0.028\\nsamples = 1989\\nvalue = [1961, 0, 28]'),\n",
       " Text(220.2163813147951, 111.1909090909091, 'X[1576] <= 0.027\\ngini = 0.026\\nsamples = 1986\\nvalue = [1960, 0, 26]'),\n",
       " Text(219.7099343813798, 106.24909090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(220.72282824821036, 106.24909090909091, 'X[2218] <= 0.316\\ngini = 0.025\\nsamples = 1985\\nvalue = [1960, 0, 25]'),\n",
       " Text(220.2163813147951, 101.30727272727273, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(221.2292751816256, 101.30727272727273, 'X[1707] <= 0.016\\ngini = 0.024\\nsamples = 1984\\nvalue = [1960, 0, 24]'),\n",
       " Text(220.72282824821036, 96.36545454545455, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(221.7357221150409, 96.36545454545455, 'X[1635] <= 0.041\\ngini = 0.023\\nsamples = 1983\\nvalue = [1960, 0, 23]'),\n",
       " Text(221.2292751816256, 91.42363636363638, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(222.24216904845616, 91.42363636363638, 'X[1062] <= 0.049\\ngini = 0.022\\nsamples = 1982\\nvalue = [1960, 0, 22]'),\n",
       " Text(221.7357221150409, 86.4818181818182, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(222.74861598187144, 86.4818181818182, 'X[71] <= 0.994\\ngini = 0.021\\nsamples = 1981\\nvalue = [1960, 0, 21]'),\n",
       " Text(222.24216904845616, 81.54000000000002, 'X[2348] <= 0.449\\ngini = 0.02\\nsamples = 1980\\nvalue = [1960, 0, 20]'),\n",
       " Text(220.469790247909, 76.59818181818181, 'X[286] <= 0.757\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 0, 2]'),\n",
       " Text(219.96334331449373, 71.65636363636364, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(220.97623718132425, 71.65636363636364, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(224.01454784900332, 76.59818181818181, 'X[197] <= 0.943\\ngini = 0.018\\nsamples = 1975\\nvalue = [1957, 0, 18]'),\n",
       " Text(221.9891310481548, 71.65636363636364, 'X[943] <= 0.037\\ngini = 0.014\\nsamples = 1951\\nvalue = [1937, 0, 14]'),\n",
       " Text(220.4700375364507, 66.71454545454546, 'X[1960] <= 0.757\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(219.96359060303544, 61.77272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(220.97648446986597, 61.77272727272728, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(223.50822455985892, 66.71454545454546, 'X[1387] <= 0.02\\ngini = 0.013\\nsamples = 1949\\nvalue = [1936, 0, 13]'),\n",
       " Text(221.98937833669652, 61.77272727272728, 'X[3587] <= 0.369\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(221.48293140328124, 56.8309090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(222.4958252701118, 56.8309090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(225.02707078302132, 61.77272727272728, 'X[2731] <= 0.229\\ngini = 0.012\\nsamples = 1947\\nvalue = [1935, 0, 12]'),\n",
       " Text(223.50871913694232, 56.8309090909091, 'X[1278] <= 0.729\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(223.00227220352704, 51.889090909090925, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(224.0151660703576, 51.889090909090925, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(226.54542242910028, 56.8309090909091, 'X[1941] <= 0.308\\ngini = 0.011\\nsamples = 1945\\nvalue = [1934, 0, 11]'),\n",
       " Text(225.02805993718815, 51.889090909090925, 'X[1212] <= 0.369\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(224.52161300377287, 46.94727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(225.5345068706034, 46.94727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(228.06278492101245, 51.889090909090925, 'X[319] <= 0.99\\ngini = 0.01\\nsamples = 1943\\nvalue = [1933, 0, 10]'),\n",
       " Text(226.54740073743395, 46.94727272727275, 'X[45] <= 0.002\\ngini = 0.008\\nsamples = 1935\\nvalue = [1927, 0, 8]'),\n",
       " Text(225.03597317052274, 42.00545454545457, 'X[895] <= 0.188\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(224.5295262371075, 37.06363636363636, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(225.542420103938, 37.06363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(228.05882830434516, 42.00545454545457, 'X[3123] <= 0.876\\ngini = 0.007\\nsamples = 1932\\nvalue = [1925, 0, 7]'),\n",
       " Text(226.55531397076857, 37.06363636363636, 'X[2638] <= 0.873\\ngini = 0.006\\nsamples = 1929\\nvalue = [1923, 0, 6]'),\n",
       " Text(225.06762610386122, 32.121818181818185, 'X[3337] <= 0.002\\ngini = 0.005\\nsamples = 1926\\nvalue = [1921, 0, 5]'),\n",
       " Text(223.61159117029231, 27.180000000000007, 'X[2890] <= 0.239\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(223.10514423687704, 22.23818181818183, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(224.11803810370756, 22.23818181818183, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(226.52366103743012, 27.180000000000007, 'X[16] <= 0.01\\ngini = 0.004\\nsamples = 1922\\nvalue = [1918, 0, 4]'),\n",
       " Text(225.13093197053811, 22.23818181818183, 'X[3055] <= 0.675\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 0, 1]'),\n",
       " Text(224.62448503712284, 17.29636363636365, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(225.6373789039534, 17.29636363636365, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(227.9163901043221, 22.23818181818183, 'X[1708] <= 0.796\\ngini = 0.003\\nsamples = 1917\\nvalue = [1914, 0, 3]'),\n",
       " Text(226.65027277078391, 17.29636363636365, 'X[1456] <= 0.796\\ngini = 0.002\\nsamples = 1909\\nvalue = [1907, 0, 2]'),\n",
       " Text(225.6373789039534, 12.354545454545473, 'X[2429] <= 0.018\\ngini = 0.001\\nsamples = 1899\\nvalue = [1898, 0, 1]'),\n",
       " Text(225.13093197053811, 7.412727272727295, 'X[3061] <= 0.69\\ngini = 0.042\\nsamples = 47\\nvalue = [46, 0, 1]'),\n",
       " Text(224.62448503712284, 2.4709090909091174, 'gini = 0.0\\nsamples = 46\\nvalue = [46, 0, 0]'),\n",
       " Text(225.6373789039534, 2.4709090909091174, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(226.14382583736867, 7.412727272727295, 'gini = 0.0\\nsamples = 1852\\nvalue = [1852, 0, 0]'),\n",
       " Text(227.66316663761447, 12.354545454545473, 'X[2420] <= 0.743\\ngini = 0.18\\nsamples = 10\\nvalue = [9, 0, 1]'),\n",
       " Text(227.1567197041992, 7.412727272727295, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(228.16961357102974, 7.412727272727295, 'gini = 0.0\\nsamples = 9\\nvalue = [9, 0, 0]'),\n",
       " Text(229.18250743786027, 17.29636363636365, 'X[1196] <= 0.324\\ngini = 0.219\\nsamples = 8\\nvalue = [7, 0, 1]'),\n",
       " Text(228.67606050444502, 12.354545454545473, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(229.68895437127554, 12.354545454545473, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(228.04300183767592, 32.121818181818185, 'X[172] <= 0.447\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(227.53655490426064, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(228.5494487710912, 27.180000000000007, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(229.56234263792172, 37.06363636363636, 'X[3153] <= 0.661\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(229.05589570450647, 32.121818181818185, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(230.068789571337, 32.121818181818185, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(229.57816910459096, 46.94727272727275, 'X[2461] <= 0.735\\ngini = 0.375\\nsamples = 8\\nvalue = [6, 0, 2]'),\n",
       " Text(229.07172217117568, 42.00545454545457, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(230.08461603800623, 42.00545454545457, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(226.03996464985184, 71.65636363636364, 'X[3289] <= 0.602\\ngini = 0.278\\nsamples = 24\\nvalue = [20, 0, 4]'),\n",
       " Text(225.5335177164366, 66.71454545454546, 'gini = 0.0\\nsamples = 18\\nvalue = [18, 0, 0]'),\n",
       " Text(226.54641158326712, 66.71454545454546, 'X[3169] <= 0.467\\ngini = 0.444\\nsamples = 6\\nvalue = [2, 0, 4]'),\n",
       " Text(226.03996464985184, 61.77272727272728, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(227.0528585166824, 61.77272727272728, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(223.25506291528671, 81.54000000000002, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(222.24216904845616, 111.1909090909091, 'X[1591] <= 0.329\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(221.7357221150409, 106.24909090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(222.74861598187144, 106.24909090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(223.76150984870196, 116.13272727272728, 'X[2865] <= 0.586\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(223.25506291528671, 111.1909090909091, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(224.26795678211724, 111.1909090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(225.2808506489478, 121.07454545454546, 'X[3404] <= 0.753\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 0, 3]'),\n",
       " Text(224.77440371553251, 116.13272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(225.78729758236307, 116.13272727272728, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(224.90101544888634, 126.01636363636364, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(226.42035624913214, 130.95818181818183, 'X[1295] <= 0.708\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(225.91390931571686, 126.01636363636364, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(226.92680318254742, 126.01636363636364, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(229.7122613163314, 135.9, 'X[1116] <= 0.647\\ngini = 0.288\\nsamples = 109\\nvalue = [90, 0, 19]'),\n",
       " Text(228.44614398279322, 130.95818181818183, 'X[4073] <= 0.278\\ngini = 0.36\\nsamples = 17\\nvalue = [4, 0, 13]'),\n",
       " Text(227.93969704937794, 126.01636363636364, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(228.9525909162085, 126.01636363636364, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 0, 13]'),\n",
       " Text(230.97837864986957, 130.95818181818183, 'X[2248] <= 0.775\\ngini = 0.122\\nsamples = 92\\nvalue = [86, 0, 6]'),\n",
       " Text(229.96548478303905, 126.01636363636364, 'X[1944] <= 0.559\\ngini = 0.045\\nsamples = 87\\nvalue = [85, 0, 2]'),\n",
       " Text(229.45903784962377, 121.07454545454546, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(230.4719317164543, 121.07454545454546, 'gini = 0.0\\nsamples = 85\\nvalue = [85, 0, 0]'),\n",
       " Text(231.99127251670012, 126.01636363636364, 'X[3262] <= 0.086\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 0, 4]'),\n",
       " Text(231.48482558328485, 121.07454545454546, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(232.4977194501154, 121.07454545454546, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(228.06630878273177, 145.78363636363636, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(230.09209651639284, 155.66727272727275, 'X[3999] <= 0.765\\ngini = 0.485\\nsamples = 29\\nvalue = [17, 0, 12]'),\n",
       " Text(229.5856495829776, 150.72545454545457, 'X[3929] <= 0.231\\ngini = 0.142\\nsamples = 13\\nvalue = [1, 0, 12]'),\n",
       " Text(229.07920264956232, 145.78363636363636, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(230.09209651639284, 145.78363636363636, 'gini = 0.0\\nsamples = 12\\nvalue = [0, 0, 12]'),\n",
       " Text(230.59854344980812, 150.72545454545457, 'gini = 0.0\\nsamples = 16\\nvalue = [16, 0, 0]'),\n",
       " Text(232.6243311834692, 165.5509090909091, 'X[3356] <= 0.59\\ngini = 0.489\\nsamples = 40\\nvalue = [23, 0, 17]'),\n",
       " Text(231.61143731663867, 160.60909090909092, 'X[2419] <= 0.765\\ngini = 0.1\\nsamples = 19\\nvalue = [18, 0, 1]'),\n",
       " Text(231.1049903832234, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(232.11788425005395, 155.66727272727275, 'gini = 0.0\\nsamples = 18\\nvalue = [18, 0, 0]'),\n",
       " Text(233.63722505029975, 160.60909090909092, 'X[1317] <= 0.675\\ngini = 0.363\\nsamples = 21\\nvalue = [5, 0, 16]'),\n",
       " Text(233.13077811688447, 155.66727272727275, 'X[2337] <= 0.584\\ngini = 0.111\\nsamples = 17\\nvalue = [1, 0, 16]'),\n",
       " Text(232.6243311834692, 150.72545454545457, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(233.63722505029975, 150.72545454545457, 'gini = 0.0\\nsamples = 16\\nvalue = [0, 0, 16]'),\n",
       " Text(234.14367198371502, 155.66727272727275, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(235.4097893172532, 175.43454545454546, 'X[1629] <= 0.68\\ngini = 0.511\\nsamples = 59\\nvalue = [26, 1, 32]'),\n",
       " Text(234.14367198371502, 170.49272727272728, 'X[990] <= 0.882\\ngini = 0.231\\nsamples = 30\\nvalue = [4, 0, 26]'),\n",
       " Text(233.63722505029975, 165.5509090909091, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 0, 26]'),\n",
       " Text(234.6501189171303, 165.5509090909091, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(236.67590665079138, 170.49272727272728, 'X[3930] <= 0.575\\ngini = 0.38\\nsamples = 29\\nvalue = [22, 1, 6]'),\n",
       " Text(235.66301278396082, 165.5509090909091, 'X[875] <= 0.551\\ngini = 0.278\\nsamples = 6\\nvalue = [0, 1, 5]'),\n",
       " Text(235.15656585054555, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(236.1694597173761, 160.60909090909092, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(237.6888005176219, 165.5509090909091, 'X[2722] <= 0.267\\ngini = 0.083\\nsamples = 23\\nvalue = [22, 0, 1]'),\n",
       " Text(237.18235358420665, 160.60909090909092, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(238.19524745103718, 160.60909090909092, 'gini = 0.0\\nsamples = 22\\nvalue = [22, 0, 0]'),\n",
       " Text(253.5597791243563, 190.26, 'X[1385] <= 0.606\\ngini = 0.579\\nsamples = 800\\nvalue = [421, 89, 290]'),\n",
       " Text(243.3645671268735, 185.3181818181818, 'X[999] <= 0.508\\ngini = 0.44\\nsamples = 472\\nvalue = [329, 15, 128]'),\n",
       " Text(239.46136478457535, 180.37636363636364, 'X[3159] <= 0.476\\ngini = 0.47\\nsamples = 86\\nvalue = [23, 5, 58]'),\n",
       " Text(238.19524745103718, 175.43454545454546, 'X[965] <= 0.416\\ngini = 0.308\\nsamples = 21\\nvalue = [17, 0, 4]'),\n",
       " Text(237.6888005176219, 170.49272727272728, 'gini = 0.0\\nsamples = 17\\nvalue = [17, 0, 0]'),\n",
       " Text(238.70169438445245, 170.49272727272728, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(240.72748211811353, 175.43454545454546, 'X[1579] <= 0.414\\ngini = 0.295\\nsamples = 65\\nvalue = [6, 5, 54]'),\n",
       " Text(239.714588251283, 170.49272727272728, 'X[2138] <= 0.606\\ngini = 0.49\\nsamples = 7\\nvalue = [4, 3, 0]'),\n",
       " Text(239.20814131786773, 165.5509090909091, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(240.22103518469825, 165.5509090909091, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(241.74037598494408, 170.49272727272728, 'X[64] <= 0.057\\ngini = 0.131\\nsamples = 58\\nvalue = [2, 2, 54]'),\n",
       " Text(241.2339290515288, 165.5509090909091, 'X[2386] <= 0.514\\ngini = 0.64\\nsamples = 5\\nvalue = [2, 2, 1]'),\n",
       " Text(240.72748211811353, 160.60909090909092, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(241.74037598494408, 160.60909090909092, 'X[2246] <= 0.512\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 0, 1]'),\n",
       " Text(241.2339290515288, 155.66727272727275, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(242.24682291835936, 155.66727272727275, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(242.24682291835936, 165.5509090909091, 'gini = 0.0\\nsamples = 53\\nvalue = [0, 0, 53]'),\n",
       " Text(247.26776946917167, 180.37636363636364, 'X[2002] <= 0.437\\ngini = 0.338\\nsamples = 386\\nvalue = [306, 10, 70]'),\n",
       " Text(243.25971678518988, 175.43454545454546, 'X[1235] <= 0.296\\ngini = 0.354\\nsamples = 32\\nvalue = [6, 1, 25]'),\n",
       " Text(242.7532698517746, 170.49272727272728, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(243.76616371860516, 170.49272727272728, 'X[2391] <= 0.3\\ngini = 0.14\\nsamples = 27\\nvalue = [1, 1, 25]'),\n",
       " Text(243.25971678518988, 165.5509090909091, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(244.27261065202043, 165.5509090909091, 'X[3351] <= 0.753\\ngini = 0.074\\nsamples = 26\\nvalue = [0, 1, 25]'),\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAADoCAYAAAA33PUJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABFZElEQVR4nO19S3BbR7red0CQOKAgiqD4AEmQAB+mKM9Q8mvG1lgP7pIq75KpSVYp1d3eqlR22aSySDY361t3UsnKyiKrmVRFu1vZSBZlyR7bI48t62GaBiGIAmkSFCmKOIQgnizIPmo0uvv0OQCIA7C/KhSBg378/Xefn43/O//fhm3b0NDQ0NAIBkLNFkBDQ0ND4w20UdbQ0NAIELRR1tDQ0AgQtFHW0NDQCBC0UdbQ0NAIELRR1tDQ0AgQtFFuI0Sj0bxhGLafVzQazTdbfg0NDcDQzym3DwzDsMl83r59G4ZhIBwO49WrV0in08jlcjh16hSi0SgymQxisRjef/99Uhe2bRvNlF9DQ0Mb5ZaHYRhdAOKHrwdkPjc3N3H9+nVMTk4CADo7O2EYBzZ3ZmYG8XicbQcA+gBs2ba9f1Tya2hoVCLcbAE0AMMwonhjWNlXr+S7OIBOAJuHLwf3799HLBYDMdITExMol8tYX1/H3/72N5imiQ8//JAV5WcAMcMwXgB4TrUrerFlntu2Xa6HTjQ0jisCv1OORqN5y7KGvNYzTXO1WCwmGiETC+Ngm3kC3g0q+d6AuwEUGcKXxGdBuy98jAG2bRuGYXQAOKUgO298pwDsKsjM/d627ZIv4X3A77oCjnZtaRw/BN4o+zU0Xn2kh4a1B94NKnm9gndjtIkDY1T0PED+GOxMJoNcLodYLIb+/n4sLi4CAEKhELq7u2HbNl6+fIne3l48f/4c3d3dGBkZQTKZrNmnbBhGCMBJePvHRJcrQe0fUdX3XnVYj39gvipraLigpYzy7du30dXVhf39fZTL5QryKh6P4+HDh7hy5Qqp59w4hmF8AOB/APh/EBuJUwCKUDemFWVs295rsCpc0cq7v8N/ijF4M+L0ZxviuToD4C+2bf8nqj/btm3cvn0bfX19WFtbAwBMT087a2prawuhUAgnT57E7OwsLas2yhoNQ0v5lN9++23E43Fcu3YNAwMDWF9fh23b2Nrawu7urmOQORgAkACwDSAL8W7r1REMo2Fo5Z/Uh/95Xxy+nnipe2jQZX758wBOG4ZhAjiNA0ITwJs19eWXX1atKcuyMDMzg+HhYV6fcWhSVKMBaKmd8sLCAlZXVzEwMAAAOHPmjENePX/+HMPDw5iZmSH19G6mTWEYRgQHhpUYWPq97FoHgA0ABQC/cltXlmUhl8shnU4jlUrR/QPAFg529s8P29tg/orebwDY9u070Wh7NNwo+/lJTf+UrpdPuVY5WhlBJUsPH+djDaibge0D0AW50RNd260zKRrGwU5c9Z8Ced+Ng19nKgacvvaikcY8qOvkuKHhRtnP4mf8wfaNGzcc/zEhsHK5HEKhEAYHB5HJZNDb24vp6WksLi7Csix89NFHFUa5VjlaGY0mSw3D6MQbo+PFwJrwZpTI+51ajROPFM3lcrAsC+FwGIODg1hbW8Ovf/1r3Lt3DwAQDofx8ccf17wuDvUVx4EeaL246Y7WlxedKenrqEh1DTmOzCjfvn0b4XAYlmUBqCZULMviknR+/3tHIpE1up5hGPbCwgIMw0BHRwcsy6qQgRCFJ0+exHvvvVclRyuDJUs7Ojqwt7eHcDhcQZZubW0BODA+77//PvvP8V8B+COAG6g2HFEc7PxUf76Taw3d+cnQiqQo88vCyz8/8suC1v/7AP7Rtu3/RrXv3KtdXV0Ih8PY3t7m3ifJZBJTU1OkXlvcJ0HBkRnlzc3NCpJudHQUxWIRhmFUESqNmGTDMOxCoSCUoVwuI5lMVvkO22Gx0UaZF+kXCoVQLBarSC3GKF8B8F8A/HdU3+DaRxpgUD542lD/OwD/27btP1HlXO9VABgfHxeuE43acaTuCxGhkslkMDg4iLfeeovUaYhRtm1bShaGw2HEYjHHMLfLYlMlS8PhMDo7OzVZ2qY4NM7jAFLUK01/dlsn+XwesVgM3d3dGBsbI+0CwAKAZeaVAZCt13P4xwU1G2WVn4F+fLkykJ+PXn+C1lsOVh5PjXtELSSMZVlDtfgKNQFUO45Ch4ZhnESlwWUNbx+Ap3hjMFkjuuh3nQCYF/Q7hoMnVdi+HMNt2/aWal/HgbCv+TlltxveMAzcvHmziqj76aefYNs2EokE1tbWMD4+jlwu59RzaXNIpW9WjuXl5QoZdnZ20NPTg2w26xA84XDYcWW4ycHK00jUYFiHAHDn4OnTpygWi0gkEnj+/Dl6enqwv7+P9fV1mKZZt7416qNDwzBiAP4tDlxGaVQbQRPVBvdb6v0z27ZfS/qqukcWFxdhmibK5bLzS3JychJLS0vY2dlBInFg62zbviloMwRgiJHzLIB/ST4bhvEafIO9A2DFtu1vSXt+9Nhq67AuwSM0iceSRyMjI5ifn/fU3sjICJ4+fVpFQPX39zvkAtt/V1cXAGB3d5dLTIyOjiKdTnuW44svvqgiBXmpL48Kt2/fxv7+Pvb3D2IWeGMdGhqqiEAzTXN1fn7eF1nK6zsWi2F3d5dLEr5+/Rq/+93vahpju4PcL6FQCKVSiRuZShNpFP4DgP8K4P/ijeH6jHq/Xotv3zTN1XQ67Ws3L/ruMLjm2eHrLvv9YeBPHNW7+t/hYPddBjDI1pMR1kSHnZ2dLbkWa3ZfuBFoXV1dePfdd9k6Vb5K4vfktbG3t4d33nkHPT09FfXdiInu7m5sbm5idnYWQ0ND0v5ZOWSpLxOJxJETgiokzN7eHt566626kzDN7LtdoEK2AsDY2JjW4SEODTbofzSqDw7Mzc2hr6+P1GkpHdbl5JF4PI6FhQXEYjHEYjFsbW1hYmICyWQS29vb+OGHH5TbmpqaQrFYxNbWlrOLmJqawqNHj/DqFT8KWtT/6dOnEYvFsLi4iMePH3se09TUFNbW1mDbtiNLMpnE+vo6Hj165Km9ekGm6xMnTuCnn35qSt+nTp3C48ePPev5OMAwjF76M51W1bZtTExMYHR0FJFIBNlsFplMhq3ffYTiBgb2IXjf3b9/H3/+858xMTGBWCyGRCKBsbExmKYJ0zTx8uXLoxa3blDeKcsc7LUSaJFIBHt7e8rt0PVrICYq+qZRD0LQC7mgSl7UOlYeaDnrOceyvoNOvNQhCnUSwH8GsAfgYxz8HI/VoMNdAPcPX7Zt239Xi6ysvM1GUAh7gmbrRtmnLHKw88gBQuKl02lks9kKEu/jjz8GUKlYojS2nWw2i1AohHK5jNOnT2NjY6OivohEzOfzmJmZwQ8//ADLstDX1+f48GKxWEX/hz9tpOPJ5XKYnZ3F4uIidnZ2kE6nsb6+DsuyuOM5bEd5kamQF6KxLi4uIhwOo7+/H8+fP0e5XIZpmtjZ2cH09DRXNpGcXuY4k8mgXC47JGFvby/W1tYQDocxMjLiuHcE7QWaeKkDmfQHAP8GwH8E8D8B/A1ASTR/pmmiVCqhu7sb+/v7ePvtt/Hw4UOUy855Af0AfgPg7wD8C4PyhbQDCVsrYZ/L5VAqlTA+Po5MJoO+vj50dXVhfX3dE2FP9dFU3Xgm+lhSb2xszDOBlkwmHcWePHkSADA8PKzczsjIiEOGeCURSX1CJAIHY4rFYk5SIz/j+eKLLwC8iYbzAzo1KUsu+iFMgTdjXV9fx4kTJ7CysgLTNPHq1SvnHworQ0dHB0qlEmzbxvT0NEZGRjzrhPT98OFDbG1toa+vD69fv64gIIMOv4Scbdv/AOAf6GvRaNQ32WpZVhEHhN5nbvISQy4ivySZFJsK2drf2tpCuVxGT08PUqmU57WYSqUc3ZimyY3mjUajDmfVbCi7L1QIsLNnz1aQcTICkI7iI7tV8peU/+STT6RtGIZRQYzICEQRMXDhwgUUCgXumEKhENLpNAYHByEaeygUQjweR29vr/OgvUiWWnTLnqvnRlbyxhQKhXDq1ClMTk6is7Ozqh1RPcMwsL+/j+npaWeMvHoysvXcuXOO/EEnXlTJJJpAbtaY3AhEso5/85vfsPUCMwduDwuo3OeytmX3Vrlcxm9/+1vnfvDafiPgmejjkRTJZBKlUgkPHjyoKCsjhmKxWMVzyTQI2efWxt7eHvL5vJLconbIdzxSj+z06DbYcqlUCt3d3Xjy5ImzW/YLGbmYzWY9tS+SNRaL4auvvsJ3333nSYbx8XGsrKwICU4Z2RqJRPD48WM8eeIpTXLTIRoTeTaXJeSOGofPADsQ3ZuhUAg3b97E8vJys0R1hew+t20bKysrNbUv0k0sFsPdu3ebRtzzoLRTJo54j34ZT8QdvVP20wYpD1RH/LkFt6j4c2shF0zT3LcsS/oPsF5kqdf22HYaXY9Xl+CoCJZmRqF6kUHWzmEgyQs/sgKOvP9o2/a/9ytTLfPF9uX3PgcOfNKy8o2ey3pDyadMBs0jKjKZjPPoW2dnJ7a2thznOuuQ39jYcCLI8vk8ent7neczyX9xug9eGz///DOmpqbw+PFjvPPOO7h37x6mp6cxOjoKwCEAh9zkzuVyGB8f5/ZRKBScsRAfKK+NlZUVDA4OIp/PY2RkBOvr6yiVSlXkgmEYIbd/DCIZATj6SqfTePjwIcLhcEX7pA2avORFZg0NDWF1dRXpdBr5fJ6OxhLWy+VySCQSFbtC4pd0qzc+Po5CoYDx8XF888036OrqcnTeTAJQ5R81O561tTWUSiXnbMOenh7s7u7i5cuXUlKTarNibLUSdLZt7xiG8a8B/Jmne9M0EQqF0NnZib29PUxPT+P7778HAPoZ+/9Vi0y1zBfdl4hI7u7uxqtXrzA2NoZsNotkMsm9z73OJSEGSXpW8iDAzs4O+vv7odBmQ9epMtHnlWjq7u5WdshHIhGk02lEIpGKPsh1LzJ+/fXXVddkcqv0wcqlKgsLEXHkh7AcHh6uiHok7cdiMU9kZSQSwc2bN2Gapmey9YsvvkC5XPZM9iaTSXz22Wc4efIkSqUSPvzwQ+W69QIhlnp7e7GyslJB/Pghr0dGRnDz5s0qggqAMz8iOTo6Ohw/NS9yNB6P49y5c1V1bdv+P9Fo1HcUXrFY/IonT09PDwqFAgB+it0TJ07ggw8+8NplFQj55pVcHx4ernC/kfsKAJcgr8dcHiVRquS+oB3xhMC7fv06rl69KiXAisUiN7KGdexfvXoVhULBKcdz+r/zzjtS0q9UKmF6epomDqv6IeQhcZXQpNbly5e5n2XkoCy6jROBKCUb3NKGupEhH330EZewvHDhQgV5ypJV8/Pz3O9FYyTzwJtv27Yr0jrKyN7u7m4Ui0VMTk5yycNGQoVYmp2drWDjRSSySBeitU/XdSMTjzqdrJte6kluivoSrS9edC5xM8hkBiojcN0eBuDdn7RtqXXcKlAm+ogjnrynHwMSRSj19vbixx9/lLZHnhumnyzgOf1F14nDvrOz0zmRWNQP6Yv+jpBaos8yclAkS1dXF/76179yZeGRaOl0GplMBjdvcnO6SPVC+hS1T8CLlCTPMfO+d5sHHomYTCaxsrJSEXkpIwBJKshmQKbLjo4O7vzxIFr7oVBIuPZV5djf30cmkzlSgk5GbnZ2dlYQ343oi1xn19fQ0BCmp6fx6NGjqmAvt4cBVAlZERlIkpYdFZR3yrxgCz9EHC96jyb6AKG/sS4Rf6qkoqw/P+OuB9ngh7B069trPT8Erip4Y/ZLqriRVrXMB02q+iVG/cggagcQ66mR0XJuhJhINhkB7+c+9yuzn3lk22gE6afsUyZElOg9L9prdnYWlmUhk8k4uzKiBJbQu3nzJpLJJHK5HLdNUV/b29tYW1tDV1cXTNPE7u4ugIMk3RcvXqxy8gNvSEX6O95n0djYskSOWCyGpaUlzMzM4PHjxxWnIMuIo7W1NYcwBN4QaQsLC06gzvz8PJe8S6fTzph5MvGuE9KP7Gh5sonGL2pvenoa29vb2NnZwe7urjMGtuzS0hKmp6extbXl+EwBOOuDnJuXSCQwNTXlm1SxLGuI6A8AyuWyM5aPPvqIS/5YloVEIoFCoYCRkRFkMhnnXD4AuHv3Lk6dOoWzZ8/ixo0bwjkZGhpyApEymYxzr9y9exelUgmhUAgXL14URmiapukQiZZlwTRN7O/vY3DwIFnagwcPHN319fVhbm5OqCdi/Gi/K8nfQoKJIpGIdI2RiFFCNufzeSdI5e7du9xgD6DiWLEqklO2vnjXs9kswuEwZmdnsbKyUvGrl5WZyEcIahJ1SstM5pHYCdFckF+xZHwkO+O3336Lc+fONYb0I1t12SsSidgAbAC26L3KK5VKVfz10qaXvlKplF0oFKr6odth23P77FcWAHZ3d7en8qSPQqFgE4yPj7uW9yOr13pexu513KlUymZxsETd1yj7AlChP/o9b114ke1QJk/tjI+PV8jiRwaRjmR6IrKKdEHDq0xEFlF7ItlI3VrXVyqV8i0zkcvPXCSTSVe91/Ly5L7gPZt67do1hxgjbZFrPT09KBaLFWfAjYyMVNVza5P8pCGkIF2G9NHd3Y3t7W1cunRJKMeFCxeqxnbr1i2nDt0+z83B+17Uj+g7osPD07aF+vrwww+lbbD1r169WqE/Vk9El14/s3pwKy8az4kTJzAzM4Ouri5hue7ubrx+/boi1atfUoV2ufHkOXnyJPr7+4URiiq6F+mCLsuSqbzv33333QpSmMwjAU9PxWIR7733HjcyU6QHkS7C4bBzWLCKzt3009XVhWQyKSRwSX16nZK2yDq+deuWcxzVlStXXO8nHpnntgbIPUZ/984770j76u3txeDgYEOjU2tKck+c6/Sk09e2trYqzoAjznJePRpTU1NYXV11ytLX2TKkDUIeyeTg4eLFixXl2fGx7cnkZccj0gUd2SYq4/V70WdWl6ze6e955UVjFX0WycsSerxylmUhl8vhL3/5S1VYsF/I1uPS0lJFaLxqXTddEP2KyrPf379/3zESqjIsLS3h888/x+joaAVh61cXf/3rX6vynvttb3FxET/88IP08TG3dUvuS5X+stks1tbWKp5SUalHwLt/RXVyuZyTWqFRcN0p0055WRSXqoOeR6i5temFXHQj6FgQnx/bvhshWCsRWMs4eN+zOyyvRKbbOGshRr2MS1BeuhMRkVle+1Gt63XsjSav6HqA/+hOlbb8tMlrT7ZOgTfcQiwWq9i9eu3P67w0k5wmcN0p0075ZDKJX375BcABYScjyniEH9ktsfVIu6I26Tq8fra3txEOh7G+vg4iqyg6ju4rmUw6JAzbPq9vmgAU9UOIK1n0I/nFIJKTHG3lJRJxbGwMT548qRiHLDpS9TP9l0fOij7TpAshakgEoYxU2d7eRqFQQE9Pj/OMr8oaXVhYqAh64JFWuVwOb7/9Nh4/foyZmRk8fPgQ+/v7ziOFd+7cQTwex+zsLHeN7ezsOGSb29onaWe7u7u535N5fPz4Maanp7G7u+vMu0yX5XIZ5XIZXV1d6OnpqSCwHjx4gK2tLXz00UdYWFjA/v4+Ll++LCUUSYRib28vtre3ncchb9y4gWQyienpady4ccORa3p6GslkUtgmIcQSiQR2d3exs7MDoJJco/XBW0e8YBIRuUzWF3mck8zlZ599hsuXL3Ojil+/fi2cF1FfhOCcnZ3Fw4cPEY1GnV/mhOwkQTU1k3+2i9MZhyQFXBzyqg56WT3Rd17IRVWCzu29GyFYKxFYyzhE36vo0uvnehCjfsrR5VXWKEtkeSVvaCLOK6la61yyctSDiCT6qBepSfTqp02WGKP1q6JLn2vGVc569FVPcpq8XN0XPKc8+/PAKxnCI9NIW7yfzXRf5LMqEUBIN7YPXn+8fugyh/qoKuc2ThUyjJaTLSMj5UTEJG+OZGVFdXljZYlXXh+8NUEio1iylyawXrx4URHFpuK+cCOeSCRaIpHg6l9G7rCkrZsOVeeN7VskNxsVSHTNk7W7uxtbW1uupKsbiQzAicxk1zddLhqNYmBggI10k7ZL7ILb2vMrv4jAE82lrC9WZp6+I5EIenp66nquojLRR0g2lvzxQ4a4gfTB64tAlQioJ2TyyMapQobx+qJJORFJ5yYXT556gW2Tloe3JjKZjPMTkZRnydpTp04hl8shn897zokhIxnpqC62nKy+bLxuMrDjFI2bd43I/t133+HSpUtO4i63sbqNx7Is1zYymQyy2axjaNzIe9oguZVny6nq0isJLptLEanvRlDz1ishXbPZbN1yuEh3ymzkjWgXxm1YQoaI/juSB/JVdrCqRADbDv0wv6gfIgdbhrTHyuM2TpFORHKyZbzqUjRHKjtkLztlWh+iMcvGqgIBkVKVClWlPVG/XkhbN92p1FXtmycL4D7WehOP9SyruvZqkV91nuulT155wD/hJ90ps5E35L2ImKMJBEAcIUfekzLAgXOfGEKWYCKRfvRnNyKAnNPHykyy0e3t7VUQdqTdX375BfPz804ZluTiySMbp0qUIE2A8srw2mGJEpFOnz17JtW76PPw8LBDmvF0RbcpGzNN9q2srDhRZSIyJZfLOUf/kJ/thMAi5y2eO3cutLCw4OyKRKReIpHA1tYWBgYGnFO2vUSRbWxsVH3npjvVeXPrm6SPPXXqlJO2koCn352dnYozKHltkmhKXhsrKyvY3993IkxnZmacxO88Ap9Emp48eRIvXrxwHn8TEYAkypXWF0+PIyMjWFlZkZLBPJlISl+SDJ+Xjpe9zpLjbD87OzvC9L4kbW+hUHB0C6DiXEzfhJ9tq5N8tUS9qZJpou9kBJsf0s1Lu36IQL/6UhmfX32plvVC+kUiEc9Rnl6jtlgA8BTtqLoWvKxjP+uyVmIplUopjbWexGO9Izi9rNN6j8+v/v2SfwBsmX0V2l03o0w17nR669Ytm/3u1q1b9p/+9Cf75s2bVd+J2qHfe3nZtm1/+umnFe8/++wz+969e9zv6b5JWV6b9FhUZZeVYa/L5BSNjb6uIpebnF71TPr0Usdtju7cuWPfvHnTvnHjhr2xsSHU0Z07d+y7d+9WlJOV/eKLL+y7d+9WzDs756Q+rUteGVZ2FX3yxi6aL941djw8+ch33377raMXXpuq88Dqi7dGZfqWySjSr9v9L5JZdh+xdWR16X7YerL+3ObjwYMHNo3D8p6Nsq+IPh7Jxl5zc+LXCll0Hy9aiC0rA2989YCI4OGVO0q5ZPDaJ03SkjmQRaX9+OOPFQSJiPB69OhRRdSbrE1altXVVUxMTFT5BOlxiUhVWia/Y3crS8NrZKht2xXpQdkIVFZ+r8QZrx12bmQy8r5TBU9mmZ7Y9carKyP4ZLKqRq0uLi6iUCjgd7/7nfI4eXA1yqwvEZAHVxA/2djYGLc+3Y5b/mARlpeXHWc6eT89PV3RN/s96S+dTnPJI9qv5earlY2LHRPrgzUMo8K/yMrC+mbpMYt8mqI+ZWVUQPepCjLv9ByQ97Q/jhzBQ8vGzuXi4iIsy8LKygri8ThWV1fx9OlTbpsPHz6sCDdm9U37b0lfvHKs7DzfOf3Xbey8Ojwfv0heVifkSZJyuYy+vj6HvxFlcaTXGE9nJGE82w/xzZIxsd8vLS1VBUrRbYu+oyFak7T8tMw8Odg+ePPAm1dePdk9Svvi2TVKDLJpmrAsC8vLy84jndFoNO+Z7JNto8H8FEilUhX+FXINgp8gor+pVMo2TdMG3vhrSNtuL1A/Iej3tn3wcLvoe7Ys3R8ri9sY6DG7leH1zZONLi/rT6ZTWj+8/ukyKvom/anMC9232xzxoFqOnWNeWZ6+6Xrs/InqiuaI1ads7KK1Qr93k1c0ThWZee/ZtkTfieST1eXVZ2Wl739aR6J7QCanqIysLm/u3daCqH8e6PHDhwtD+mWt5JoKGeLWFjtxboSA6HtVZz3bTyOIM7d2ZHX9EI1eCEe2nPJCwhtS2I/evZAp0WjUV1teiTcva8mNsPIyx7Xozs/6d+vfT10V/fL6kMnspz2RLmppW/VF/ZPxZJSlzykbhlHxJSmr8iwuz0VAwEbjkbaJD5Bk7qIf4D5Mll0lC9sn/ZcnD9033ceLFy+ck6tlz+mKPquAlc2tL1ZukmJUVGdhYQGXLl0Sykdfk807LZutGJlkMOldRfMh6KMu12Rl3J4r9vL8LP2e1jkN2RzL5rAWXbn146YrVg9ucrnpUNQmT2+y9ep2b/PGzpNbtYzbOlC5d5ixezIUnog+YjTpz6LvZBCRR6Lr5FhxN3l4MrHXmkGW8eBFX4Ca3H5IOd4/qMXFRa6h8QPeGqH7410XXXMr61ZXJJ8sVakbZDoXzbGoHxVd8b7zInstuuKV530W9UXDy1rljU1EanppQ1RGtazo3jFNs6boPk9GWUSA8JzhMrAP1NPtsQ9xRyIRDA8PVxFOPCc9kZGWib7G9k2yecXjcUSjUeRyOefoHxYyMk0VPHLJrZzsGisPj5DitUve04TF9vY2fv75Z4yOjmJwcBDPnj3zNjimT9F80AQJTSaxBBfvGo+IUSFrRGQsu25VyGmW7GWDmNjveHNMr0fedVZX9DFEMh3wZKDBjldGLvLakZGi9Gfe+Fkd8u5nkfy0Xtjx8shyuh+ZfnhjY8cg+svq7dGjRzh//rzT7p07dzAyMgLAB9kn822YppkH5A54+j39ma7HEkxg/DSqvhrTNPNEJlGfIvlYklL2Ykkwtg3ab8Uju9hyMtKPV14mNysHT3+0X5wtQ/dBwCMsCIlimmZetkbIizfvojG7kUwq10S6FJWRrRGVcvQc8taSiKwibbBErNu802NXGZ9bPyq6ovXstm5519x0y+qNN3ae/KK2eWOXya2ic7d+RXrjgejzsI7rPURergVUCQz2s4rjXvRyI5ga0Sd9c1HK5/Yne9GssptsKvqTlRXprh5lmMVd0zqplQxSvaZCwHklUFXWkpc5Vu3fj65k/aiSVqr68jIGt/WmsnZU7ZAf4tBLO0dB9iml7sRBqzAMwyGcyDWqnFOGLk9A1xORbTShZyucESYjJdjPbuPk9OHIQPfnRhSyhOLvf//7inaJHDJCTEY8MPJVyUzaFPm8njx54pxVKBrLs2fPMDc3h0gkokxUsKQwPTZ27Dz5vRArorXG6ozWCQ88Hcsgk0dWXvSeHb/sO976dSPGVMfgRV+qhCgpT7cvun/I4QciGyPSoUgPMtnJexlBq9qeKrySfco+Zda/QyBy5rM+Iroe6y9cWlqCYRgYHh529UfT/dJ/3crRsrJGiPjseCcesGBlLxQK2NrawvDwMG7fvl1Vzk0moidyjdYbO0Y3koVuk/V5LS0tIR6P4/Xr18KxkHkYHR3FN9984yRjqRfcSDpZClJVQsovAeSV5FORhzfP7HsZGVYrKSeTyQ9Z6JZSl3ednVt2zS0uLlb1Q9sKWbCZV7KcQOaH9rIOZGTfwMAA3n77bc+yAR6MMnl0LUUdTsgjDtjyBHS9VCrlfN7c3Kw4ZXpzc1NJHjpqh4bonwHPUK2trcGyLOzv7yMUCsEwDNy5c6fCGEWj0TwZK092+skQciIxW44GuyCInoicbLYtdqwikoXOU8zOFatjnoxsmbGxMeW5EIE3F7T8bkSbaO5IXQKvBBAtH6tjlfHwosp4oNuk7wd2jmk5RSQk2+fa2ppUPjeZRHMhA3vPkX5E9yIb1QlUrzmaWKfvMQKe3shYZWQ5C3otiu5N3hhk7YnIvsHBQWxvb2NhYQETExNK7VXAzb9xSK5x/So0yGc2Wo9HjMHFDyMjl2iij/4rImLocjREznny3WEdEJlIuwqyc8kMohNaX7wIMfozO0aevlmZVWT0Uk6V6DNNM8/ON29uRPLz5lQ0d6y+2HL0e5ZsZuVj++KVkxFe5OgpHqnKjp9d/zRIhjWZbug+WXnZuiy5LrsfvOhL5a/owQDRmqPbp3VF2xHWBrHyy+aNpxPWPvHmjG2Hd3+yc8K7TmyJ6ku5YEUlVJ/b58UB7kbkufXtl7zx8iIy8sbqdWwAqs6NUyEgVMbmZw68lPM7T16JJr8EkxdCx6uOVeXhvUSh+yoyeSXlVOt6nQsv8+OFYKtlTdK6VZXX633hRvx5tSde7yNXoo8Hlmg7vAYAsG21yDzb5xlWPEKJ9CsiOWgZVcdLZGTHKhobTfSxYzOoM+RI2zz5SdssOSgaHyuPSnQkSZbudyyqYOeJyM1GJsrmjdQjOhPVYXVCyVDVN3uuI49g4+mUNw6R7siJzWy7jH4AiKNb6T5+//vfc+uLdEfGoBLdKVqXftYjry+2fdH9x5s/EUTEn0xetgw7b4VCAefOnVNel6qyEnm93Ee+UneyoJ3jrO8rm83i559/xvDwsNT/VitYwkwmo2hiVldX8d577wn7EAVcDA8PO6dUyCAjJlR9ZCx5xMvAJSL6WN8lW0ZEWtYTxGfnlVCR1XEjgGgfNasrtowsqxk7DpHuZONgyTWZTCxZLIueY8fiRljz5OK1IVqPKhkKRe17iVakU7LG43H8+te/5srD+uBFMovuC+Jj9hoUJnt4wLKsqn/qSvD6s5T4dG/cuGGTv5lMxtmq02D9LEz2KN/uC96LtEvLQl60jOT9wsKCfe/ePTuXy9mff/65/eDBA3tlZcVeWFiokJEeq9+xsf2K5CfgfU9kEOmarseCDUBwK0M+13OeiNzsPNHrSDRuUpb9S88LW57WMzUvFXpgdSnTKTsPMt3xyrPrTjbvbB+i+qw+2DbZ9tzk8rIeaX3xrovmg3f/0fLx7s1vvvnG/vLLL6vkpOu5yauy5mn53dYlT9aFhQU7k8nYP/zwg3337l371q1bdi6XswF1bsa2fbgvDMOwyTlakcNz7AAgEokAgPNZBr8HCgIHT0PYtl119tXe3p4jD5GF/o7IqCLfoYz7xWKxgxweq1o3EonAsqyK7YVpmjZdl5WPllH2PTs+Vh6VOTjKeQLgHLrLyi/6S0B+OrJzx/4lOWwjh89U06c102Nl54+uT/ohbfH0RWQifanoWNQ3Kxt9jdeHqD5Pd7QO2PHTEOmE/p53nf6e1j3dN9Eprx2R3jyuS2fORHrkwa1tMh56XDzdAahaazIQe2mrJvfyY5QLhQKuX7+Oq1evAgAKhYJzyKVbe7X4KXmykD4Nw3DkIDLQP728yMjKSY95cnISANDZ2YlSqYRQKISpqSnnZ6vMp0zLqCIH7ddmx+BnHEcNkV+ZHQf9PVOfW4bnw6Tn5/Lly656lvmiJePxXJaVXaUtdi1vbm4Kx8aueRWZRfpz05doLCpl6T5499KFCxcq/Lh//OMfMTc3h56eHhSLRRiG4ST5cdMtTx5VO6fStttYSqUSbNvG3Nyco1Mv96Evn3I8Hq84Iicejzvv3cijRoD41lg5WJnZOl7kJGMmdUqlUsXD4tlsVpoZSiQjT4aNjQ2cO3eOK0MtYwgK2HHQ8BsgQc8Prw/VYA9Vfcp8ib/97W9d+5C1w8p///79iiOK6O/Ie5E8quN3W5eysYj6FPXBu5fYdoeGhmDblcctfffdd5ibm/Mky4sXL1zLrK+vw7Is1/uXrisbC2n3xx9/RFdXF959911huzz4JvpEqfd4UWIkC1ujySMCtwfhZRFvMjm9phZ1q8vTVSQSwenTp5V05RZdKMp41yy4kSiqJJuoTdH88Mhntq6XNSEis3/1q1/BNE0n+51MDgLeGmChkuaSFynX0dHB/d5rW4VCQToWlvRWAW9MJHjEz33mRrzy5pcc5ZRIJNDb2yu859zWZS12gQtV5zN5AdXknheiDzWQRzxZSJ9ELloG8r1MRhU5SX3aqf/DDz/Yd+7csXd3d+0bN25UEYQ8nfnVFSnPkg5u9UXyHNWLlpWeJx4Zy5sXXhkeqUWvSZpQkumJrutlTbjpnS0rGp+bbDKCkNaBG/Eo65tuy21dysYiIzrZsfDGRMgwUldExO/u7iqtHdXjwXjXVNclfT/Tsj548KCC7CPkn5f70LNPmSatWGICUHKm+yaPWBDSj0cAEfkAeJaR1CWEXTQatVWd+oQgZOR8bVlWyI2o47S1WiwWE4Q0o8egOo566tsrWFJWRsaS72nICE9em3Q9Nz2zJJWiLvdt2w6p6h3AgG3bIVpWdmxusokIPpbs8kKgifQnk0lEnsv6FPUhat9tLASHh8Xui3TLK+/h/l0FAHbd+pWVlqFYLDaO6GOvqbbRSNKJJv0E/VYQJsAbp/yJEydw7tw5dHZ2cmVlgz9c5KgaI03UEYL0008/rZDDMAz09vZicHAQ8Xi8qh3Z+FTlaBZk5LDbeHjzwJJX5DNLvly9etUp40YcNUJXXuaMHSe5TsZL1i9NxnklHnnrCUCVvq5du4aBgQGMjo46upKtTRUd0H3JyD6/4zlKsMR7veWtS/AIIHaiP3nyBPF4XEgWNAIiUoMlTCYmJpygkW+++QYjIyPShCSyB9tN08RvfvMbqVw0QSoiB4i+GiVDsyAih2shK1nSjCVf6HJeiaN6gzdOy7KQyWRw+fJlaT2C+/fvc6+L2i+Xy8hms/jggw+kspH7goCsza2trYq23NamCryQfUEnsRv1gENddso3btyoOsrpxYsX2NraQm9vL0zTRC6Xw8WLFxu+U+bJkkwmlXeYVHsVOxdeu9lsFoZh4Pz58/jyyy8BAPPz88KdMr2z87JDpNvIZDKuMly5ciVwO2V2V0t2eux4tre3HYKGXTNkHubn5wG80QUhWuhdJemrmbsu2ZpcXFzEe++9h++//x6GYZBHwqQ7ZSIrcDB2ErXntiamp6fJPcDdKTdSX6LHIkW/aEX6Yo9ta6QtcQP7KG695fW1U04mk/jll1+IgM5N4gbir2kUksmkUBbRGYDd3d0ol8sIhUJIJBLIZDJVoZqRSKSmMZqmuWpZ1hB9Nhl7ViAxRr/61a/wzTffcNtWyfcsk6MZoFOf5nI5jI6O4unTp7h58yaSyaTreGj/pGma+/Pz8yFyjdQlvj3eeWu8eSe6Pn/+PDcFZr1gmuaqbdtDKmsnEok4gpB69JjotUP0xurBTRaebHt7exVt8/RFDAzJs+0FpB8A3Dmi+xkZGcHGxobSvdbM9U3uZ7KGFedXvQNVRtC2K9N4ur1M03ztpe1aX7LMTV6zOpE61Lhf1zpmug3VrFl0aKaqDGy9Zr8A2CMjI77nQzXDFtGP1+xkzVirHu4332NSWQcA7NHR0SPTF2889Zr/o355tSkNC7Omt+2ybEtzc3NH/vOZkEnxeLyKqCiVSrhy5Qpk3588ebLiIW8e8aJyFJRozLyfcV6ytKnKwMrebLAkn21XElTsXIRCIXR0dKC/vx+pVEp5LDwylaCWeWsm6PuNJflkgRBzc3POoQ2ycdHEKR3RJ9IXSdjlV1+8e4B3Lw4NDfkiFY8SZF339fXVfX35NsoKZY/cKMsWK/EryzLEvXr1CoODg5iYmOAaRLdxezXKCmPyLIObHEcNel4uXbpUdf6aW8Y+r0aZ7ouglnlrJkRjUr1nvRhl9p9lLe3K+qM/i4yZZVmYnJyEYRiBnhtady5lG2+UZaRXKpXC0tLSkTvi3R5bUyUxmPIVBtELKcWTj/7M06EbyaUiw8cffxyohcySfF5ufqqOJ6NM6hHIiLC1tTWk0+nA6IuGaEwqpDOP3OO1zzPKIn0RvoNHZnsZD0GrbTBo0LqrxS7w4Ino80JcNMMRLyIpDh82ryLXeERfPp93EsHTY7Fte8iNUJGNmZADhCT1qkNVGdzkaAbYs/NI1iwR2Un+sXsJE+eRqUTXtcxbM0ETSul0GiMjIygUCnUl1mkikRBtjdIXS/qx87+0tITOzk6cPXsW9+7dcwj3aDSab1YAlAxEZypktZcx+Dp5JIggUXOi771E35DybArOWsGm8BQhmUwil8sFcofgFfS8uKWj5IEXISkpa3tp/zAitWkRj26gIzm9QHXtspGm9WzbDar3AnlaJ2j3gpu9oZFKpbC8vKw8hrYxyizRw0sLSMgSFcc8gLovBJr0YqMKT548iWQy6cgU1J9tXkH/ZP2nf/on/P3f/70SqeSHJPFCppJMfEHWMxt1JyKpbdtfmkgeOcoj34wGRD/K7oVIJIL33nvPibAN4hzRriXenNQyhrYzyrybPJFIVJAlKo55oDFG2Y05JykEg7gQ/YA2LOz5fEB9SaV28lkC1QEesnUTCoXQ1dWFM2fO1ESOiv5JPnv2DB988EFdjbJsTPl83kl9EMQ5cnsaKp/Po1wu+/pn1nZGmTceNiJKhfg5bKshRlmxbOAWoh+whsWNVKqFJFEhU8lcz83N4auvvvJNWh0FWN15qOebHD2qJ1Va/V7w8jTUYXnlMdQt90WzYZrmvmVZIR55BLwhm1Qc82NjY3jy5ElD5OSRjbFYDLFYDKZpIpPJ+DtsMaBgI8cAz6TSvpf+hoeHnfy/QSWkVUFnpWPXzdraGkqlEkqlEsLhMPr6+rC9vY2RkREAB0bDLUOgSqQpId9kkaZ+ISLmDcMIPNnH6o6+nyORCIaHh5HJZBAOh73nNbcDEB1Tjxc4kWPk5SeirxFRcapReUTmZuu0juN2IkG9zEUqlbIPlmh99RvUCD7eml5YWKiIulN5JZNJ2z5owFV3XqMF6xUx6mUdkPu62fNRyxi83M9t5b6gU+nRvioSzcf7Dji6CC83cqC3txcDAwMYHh4O5E82v+C5MGTEVUdHB5LJpKeIProfkZ+vFcg9GmRN03r65JNPuOvHMA5yhs/MzEjPi+T1QX+W3R+1RvTx+pWRfWfPnkVPT4/yWI4abmSlX/nbyiiTG54dE+3HVBlvo42yyGisr6/j9evXdVv4QYHIryy6+TOZDAYHB/HWW2/5Mspuc9wquuWRYVeuXBGunydPnnh+UqJZ5ChLMorIsvPnzyMcDgdyzlTIyp2dHc9ZG9vSKLPkEQmxNiRp9o4iwssLORDERegXIqOsWNezURYRua1A7tHgkWH11p0XcrTWiD5ev41YB0eFRpGVbUP0AZCmgyTkUt3T7HmAiIxkyT5CugSN3PALXipKHsmTyWTQ0dHhkCQEqnqoR+RlUMCmPCU64l3L5XJIJBJYWVlBPB7H6uqqQxar6K6Z5KgsterZs2fxt7/9zXENBBHsXBQKBbx8+ZJL9Kmu47bZKcsihIIQzQcc/GclIcZuIOWCtjuoBX4iyMiTMO2kBxWI1ooX3amsIdXINC+RlW4gkYq2bXs5465u/dcLjYrqaxujTBMHPGKk2dF8REb2XK9mnB3XLNBzRHQgOjfRL9nXLqBJPpYTIUQpq7fu7m5sbm56iu5z4zkaQX57IRdXVlbwzjvvoKurK3BrwI24NwwD09PTnohXoM3cF8DBuVkLCwuOO4CAnG9Gjg5qFthz1pp9dlwzQJ9tJjo3cXFxEU+fPkUqlWqWmE0HWcs0yGfeGXcTExM4ffo0vvvuO1y6dAmhkNImDkDz7wtR/6Ojo0csiXfQ9oa+j/P5PLa3tx2jrIq22ynLiJFmRvMRGYPwFEizQM9Ro8i+dgFNIvF2yvXSnYgcrTX9pNvY6M+ie3J0dBQrKytIJpOuaUibgUaRlW23U2aJA/qal2g+onC3qCivIFFtzTw7rlmgU1ECch2wZN9xAkvykff0X9GZk5OTk8jlcgiFQk4KWhnB1AxylCZ+Vc+dDCI526iovrbYKcuIA68kH3DARv/zP/9zXY+1ikajebIQG5G2slVACNlmpItsFRiGYRNiCHizhtm/KggyYdwMkrHeUE1BCqiv47YwyuzPITobGeuAv3DhgjSaLBQKYWpqyrNzXlXGRqWtbBXwSB7ePJimibGxsbaLblQBcV3Q5/LRIGtItI4Nw0BXV5dz5mRQ9edGMtY7M10jwIu6FJ39qZwoqh2NMvG7uaXxlJ3VNzQ0hHQ6XXejTGQj713qBHYx+oUX5n19fR3nzp1DKBRqOz3IQEeK0WcNEqhERebzebz//vukvUDqrx0iMFWi+kgKz2NtlDOZDInK45VVdsyT8vXwK/OMcqueHVcLmhXW2yqIRqN5y7KGaJKPRbsQpW4RmKOjo8hms0d+3qcq2Llyg6otaQuiT0Qc8NIQ8q5ns1mEw2GUSiXs7+9jcHAQ+XzeSRtoWdZQPWQkJFernx1XK8j4eSkpCdE3NzeHr7/+GlNTU80W90hB1hpNTm9sbAA4uKkty5JGRdL6++qrrwKdBrbVIzDJXHkh+lRsSVvslAlE58HR8Er81fO8PC8RQEEmN/yCJjsB9bkI+ll69QRL8rHwQ/a141oKArxE6ALqpGtbGWVR4ptr167h6tWrwmg/1kEfCoVQLBadXUYj/MrNSh/aTNDPaRMyFhATPT/99BM+/PBDYpTbTh880CQf79y8Tz75pKK8bC21WqrSVgMdoSsj+wYGBtDf34+BgQGluWgL9wUPJPKJRNsA4mg/Ehm1tbUF4M2i/vrrrx2ypN5odgRVs0GPv5WjuRoFEukIgLtmaWj9NQ8kOpW1LWxk39LSkvNP0w3HYqd8+J002s+l3brulJuZPrSZMAzDvnHjBubn5x0yFpCn2iR+5SBGdNUbPOKIXaMs8dfq5xC2MrxG6B7WASAPSmurnbLoPDjR+WOA+JywcDiMZDLpkIP1lK/Vz47zC9M0V+fn54cikQjS6bSTIrVVI7rqDR5xxH4eGxuriPY8rmspKPCSijYcPjC3h4ZcSPi11U6ZgJcikkeMHOfIOo3ggUcc6TUaXPhJRTsyMoKnT59Kf323pVFm3RhsesjLly8rRdbV80wyDQ03sOk6CdyCnfQabQ5kDxawZJ9t28opVdvKfSECmx4SqEwfqYkSjaDg/v37WF2t9jboNRpssA8W8Mi+J0+ecMPmWRyLnTLne9fIunA4jMHBwbqnLdTQ4EEWyccj85aWltDZ2dmQ1JoaapA9WKBQV0j2teVOmTzXSqKf2AUNvDnPTyWyrlFn9mloELAkH/Dm7DxN5gUTsgcL2H+ec3Nz+P7772FZlhP/IIrua9udsm3bTpJsFu2S+lCjfcCSfDrasTVA0gZbluXJrsjO7Gtro0wTfDS55xaFc5iVrG3PytMIHkQkn1t618O6en02CV7IPgB46623XNMCt6X7goAl+OjoG/JX5Ji3LKtpcmscT/BIvuMe+dmKENmUxcVF7OzsuNZvq50yIUsA8Vl9jTjnTEOjVrBn8hG4nZ338ccf6/XZRNRK9rX9Tpmw14ZhCM/qY/+KovnefvvtwKc+1Ggv0CSfKgkNaJKvmaDJPmJXeKmBSdg7S/bx0FY7ZcMw7IWFBfzhD3+oIvhqOedMR0tpNBr0WW86iq/14Ce6TzR/bWeUC4WCNHqPhY6W0ggC6DSQgHxdFgqFuh7qq1E7WDeG7Iiz58+f48qVK8L5azujzCrkypUrFYEiLPRxRBpBAJ1xDNDrstXgFrAmqNPePuXD5wUBeGOsZX5lEtGnoXHUEK1LwzCQSqXqmr1Qo76Qzd3c3BxyuRzy+bywftsYZfZsM5bgI8QJCx0tpREULC8vO2fyqaxLHWkaHBDCD1CzKaQO73rbuC8Mw7DHx8eRzWYrrns9ky8SicCyLP2TUONIQT/OqQJZRJhGc0BH97lBRtK2lVHmnctH3pOoPvpzT08PisUiDMNAV1cX3n33Xe2n02ga6GeV2TVaKpVw4sQJ9Pf3I5VKkfJ6rQYIKmdwqpC0beO+YEGOpifRNWSx05/Z1HoaGs0GuZknJiZg2zYSiQTK5TKy2Sx2dnZw8uTJZouooYBaUq227U758FrV+WZu49W7D41mgd4pK5bXazVAUDmDUyXValvtlNlIPUB+3hkJWy0Wizh9+rR+0kKj6WDX5+LiIkzTRLlcRigUcojAoSFl97PGEaFeZ3C2zU5Z5Vw+FdJPp0LUaBboqD4VaFK6PdE2Rpl+eJuATUBEromc8CQdov5ZqNEMuBF9hmFgenraNfWjRmvjWBplhbb0Ytc4cvAiUoE3m4ZsNotSqYREIoEzZ87oddqmOHZGmeeEZ9Mh6vPONJoBP0Sf6Jw3jdZF2xB9dEQNANCp9OiIPh0ppRFkqBB9+XweyWQSgPicN43WRdvslFn4SaUH6EgpjeZBR/VpAG1slOnomsPP3Gi+UqmEUCiEqakpTaBoNB1uZJ9t25ibm3NSfOq12n5oG/eFDAsLC85fXjTf0tISHj9+jL29PaWTHjQ0GglZVF+pVML29rYwP7hG6+PY7ZQV62oCRaMp0FF9Gm27UzZNc9WyrCFRdB8JfTRN0zn+u7e314n80wSKRrOgQvatr68jkdB7hnZE2+6UAX/nngGaQNFoHnRUn0ZbG+VGHP+todFIaPeFRtu6L0QQRUuR43UGBwdx5syZZoqooeEa1ZdOp528yhrthWNjlEkgydjYGAzDcPx1S0tLME0T+/v7ME0Tvb29WF5eBnDw3Kgm+zSOGoQHodfpw4cPnXXa1dUFAPj888+bLKlGI9DW7otoNJq3bXtob2+P677Y3NxEPB6vqre5uUkf9a5/GmocGXjuC9E6PSyv12iboa13ymSXa5qmbRgGScupVJeQfRoaRwkva5SU12gvtPVOmYB+ZlmTfRpBBn2Czq1bt6QpZg/L6zXaZmjrnbIIMrJvf38fw8PDmJmZabKUGscVJAKVx38YhoHz589jeXlZE31timNllFXJvkgkgqdPnzZZWo3jhsMj6jE2NgbgwIVGDO/m5iYuXLjglO3p6XHeG4Zh6wjU9sGxcF+Q7Ft+yD692DWOCrSbLZ1OK3Eah8Ej2o3RRjgWO+VisZiogezT4dYaR4ZUKuWJ6NOh1u2HY7FTBqqj+0R+5fX1dTx//lwfuaNx5KBJPq/3pV6n7YNjsVNmwXs4n/iVu7u70d3dDQD6kTiNpkIW1RcKhZBIJDTZ14Y4tjtlGm5+Zb0D0TgKGIZhZzIZpNNp7lmSJFtcLBZzcirn83lMT08jmUxq/qNNcGyMMonuMwwDlmUp19MLXeOoQDLEeT3CDABGR0fx9OlTvYFoAxwbowwc7EQKhQLZ/bqV1Qtc40hBfMqbm5u4fv06JicncfnyZRQKBeczAHR2dsIwDPT29qKnp0cfY9ZmOHZG2S1aqlAoYG5uTi9wjSMHL++FjkA9fjiWRB8gjpZKpVK4fft2s8XTOMZgCT7eNfppobm5OYRCoWaJq1FnHDujTKL6ZNFSpmk2RTYNDfbJIN61/v5+rKysoK+vD7u7u7h37x6GhvTj9O2CY+W+iEajry3LCqkQKaZpolgs6p+CGkeGaDRqsyS0F9JPHw3VHjhWRpk94dqlrPbPaRwp2OARJq83rl27hoGBAYyOjqJYLCIUCqGjowP9/f1OJKBes62PY+e+IBD56Oi0iBoazcT9+/crPk9NTWF1dRVbW1sA3qzZZ8+e6SCSNsKx3CnzHszPZrNOWsS1tTWk02m969A4UvDCrEkeDP3r7vjgWO2UTdNctW17aH5+XqXsfuMl0tCoBAntX15eRi6Xc4JCCNnH20jMzc3hq6++arLkGvXCsdopa2gEGSIiWpXs0+R0e0AbZQ2NgIC41+ioU5rsEwU8bWxs4Ny5c9p90SbQRllDIyDgnSW5sLCAS5cugVx3qa+NchvgWPmUNTRaDRcvXnTeEz+z9im3N7RR1tAICEzTXLUsa4hEnRJyb2RkBBsbG0in09L6kUgE0Wg0r7Matja0+0JDI0DwEnXK4vD4Mu3CaHFoo6yhESCwhzEYhoFCoYB4PF4V0VcqlXD69GnMzMygs7OT1NdGucWhjbKGRoDAM8qyMyXZo6G0UW59aKOsoREgiIyyh/raKLc4NNGnoREgkKjTvb09J80s+9QFOavPNE3s7u6ir68PpVLJeZ7ZMAxbH2PWutA7ZQ2NAMIv4ZdKpZDJZPSOuYWhjbKGRgAhiu4TEX6Dg4MV2Q21UW5daPeFhkaAEY/Hnff379/H6uoqJiYmAACJRMIh+1ZXV2EYBs6cOdMsUTXqBL1T1tAIIHgh1x7r651yi0LvlDU0AghRdB+P8CuXywiFQujr68Pa2homJyebLL1GLdA7ZQ2NgKKW6D59Xl/rQhtlDY2AgnZhbG5u4vr167h69Sr3vD7DMNDb24vBwUHE43HtvmhhhJotgIaGhjvu37+PWCzmfJ6amkKxWMTW1hZKpRLS6TRM08SDBw+aKKVGPaB3yhoaAQXv9HVV0k/vlFsXmujT0AgoaLKPkHyAmPSLRCJIpVJYWlpqsuQatUDvlDU0AgzTNG2f5/XtF4vFjkbKptEYaKOsoRFgGIZhf/rpp7h69aoT3QeIz+srFAqYm5vT7osWhnZfaGgEHFNTUwAOyD4C+pgoGqOjo0cik0bjoHfKGhoBhmEYNh3VZxgHm99MJsM9r4/4lC9evKh3yi0KvVPW0Ag4lpeXnb9ezuvTaE3onbKGRkARjUbzJLeyl6i+ZDKJXC6nd8otCm2UNTQCCjp9J0nZKYroC4VC6OjoQH9/vz4WqsWhI/o0NAKOeDyOhYUFaURfKpVCIpHAxsZGEyXVqAf0TllDI6DQEX3HE5ro09AIKIgfWSWijzx9cf78eaytrTVZco1aoHfKGhoBhWEY9sjICFZWVpxrOqKv/aGNsoZGQGEYhl0oFHD9+nVMTk7i8uXLzneiiL4XL15gdnZWuy9aGNp9oaERYJCUnezmSRTRp9H60DtlDY0AIhqN5i3LGmJJPgJRRB/xKafTab1TblHonbKGRgBhWdYQcBDFR4wvcBAY8ssvv7hG9JmmudpwITUaAr1T1tAIIPySfJFIBIZhrBaLxUSjZdRoDLRR1tAIIESJiGzbxsLCgk7b2cbQRllDI4CQGWWFutootzC0T1lDo4UgCxwZHh52Akw0WhfaKGtoBBQ3b950/hKCb35+3rWeTtvZ2tDuCw2NACIajb62LCvkJWUnABByULsvWhfaKGtoBBBs2k7DMEBH9wFAZ2cnSqUSQqEQpqamMDw8TOpqo9zC0O4LDY0Ag6TtBKqj+yYmJlAul5HNZrG2toZyuYyxsbFmiqtRB+idsoZGAMGm7VRN2UnKmqapn1VuUeidsoZGAGGa5qplWUPkaQugMrqvv78fi4uLAIDe3l7s7u5iZGQE4fDBLU0iAjVaD3qnrKERUBCyD1BP2QkAqVQKy8vL2q/cotBGWUMjoJC5MK5du4bJyUn09PSgWCzCMAxYloXZ2VkMDQ1psq+Foc/o09BoARCyj7wnhN/W1hYmJiaQSCTQ2dmJoSHttWh16J2yhkZAUSvZp3fKrQlN9GloBBTsGX0AP8y6UCjg5cuXTi7lVCrVXME1aoLeKWtoBBSGYdjj4+PIZrMAvJF9+oy+1oU2yhoaAQXJFHf43rkuS99pWRampqa0+6KFod0XGhoBB03yEegz+toX2ihraAQcrAGW+ZV1+s7Wh3ZfaGgEFIZh2Ddu3EA6nUY6ncbw8DAKhYKSX1mHWbcutFHW0AgoTNO0iQFWJfk0wdf60EZZQyOgIM8p37p1C5cuXQJ5zyP48vk83n//fU3wtQG0UdbQCCjo4BHVM/q0UW59aKJPQyPgWF5ernjPZoqLRCKa4Gsj6J2yhkZAYRiGPTw8jGfPnjnn7rn5lTXB1/rQRllDI6CgU3e6QRN87QNtlDU0AgrapyyK4Hvx4gVmZ2e1L7mNoI2yhkZAwWaJcymrjXKbQBN9GhoBBy+CL5vNwjAMJzOcRvtA75Q1NAKKaDSat217SEfwHS9oo6yhoaERIOjjoDQ0NDQCBG2UNTQ0NAIEbZQ1NDQ0AgRtlDU0NDQCBG2UNTQ0NAKE/w/xrCQ28JdOAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Tree Plot for Visual Representation of Tree\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(decision_trees) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis, Keep 90% of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12589, 157)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction with Principal Component Analysis (PCA)\n",
    "pca = PCA(0.90) # Preserve 90% of the variance\n",
    "\n",
    "X_transformed = pca.fit_transform(X_train) # Fit the pca transform with X_train\n",
    "X_test_transformed = pca.transform(X_test) # Apply transform to X_test\n",
    "\n",
    "# Training set shape after Principal Component Analysis form\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12589, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Original Training Set Shape\n",
    "# Notice we lose 3,943 features using PCA, while preserving 90% variance\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Decision Trees model for PCA instance\n",
    "decision_trees_pca = DecisionTreeClassifier()\n",
    "\n",
    "# Use training data to fit Decision Trees model with transformed X_train\n",
    "decision_trees_pca.fit(X_transformed, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 4096 features, but DecisionTreeClassifier is expecting 157 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \"\"\"\n\u001b[0;32m    436\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m    403\u001b[0m                                     reset=False)\n\u001b[0;32m    404\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 4096 features, but DecisionTreeClassifier is expecting 157 features as input."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make prediction on entire train data\n",
    "predictions_set_pca = decision_trees_pca.predict(X_train)\n",
    "print(\"Accuracy Train PCA:\", accuracy_score(y_train, predictions_set_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train PCA: 0.7579415501905972\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make prediction on entire test data\n",
    "predictions_set_pca = decision_trees_pca.predict(X_test_transformed)\n",
    "print(\"Accuracy Train PCA:\", accuracy_score(y_test, predictions_set_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1014\n",
      "           1       0.85      0.82      0.83      1137\n",
      "           2       0.66      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Confusion Matrix for \n",
    "cm = confusion_matrix(y_test, predictions_set_pca)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Reds_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score Test PCA: {0}'.format(accuracy_score(y_test, predictions_set_pca))\n",
    "plt.title(title,size=15)\n",
    "\n",
    "print(\"\\nPCA Classification Report\\n\", classification_report(y_test, predictions_set_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Depths [Decision Trees Hyperparameter Tuning]\n",
    "Determines the depth of a tree. The deeper the tree, the more splits/information is garnered about the data.\n",
    "\n",
    "> Notes: As depth increases, likelihood of overfitting the data increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.600\n",
      "===== Accuracy Test: 0.596\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.60      3148\n",
      "   macro avg       0.42      0.58      0.48      3148\n",
      "weighted avg       0.44      0.60      0.49      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.699\n",
      "===== Accuracy Test: 0.692\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.81      0.66      1014\n",
      "           1       0.88      0.81      0.85      1137\n",
      "           2       0.67      0.44      0.53       997\n",
      "\n",
      "    accuracy                           0.69      3148\n",
      "   macro avg       0.71      0.69      0.68      3148\n",
      "weighted avg       0.71      0.69      0.69      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.744\n",
      "===== Accuracy Test: 0.734\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      1014\n",
      "           1       0.88      0.82      0.85      1137\n",
      "           2       0.63      0.64      0.64       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.74      0.73      0.74      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.789\n",
      "===== Accuracy Test: 0.771\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.64      0.76      0.69       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.78      0.77      0.77      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.820\n",
      "===== Accuracy Test: 0.785\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.62      0.67       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.79      0.78      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.858\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.74      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.888\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.919\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.943\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.964\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.78      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.976\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.983\n",
      "===== Accuracy Test: 0.844\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.78      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.988\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.990\n",
      "===== Accuracy Test: 0.844\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.991\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.992\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.993\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.994\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.995\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max depth: 1.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "\n",
    "for depth in max_depths:\n",
    "    # Initialize Classifier with max_depth\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_train, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_train)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For max depth:\", max_depth)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Depth 83.7%, max-depth=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Samples Splits [Decision Trees Hyperparameter Tuning]\n",
    "The minimum number of samples required to split a node. If increased, tree considers more samples at each decision node.\n",
    "\n",
    "> Notes: Causes more underfitting as it increases number of samples per decision node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.775\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70      1014\n",
      "           1       0.88      0.87      0.87      1137\n",
      "           2       0.62      0.76      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.75      0.75      3148\n",
      "weighted avg       0.77      0.76      0.76      3148\n",
      "\n",
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.757\n",
      "===== Accuracy Test: 0.741\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71      1014\n",
      "           1       0.89      0.80      0.84      1137\n",
      "           2       0.60      0.76      0.67       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.76      0.74      0.74      3148\n",
      "weighted avg       0.76      0.74      0.75      3148\n",
      "\n",
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.754\n",
      "===== Accuracy Test: 0.742\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71      1014\n",
      "           1       0.88      0.81      0.85      1137\n",
      "           2       0.60      0.76      0.67       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.76      0.74      0.74      3148\n",
      "weighted avg       0.76      0.74      0.75      3148\n",
      "\n",
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.721\n",
      "===== Accuracy Test: 0.711\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.63      0.56      0.59       997\n",
      "\n",
      "    accuracy                           0.71      3148\n",
      "   macro avg       0.70      0.71      0.70      3148\n",
      "weighted avg       0.71      0.71      0.71      3148\n",
      "\n",
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.681\n",
      "===== Accuracy Test: 0.670\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.81      0.66      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.70      0.35      0.47       997\n",
      "\n",
      "    accuracy                           0.67      3148\n",
      "   macro avg       0.68      0.66      0.65      3148\n",
      "weighted avg       0.69      0.67      0.65      3148\n",
      "\n",
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.681\n",
      "===== Accuracy Test: 0.670\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.81      0.66      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.70      0.35      0.47       997\n",
      "\n",
      "    accuracy                           0.67      3148\n",
      "   macro avg       0.68      0.66      0.65      3148\n",
      "weighted avg       0.69      0.67      0.65      3148\n",
      "\n",
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.600\n",
      "===== Accuracy Test: 0.596\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.60      3148\n",
      "   macro avg       0.42      0.58      0.48      3148\n",
      "weighted avg       0.44      0.60      0.49      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.600\n",
      "===== Accuracy Test: 0.596\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.60      3148\n",
      "   macro avg       0.42      0.58      0.48      3148\n",
      "weighted avg       0.44      0.60      0.49      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.600\n",
      "===== Accuracy Test: 0.596\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.60      3148\n",
      "   macro avg       0.42      0.58      0.48      3148\n",
      "weighted avg       0.44      0.60      0.49      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min sample splits: 0.1\n",
      "===== Accuracy Train: 0.600\n",
      "===== Accuracy Test: 0.596\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.60      3148\n",
      "   macro avg       0.42      0.58      0.48      3148\n",
      "weighted avg       0.44      0.60      0.49      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "\n",
    "for split in min_samples_splits:\n",
    "    # Initialize Classifier with minimum samples split\n",
    "    dt = DecisionTreeClassifier(min_samples_split=split)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_train, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_train)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For min sample splits:\", min_samples_split)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Minimum Sample Splits 75.9%, min sample splits = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Samples Leaf [Decision Trees Hyperparameter Tuning]\n",
    "The minimum number of samples required for each leaf node.\n",
    "> Notes: May cause underfitting if increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min samples leafs: 0.1\n",
      "===== Accuracy Train: 0.724\n",
      "===== Accuracy Test: 0.709\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.58      0.71      0.64       997\n",
      "\n",
      "    accuracy                           0.71      3148\n",
      "   macro avg       0.72      0.70      0.70      3148\n",
      "weighted avg       0.73      0.71      0.71      3148\n",
      "\n",
      "For min samples leafs: 0.2\n",
      "===== Accuracy Train: 0.692\n",
      "===== Accuracy Test: 0.672\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.48      0.59      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.53      0.69      0.60       997\n",
      "\n",
      "    accuracy                           0.67      3148\n",
      "   macro avg       0.69      0.67      0.66      3148\n",
      "weighted avg       0.69      0.67      0.67      3148\n",
      "\n",
      "For min samples leafs: 0.30000000000000004\n",
      "===== Accuracy Train: 0.673\n",
      "===== Accuracy Test: 0.659\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1014\n",
      "           1       0.79      0.83      0.81      1137\n",
      "           2       0.52      0.50      0.51       997\n",
      "\n",
      "    accuracy                           0.66      3148\n",
      "   macro avg       0.65      0.65      0.65      3148\n",
      "weighted avg       0.66      0.66      0.66      3148\n",
      "\n",
      "For min samples leafs: 0.4\n",
      "===== Accuracy Train: 0.603\n",
      "===== Accuracy Test: 0.600\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.91      0.63      1014\n",
      "           1       0.77      0.85      0.81      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.60      3148\n",
      "   macro avg       0.42      0.59      0.48      3148\n",
      "weighted avg       0.43      0.60      0.50      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min samples leafs: 0.5\n",
      "===== Accuracy Train: 0.365\n",
      "===== Accuracy Test: 0.361\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1014\n",
      "           1       0.36      1.00      0.53      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.36      3148\n",
      "   macro avg       0.12      0.33      0.18      3148\n",
      "weighted avg       0.13      0.36      0.19      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaves = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "\n",
    "for min_leaf in min_samples_leaves:\n",
    "    # Initialize Classifier with minimum samples leaf\n",
    "    dt = DecisionTreeClassifier(min_samples_leaf=min_leaf)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_train, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_train)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For min samples leafs:\", min_leaf)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Minimum Sample Leaf 68.8%, min sample splits = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Features [Decision Trees Hyperparameter Tuning]\n",
    "The number of features to consider when searching for best fit.\n",
    "\n",
    "> Notes: May overfit with more features\n",
    "\n",
    "> Sklearn implementation does not stop searching for a split until a valid partition of the node samples is found, including adding more features to the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.653\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66      1014\n",
      "           1       0.72      0.73      0.73      1137\n",
      "           2       0.56      0.56      0.56       997\n",
      "\n",
      "    accuracy                           0.65      3148\n",
      "   macro avg       0.65      0.65      0.65      3148\n",
      "weighted avg       0.65      0.65      0.65      3148\n",
      "\n",
      "For max feature: 2\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.695\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      1014\n",
      "           1       0.78      0.78      0.78      1137\n",
      "           2       0.60      0.60      0.60       997\n",
      "\n",
      "    accuracy                           0.70      3148\n",
      "   macro avg       0.69      0.69      0.69      3148\n",
      "weighted avg       0.69      0.70      0.69      3148\n",
      "\n",
      "For max feature: 3\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.703\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70      1014\n",
      "           1       0.78      0.77      0.78      1137\n",
      "           2       0.61      0.63      0.62       997\n",
      "\n",
      "    accuracy                           0.70      3148\n",
      "   macro avg       0.70      0.70      0.70      3148\n",
      "weighted avg       0.70      0.70      0.70      3148\n",
      "\n",
      "For max feature: 4\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.730\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74      1014\n",
      "           1       0.80      0.81      0.80      1137\n",
      "           2       0.64      0.63      0.63       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.73      0.73      0.73      3148\n",
      "\n",
      "For max feature: 5\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.730\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1014\n",
      "           1       0.80      0.78      0.79      1137\n",
      "           2       0.64      0.66      0.65       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.73      0.73      0.73      3148\n",
      "\n",
      "For max feature: 6\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.748\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1014\n",
      "           1       0.83      0.84      0.84      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 7\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.750\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.65      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 8\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1014\n",
      "           1       0.84      0.85      0.84      1137\n",
      "           2       0.67      0.68      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 9\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.752\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73      1014\n",
      "           1       0.83      0.84      0.83      1137\n",
      "           2       0.67      0.70      0.68       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 10\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.764\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      1014\n",
      "           1       0.83      0.84      0.84      1137\n",
      "           2       0.69      0.65      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 11\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.760\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 12\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.767\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1014\n",
      "           1       0.84      0.86      0.85      1137\n",
      "           2       0.68      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 13\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.775\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1014\n",
      "           1       0.86      0.86      0.86      1137\n",
      "           2       0.69      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 14\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.784\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1014\n",
      "           1       0.87      0.87      0.87      1137\n",
      "           2       0.69      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 15\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.767\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.68      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 16\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.785\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.86      0.88      0.87      1137\n",
      "           2       0.70      0.69      0.70       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.79      0.78      3148\n",
      "\n",
      "For max feature: 17\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.783\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1014\n",
      "           1       0.87      0.85      0.86      1137\n",
      "           2       0.69      0.72      0.70       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.78      0.78      3148\n",
      "\n",
      "For max feature: 18\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.787\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1014\n",
      "           1       0.87      0.86      0.87      1137\n",
      "           2       0.71      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 19\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.785\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77      1014\n",
      "           1       0.85      0.86      0.86      1137\n",
      "           2       0.70      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.78      0.79      3148\n",
      "\n",
      "For max feature: 20\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.785\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.85      0.84      0.85      1137\n",
      "           2       0.70      0.71      0.70       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.78      0.79      3148\n",
      "\n",
      "For max feature: 21\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.780\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1014\n",
      "           1       0.85      0.87      0.86      1137\n",
      "           2       0.70      0.68      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 22\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.787\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.87      0.88      0.87      1137\n",
      "           2       0.71      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 23\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.780\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.86      0.86      0.86      1137\n",
      "           2       0.69      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 24\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.783\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1014\n",
      "           1       0.87      0.86      0.86      1137\n",
      "           2       0.69      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 25\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.780\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.87      0.86      0.87      1137\n",
      "           2       0.69      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 26\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.787\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78      1014\n",
      "           1       0.89      0.86      0.87      1137\n",
      "           2       0.69      0.73      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.78      0.78      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 27\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1014\n",
      "           1       0.87      0.88      0.88      1137\n",
      "           2       0.72      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 28\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.790\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1014\n",
      "           1       0.86      0.88      0.87      1137\n",
      "           2       0.71      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 29\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.87      0.88      0.87      1137\n",
      "           2       0.71      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 30\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.795\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1014\n",
      "           1       0.87      0.88      0.88      1137\n",
      "           2       0.72      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.80      0.79      3148\n",
      "\n",
      "For max feature: 31\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 32\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.785\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1014\n",
      "           1       0.87      0.86      0.86      1137\n",
      "           2       0.70      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.78      0.79      3148\n",
      "\n",
      "For max feature: 33\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.787\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78      1014\n",
      "           1       0.86      0.89      0.87      1137\n",
      "           2       0.70      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 34\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.776\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.87      0.86      0.86      1137\n",
      "           2       0.69      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 35\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.791\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      1014\n",
      "           1       0.88      0.86      0.87      1137\n",
      "           2       0.71      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 36\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.87      0.88      0.87      1137\n",
      "           2       0.71      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 37\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.779\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.86      0.87      0.87      1137\n",
      "           2       0.69      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 38\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.792\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.87      0.87      0.87      1137\n",
      "           2       0.71      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 39\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 40\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.87      0.88      0.87      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 41\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.71      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 42\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.784\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.88      0.87      0.87      1137\n",
      "           2       0.69      0.71      0.70       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 43\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.72      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 44\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      1014\n",
      "           1       0.91      0.87      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 45\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.783\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1014\n",
      "           1       0.87      0.87      0.87      1137\n",
      "           2       0.70      0.68      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max feature: 46\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.87      0.90      0.88      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 47\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.792\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1014\n",
      "           1       0.87      0.88      0.87      1137\n",
      "           2       0.71      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 48\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 49\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.72      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.80      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 50\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.791\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1014\n",
      "           1       0.87      0.89      0.88      1137\n",
      "           2       0.71      0.68      0.70       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 51\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.72      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 52\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 53\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.790\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1014\n",
      "           1       0.87      0.90      0.88      1137\n",
      "           2       0.70      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 54\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.789\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1014\n",
      "           1       0.87      0.87      0.87      1137\n",
      "           2       0.70      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 55\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 56\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 57\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 58\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.798\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.89      0.86      0.87      1137\n",
      "           2       0.71      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 59\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 60\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.81      0.81      3148\n",
      "\n",
      "For max feature: 61\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.71      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.80      0.81      3148\n",
      "\n",
      "For max feature: 62\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 63\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.797\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.70      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 64\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.72      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 65\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.793\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1014\n",
      "           1       0.87      0.88      0.88      1137\n",
      "           2       0.71      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 66\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.71      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.80      0.80      3148\n",
      "\n",
      "For max feature: 67\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 68\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.71      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 69\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.71      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 70\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 71\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 72\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.87      0.89      0.88      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 73\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.795\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.70      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 74\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 75\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 76\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1014\n",
      "           1       0.89      0.88      0.88      1137\n",
      "           2       0.72      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 77\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.72      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 78\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 79\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 80\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 81\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.81      0.80      3148\n",
      "\n",
      "For max feature: 82\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.88      0.89      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 83\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 84\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.71      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 85\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 86\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 87\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.87      0.89      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 88\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 89\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.789\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.70      0.71      0.70       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 90\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.71      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 91\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.87      0.89      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 92\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.72      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.81      0.81      3148\n",
      "\n",
      "For max feature: 93\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 94\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.70      0.74      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.80      0.80      3148\n",
      "\n",
      "For max feature: 95\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 96\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 97\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 98\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 99\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 100\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 101\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.796\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.70      0.70      0.70       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 102\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.81      0.81      3148\n",
      "\n",
      "For max feature: 103\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.72      0.75      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 104\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 105\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 106\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.70      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 107\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.74      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 108\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 109\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.804\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.73      0.70      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 110\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 111\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 112\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 113\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 114\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 115\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 116\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 117\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 118\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.71      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 119\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 120\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.87      0.89      0.88      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 121\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 122\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.70      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.79      0.79      0.79      3148\n",
      "\n",
      "For max feature: 123\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 124\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 125\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 126\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.71      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 127\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 128\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 129\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 130\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.799\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.71      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 131\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 132\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 133\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 134\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 135\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 136\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.87      0.89      0.88      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 137\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.71      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 138\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 139\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 140\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.88      0.89      0.88      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 141\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.88      0.90      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 142\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 143\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 144\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 145\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 146\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.794\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1014\n",
      "           1       0.88      0.87      0.88      1137\n",
      "           2       0.71      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.79      3148\n",
      "   macro avg       0.79      0.79      0.79      3148\n",
      "weighted avg       0.80      0.79      0.79      3148\n",
      "\n",
      "For max feature: 147\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 148\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.81      3148\n",
      "\n",
      "For max feature: 149\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.72      0.75      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 150\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 151\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 152\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 153\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.71      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 154\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 155\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 156\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 157\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.72      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 158\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 159\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.71      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 160\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 161\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 162\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 163\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.88      0.88      0.88      1137\n",
      "           2       0.71      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 164\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 165\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.88      0.91      0.90      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 166\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.72      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 167\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 168\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 169\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 170\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 171\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 172\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 173\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 174\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.88      0.91      0.90      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 175\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.71      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 176\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.805\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.87      0.89      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.80      0.81      3148\n",
      "\n",
      "For max feature: 177\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 178\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 179\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 180\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 181\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 182\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 183\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 184\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 185\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 186\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 187\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 188\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 189\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 190\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 191\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 192\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 193\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 194\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 195\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 196\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 197\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 198\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 199\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.88      0.91      0.89      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 200\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.72      0.75      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 201\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.71      0.71      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 202\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 203\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 204\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 205\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 206\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 207\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 208\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 209\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 210\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 211\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 212\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 213\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 214\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 215\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 216\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 217\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 218\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 219\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 220\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 221\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 222\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 223\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 224\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 225\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 226\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 227\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 228\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.88      0.91      0.89      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 229\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 230\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 231\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 232\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 233\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 234\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 235\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 236\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 237\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 238\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 239\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 240\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 241\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 242\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 243\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 244\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 245\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.806\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 246\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 247\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 248\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 249\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 250\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 251\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 252\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 253\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 254\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 255\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 256\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 257\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 258\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 259\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 260\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 261\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 262\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.71      0.74      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 263\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 264\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 265\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 266\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 267\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 268\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 269\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 270\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 271\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 272\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 273\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n",
      "For max feature: 274\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 275\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 276\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 277\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.802\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.70      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 278\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 279\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 280\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 281\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 282\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 283\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 284\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 285\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 286\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.803\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.89      0.88      0.89      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 287\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 288\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 289\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 290\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 291\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 292\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 293\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.88      0.89      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 294\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 295\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 296\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 297\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 298\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 299\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 300\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 301\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 302\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 303\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 304\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 305\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 306\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 307\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.93      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 308\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 309\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 310\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.88      0.90      1137\n",
      "           2       0.72      0.75      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 311\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 312\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 313\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 314\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 315\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 316\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 317\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 318\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 319\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 320\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.91      0.88      0.90      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 321\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 322\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 323\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 324\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 325\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 326\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 327\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 328\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 329\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 330\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 331\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 332\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 333\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 334\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 335\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.72      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 336\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 337\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 338\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.74      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 339\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 340\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.70      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 341\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 342\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 343\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 344\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 345\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 346\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 347\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 348\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 349\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 350\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.808\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 351\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 352\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 353\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 354\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 355\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 356\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 357\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 358\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 359\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 360\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 361\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 362\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 363\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 364\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 365\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 366\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 367\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 368\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 369\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 370\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 371\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 372\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 373\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.801\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.71      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 374\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 375\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 376\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 377\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 378\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 379\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 380\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 381\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 382\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 383\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 384\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.83      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 385\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 386\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.71      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 387\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 388\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.78      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 389\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 390\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 391\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 392\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 393\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 394\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 395\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 396\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 397\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 398\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 399\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 400\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.72      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 401\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 402\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 403\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 404\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 405\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 406\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 407\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 408\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.93      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 409\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 410\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.75      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 411\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 412\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 413\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 414\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 415\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 416\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 417\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 418\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 419\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 420\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 421\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.800\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.71      0.72      0.71       997\n",
      "\n",
      "    accuracy                           0.80      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.80      0.80      0.80      3148\n",
      "\n",
      "For max feature: 422\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 423\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 424\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 425\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 426\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 427\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 428\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 429\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 430\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 431\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 432\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.88      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 433\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 434\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 435\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 436\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.77      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 437\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 438\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 439\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 440\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 441\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 442\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 443\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 444\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 445\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 446\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 447\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 448\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 449\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 450\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 451\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.84      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 452\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 453\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.89      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 454\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 455\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 456\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 457\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 458\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 459\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 460\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 461\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 462\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 463\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 464\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.94      0.93      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.83      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 465\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 466\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 467\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.84      3148\n",
      "\n",
      "For max feature: 468\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 469\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 470\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 471\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 472\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 473\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 474\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 475\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.74      0.70      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.81      3148\n",
      "\n",
      "For max feature: 476\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 477\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 478\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 479\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 480\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 481\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 482\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 483\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 484\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 485\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 486\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 487\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 488\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 489\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 490\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.88      0.91      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 491\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 492\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 493\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 494\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 495\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 496\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 497\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 498\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 499\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 500\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 501\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 502\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 503\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 504\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 505\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 506\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 507\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n",
      "For max feature: 508\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 509\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 510\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 511\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 512\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 513\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 514\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 515\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 516\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 517\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 518\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 519\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 520\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 521\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 522\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 523\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 524\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 525\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 526\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 527\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 528\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 529\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 530\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 531\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 532\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.71      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 533\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 534\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 535\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 536\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 537\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 538\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 539\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 540\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 541\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 542\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 543\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 544\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 545\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 546\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 547\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 548\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 549\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 550\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 551\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 552\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 553\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 554\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 555\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 556\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.71      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n",
      "For max feature: 557\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 558\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 559\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 560\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 561\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 562\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 563\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 564\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 565\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 566\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 567\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 568\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 569\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 570\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 571\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 572\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 573\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 574\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 575\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 576\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 577\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 578\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 579\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 580\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 581\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 582\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 583\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 584\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.77      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 585\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 586\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.83      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 587\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 588\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 589\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 590\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 591\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 592\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 593\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 594\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 595\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 596\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 597\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 598\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.70      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 599\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 600\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 601\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 602\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 603\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 604\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.82      3148\n",
      "\n",
      "For max feature: 605\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 606\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 607\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 608\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 609\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 610\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 611\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 612\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 613\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 614\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 615\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 616\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 617\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 618\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 619\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.88      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 620\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 621\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.82      3148\n",
      "\n",
      "For max feature: 622\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 623\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 624\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 625\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 626\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 627\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 628\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 629\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 630\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.93      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 631\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.89      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 632\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 633\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 634\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 635\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 636\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 637\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 638\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 639\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 640\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 641\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 642\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 643\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 644\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 645\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 646\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 647\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 648\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 649\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 650\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 651\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 652\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.89      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 653\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 654\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 655\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 656\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 657\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 658\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 659\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 660\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 661\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 662\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 663\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 664\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 665\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 666\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 667\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 668\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 669\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 670\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 671\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 672\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 673\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 674\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 675\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.810\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 676\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 677\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 678\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 679\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 680\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 681\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 682\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 683\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 684\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 685\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 686\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 687\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 688\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 689\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 690\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 691\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 692\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 693\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 694\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 695\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 696\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 697\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 698\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 699\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 700\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 701\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 702\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 703\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 704\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 705\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 706\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 707\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 708\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 709\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.88      0.91      0.90      1137\n",
      "           2       0.76      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 710\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 711\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 712\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 713\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 714\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 715\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 716\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.89      0.93      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 717\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 718\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 719\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 720\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 721\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 722\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 723\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 724\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 725\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 726\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 727\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 728\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 729\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 730\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 731\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 732\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 733\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 734\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 735\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 736\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 737\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 738\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 739\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 740\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 741\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 742\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 743\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 744\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 745\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 746\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 747\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 748\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.811\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.71      0.73      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 749\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 750\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 751\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 752\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 753\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 754\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.84      3148\n",
      "\n",
      "For max feature: 755\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 756\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 757\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 758\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 759\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 760\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 761\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 762\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 763\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 764\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 765\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 766\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 767\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n",
      "For max feature: 768\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 769\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 770\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 771\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 772\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 773\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 774\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.77      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 775\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 776\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 777\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 778\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 779\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 780\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 781\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 782\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 783\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 784\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 785\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 786\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 787\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 788\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 789\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 790\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 791\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 792\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.83      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 793\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 794\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 795\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 796\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 797\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 798\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 799\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.844\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 800\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 801\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 802\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 803\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 804\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 805\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 806\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 807\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 808\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 809\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 810\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 811\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 812\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 813\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 814\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 815\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 816\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 817\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 818\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 819\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 820\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 821\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 822\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 823\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 824\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 825\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 826\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n",
      "For max feature: 827\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 828\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 829\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 830\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 831\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.84      3148\n",
      "\n",
      "For max feature: 832\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 833\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 834\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 835\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 836\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 837\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 838\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 839\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 840\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 841\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.846\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.79      0.78       997\n",
      "\n",
      "    accuracy                           0.85      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.85      0.85      0.85      3148\n",
      "\n",
      "For max feature: 842\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 843\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 844\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 845\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 846\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 847\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 848\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 849\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 850\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 851\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.93      0.89      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 852\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 853\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 854\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 855\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 856\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 857\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 858\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 859\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.72      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 860\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 861\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 862\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 863\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 864\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 865\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 866\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 867\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 868\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 869\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 870\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 871\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 872\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 873\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 874\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 875\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.807\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.70      0.71       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 876\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 877\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 878\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 879\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 880\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 881\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 882\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 883\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 884\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 885\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 886\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 887\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 888\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 889\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.843\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 890\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 891\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 892\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 893\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 894\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 895\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 896\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 897\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 898\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 899\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 900\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 901\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 902\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 903\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 904\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 905\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 906\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 907\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 908\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 909\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 910\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 911\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 912\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 913\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 914\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 915\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 916\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 917\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 918\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 919\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 920\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 921\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 922\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 923\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 924\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 925\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 926\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.843\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.80      0.78       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 927\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 928\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 929\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.93      0.89      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 930\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 931\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 932\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 933\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 934\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.88      0.90      0.89      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 935\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 936\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 937\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 938\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 939\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 940\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 941\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.845\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.94      0.93      0.93      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 942\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 943\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 944\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 945\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 946\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 947\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 948\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 949\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 950\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 951\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 952\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 953\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 954\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 955\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 956\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 957\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 958\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 959\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 960\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 961\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 962\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 963\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 964\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 965\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 966\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 967\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 968\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 969\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 970\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 971\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 972\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 973\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 974\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 975\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 976\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 977\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 978\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 979\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 980\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 981\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 982\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 983\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 984\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 985\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 986\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1014\n",
      "           1       0.92      0.89      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 987\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 988\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 989\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 990\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 991\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 992\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 993\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 994\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 995\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 996\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 997\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 998\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 999\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1000\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1001\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1002\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1003\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1004\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1005\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1006\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1007\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1008\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1009\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1010\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1011\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1012\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1013\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1014\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.89      0.90      0.89      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1015\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1016\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1017\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1018\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1019\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1020\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1021\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1022\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1023\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1024\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1025\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1026\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1027\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.82      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1028\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1029\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1030\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1031\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1032\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1033\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1034\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1035\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.89      0.90      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1036\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1037\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1038\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1039\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1040\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1041\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1042\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1043\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1044\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1045\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1046\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1047\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1048\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1049\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.93      0.91      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1050\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.77      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1051\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1052\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1053\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1054\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1055\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1056\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1057\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1058\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1059\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1060\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1061\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1062\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1063\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1064\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.93      0.93      0.93      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1065\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1066\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1067\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1068\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1069\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1070\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1071\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1072\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1073\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1074\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1075\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1076\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1077\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.82      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1078\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1079\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1080\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1081\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1082\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1083\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1084\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1085\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1086\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1087\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1088\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1089\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1090\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.78      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1091\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1092\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1093\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1094\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1095\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1096\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1097\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1098\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.84      3148\n",
      "\n",
      "For max feature: 1099\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1100\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1101\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1102\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1103\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1104\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 1105\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1106\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1107\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1108\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1109\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1110\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1111\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1112\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1113\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1114\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1115\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1116\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1117\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1118\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1119\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1120\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1121\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1122\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1123\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.845\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.85      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.85      0.85      0.85      3148\n",
      "\n",
      "For max feature: 1124\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1125\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1126\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1127\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1128\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1129\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.84      3148\n",
      "\n",
      "For max feature: 1130\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1131\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1132\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1133\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1134\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1135\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1136\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1137\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.844\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.78      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1138\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1139\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1140\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1141\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1142\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1143\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1144\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1145\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1146\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1147\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1148\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1149\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1150\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1151\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1152\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1153\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1154\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1155\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1156\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1157\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1158\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1159\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1160\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1161\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1162\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1163\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1164\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1165\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1166\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1167\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1168\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1169\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1170\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1171\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1172\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1173\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1174\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1175\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1176\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1177\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1178\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1179\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1180\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1181\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1182\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1183\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1184\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1185\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1186\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.89      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1187\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1188\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1189\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1190\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1191\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1192\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1193\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1194\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1195\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1196\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1197\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1198\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.72      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1199\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1200\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1201\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.78      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1202\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1203\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1204\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1205\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1206\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1207\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1208\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1209\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1210\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1211\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1212\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1213\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1214\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.93      0.92      0.93      1137\n",
      "           2       0.75      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1215\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1216\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1217\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1218\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1219\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1220\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1221\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1222\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1223\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1224\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1225\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1226\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1227\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1228\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1229\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1230\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1231\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1232\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1233\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1234\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1235\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1236\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1237\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1238\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1239\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1240\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1241\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1242\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1243\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1244\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1245\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1246\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1247\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.82      3148\n",
      "\n",
      "For max feature: 1248\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1249\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1250\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1251\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1252\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1253\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1254\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1255\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1256\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1257\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1258\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1259\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1260\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1261\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1262\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1263\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1264\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1265\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1266\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1267\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1268\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1269\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1270\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1271\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1272\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1273\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1274\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1275\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1276\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1277\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1278\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1279\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1280\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1281\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1282\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1283\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1284\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.90      0.88      0.89      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1285\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1286\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1287\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1288\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1289\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1290\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1291\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.83      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1292\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 1293\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1294\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1295\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1296\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1297\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1298\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1299\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 1300\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1301\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1302\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1303\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.72      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1304\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1305\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1306\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1307\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1308\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1309\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1310\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1311\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1312\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.71      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.82      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1313\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1314\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1315\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1316\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1317\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1318\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1319\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1320\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1321\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1322\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1323\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1324\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1325\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1326\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1327\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1328\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1329\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1330\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1331\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1332\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1333\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1334\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1335\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1336\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1337\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1338\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1339\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1340\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1341\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1342\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1343\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1344\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1345\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.71      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1346\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1347\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1348\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1349\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1350\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1351\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1352\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1353\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1354\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1355\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1356\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1357\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1358\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1359\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1360\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1361\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1362\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1363\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1364\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1365\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1366\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1367\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1368\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1369\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1370\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1371\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1372\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1373\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1374\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1375\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1376\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1377\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1378\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1379\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1380\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1381\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1382\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1383\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1384\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1385\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1386\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1387\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 1388\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1389\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1390\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1391\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1392\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1393\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1394\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1395\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.84      3148\n",
      "\n",
      "For max feature: 1396\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1397\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1398\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.84      3148\n",
      "\n",
      "For max feature: 1399\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1400\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1401\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1402\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1403\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1404\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1405\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1406\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1407\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1408\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.82      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1409\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1410\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1411\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1412\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1413\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1414\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1415\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1416\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1417\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1418\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1419\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1420\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1421\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1422\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1423\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1424\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1425\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1426\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.72      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1427\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1428\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1429\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1430\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1431\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1432\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.71      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1433\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1434\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1435\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1436\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1437\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1438\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1439\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1440\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1441\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1442\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1443\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1444\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1445\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1446\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1447\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1448\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1449\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1450\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1451\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1452\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1453\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1454\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.94      0.92      0.93      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1455\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1456\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.71      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1457\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1458\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1459\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1460\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1461\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1462\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1463\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1464\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1465\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1466\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1467\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.844\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1468\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1469\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1470\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1471\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1472\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1473\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1474\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1475\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1476\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1477\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1478\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.88      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1479\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1480\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1481\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1482\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1483\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1484\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1485\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1486\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1487\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1488\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1489\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1490\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1491\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1492\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1493\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1494\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1495\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1496\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1497\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.93      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1498\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1499\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1500\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1501\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1502\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1503\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1504\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1505\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1506\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1507\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1508\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1509\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1510\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1511\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1512\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1513\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1514\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1515\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1516\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1517\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1518\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1519\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1520\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1521\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1522\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1523\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1524\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1525\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1526\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1527\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1528\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1529\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1530\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1531\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1532\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1533\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1534\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1535\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.846\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.78      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.85      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.85      0.85      0.85      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1536\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1537\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1538\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1539\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1540\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1541\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1542\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1543\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1544\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.89      0.90      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1545\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1546\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1547\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1548\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1549\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1550\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1551\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1552\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1553\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1554\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.843\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1555\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1556\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1557\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1558\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1559\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1560\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1561\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1562\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1563\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1564\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1565\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1566\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1567\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1568\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.79      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1569\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1570\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1571\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1572\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1573\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1574\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1575\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1576\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1577\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1578\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1579\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1580\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1581\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1582\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1583\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1584\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1585\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1586\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1587\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1588\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1589\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1590\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1591\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1592\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1593\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1594\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1595\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.844\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.78      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1596\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1597\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1598\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1599\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1600\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.89      0.89      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1601\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1602\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1603\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1604\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1605\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1606\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1607\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1608\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1609\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1610\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1611\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.93      0.90      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1612\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1613\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1614\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1615\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1616\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1617\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1618\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1619\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1620\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1621\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.72      0.75      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1622\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1623\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1624\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1625\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1626\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.72      0.75      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1627\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1628\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1629\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1630\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1631\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1632\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1633\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1634\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1635\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1636\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1637\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1638\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1639\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1640\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1641\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1642\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1643\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1644\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1645\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 1646\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1647\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1648\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1649\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1650\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1651\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.93      0.90      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1652\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1653\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.78      0.78       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1654\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1655\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1656\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1657\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1658\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1659\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1660\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1661\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1662\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1663\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1664\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1665\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1666\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1667\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1668\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1669\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1670\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1671\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1672\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1673\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1674\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1675\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1676\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1677\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1678\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1679\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1680\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1681\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1682\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1683\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1684\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 1685\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1686\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1687\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1688\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1689\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.89      0.90      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1690\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1691\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1692\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1693\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1694\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1695\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1696\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1697\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1698\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.80      0.80      0.80      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1699\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.93      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1700\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1701\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1702\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1703\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1704\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1705\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1706\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1707\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1708\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1709\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1710\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 1711\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.93      0.92      0.93      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1712\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1713\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1714\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1715\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1716\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1717\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.94      0.93      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1718\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1719\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1720\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1721\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1722\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1723\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1724\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1725\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1726\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1727\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1728\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.76      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1729\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1730\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1731\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1732\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1733\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1734\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1735\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1736\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1737\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1738\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1739\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1740\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1741\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1742\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1743\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1744\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1745\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.89      0.92      0.90      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1746\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1747\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1748\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1749\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1750\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1751\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1752\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1753\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.79      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1754\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1755\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1756\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.71      0.72       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1757\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1758\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1759\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1760\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1761\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1762\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1763\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1764\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1765\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1766\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1767\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1768\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.93      0.90      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1769\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1770\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.89      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1771\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1772\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 1773\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1774\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1775\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1776\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1777\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1778\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1779\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1780\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1781\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1782\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1783\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1784\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1785\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1786\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1787\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1788\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1789\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1790\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1791\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1792\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1793\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1794\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1795\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1796\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1797\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1798\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1799\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1800\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1801\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1802\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1803\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1804\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1805\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1806\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1807\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1808\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1809\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1810\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1811\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1812\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1813\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1814\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1815\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1816\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1817\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1818\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1819\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1820\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1821\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1822\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1823\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1824\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1825\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1826\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1827\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1828\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.84      3148\n",
      "\n",
      "For max feature: 1829\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1830\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1831\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1832\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1833\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1834\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1835\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1836\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1837\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1838\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.94      0.93      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1839\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1840\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1841\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1842\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1843\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.849\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.79      0.76      0.78       997\n",
      "\n",
      "    accuracy                           0.85      3148\n",
      "   macro avg       0.85      0.85      0.85      3148\n",
      "weighted avg       0.85      0.85      0.85      3148\n",
      "\n",
      "For max feature: 1844\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1845\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1846\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1847\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1848\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1849\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 1850\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1851\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1852\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1853\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1854\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1855\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1856\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1857\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.83      3148\n",
      "\n",
      "For max feature: 1858\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1859\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1860\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1861\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1862\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1863\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.78      0.75      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1864\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1865\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1866\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1867\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1868\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1869\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1870\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1871\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1872\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1873\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1874\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1875\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1876\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1877\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.78      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1878\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1879\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1880\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1881\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1882\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1883\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.78      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1884\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1885\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1886\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1887\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1888\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1889\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1890\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1891\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1892\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1893\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1894\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1895\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1896\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1897\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1898\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1899\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1900\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1901\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1902\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1903\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1904\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1905\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1906\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1907\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1908\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1909\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1910\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1911\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.79      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1912\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1913\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1914\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1915\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 1916\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1917\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1918\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1919\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1920\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1921\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1922\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1923\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1924\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1925\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1926\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1927\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1928\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1929\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1930\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1931\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1932\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1933\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1934\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1935\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1936\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1937\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1938\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1939\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1940\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1941\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1942\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1943\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1944\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1945\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1946\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1947\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1948\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1949\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1950\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1951\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1952\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1953\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1954\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1955\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1956\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1957\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1958\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1959\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1960\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1961\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1962\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1963\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 1964\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1965\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1966\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1967\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1968\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1969\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1970\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.79      0.78       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1971\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1972\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.89      0.90      0.90      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1973\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1974\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1975\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1976\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1977\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.89      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1978\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1979\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1980\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1981\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1982\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1983\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1984\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1985\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1986\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1987\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1988\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1989\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1990\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1991\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1992\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 1993\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1994\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1995\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1996\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1997\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 1998\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 1999\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2000\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2001\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.78      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2002\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2003\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2004\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2005\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2006\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2007\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2008\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2009\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2010\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2011\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2012\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.815\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.81      0.82      3148\n",
      "\n",
      "For max feature: 2013\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 2014\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2015\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2016\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2017\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2018\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2019\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2020\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2021\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2022\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2023\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2024\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2025\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2026\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2027\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2028\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2029\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2030\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2031\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2032\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2033\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2034\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2035\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2036\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.72      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2037\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2038\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2039\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2040\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2041\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2042\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2043\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2044\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.93      0.93      0.93      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2045\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2046\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2047\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2048\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2049\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2050\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2051\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2052\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2053\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2054\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2055\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2056\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2057\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2058\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2059\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2060\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.78      0.73      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2061\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.93      0.93      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2062\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2063\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2064\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2065\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2066\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2067\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2068\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.845\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.77      0.78      0.78       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.85      0.84      0.85      3148\n",
      "\n",
      "For max feature: 2069\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2070\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2071\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2072\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2073\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2074\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2075\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2076\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2077\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2078\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2079\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.89      0.92      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2080\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2081\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2082\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2083\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2084\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2085\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2086\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2087\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.813\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 2088\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2089\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2090\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.816\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2091\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2092\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2093\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2094\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.77      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2095\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2096\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2097\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2098\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2099\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2100\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2101\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2102\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2103\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2104\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2105\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.840\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2106\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2107\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2108\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2109\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.93      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2110\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2111\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2112\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2113\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2114\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2115\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.83      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2116\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2117\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2118\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2119\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2120\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2121\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2122\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.71      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2123\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 2124\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2125\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2126\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2127\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2128\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2129\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2130\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2131\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2132\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2133\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2134\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 2135\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2136\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2137\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2138\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2139\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2140\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2141\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2142\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2143\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2144\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2145\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2146\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2147\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2148\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2149\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2150\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2151\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2152\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2153\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2154\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2155\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2156\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2157\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 2158\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2159\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.846\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.78      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.85      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.85      0.85      0.85      3148\n",
      "\n",
      "For max feature: 2160\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2161\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.93      0.91      0.92      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 2162\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2163\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2164\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2165\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2166\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2167\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2168\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2169\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.82      3148\n",
      "\n",
      "For max feature: 2170\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2171\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.73      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2172\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2173\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2174\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.818\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2175\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2176\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2177\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2178\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2179\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2180\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2181\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2182\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.78      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2183\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2184\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2185\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2186\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2187\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2188\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2189\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2190\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2191\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2192\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2193\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2194\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2195\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2196\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2197\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2198\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2199\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2200\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 2201\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2202\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2203\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2204\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.89      0.89      0.89      1137\n",
      "           2       0.73      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 2205\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.93      0.89      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2206\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2207\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.817\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2208\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.839\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.90      0.93      0.92      1137\n",
      "           2       0.78      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2209\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2210\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2211\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2212\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2213\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2214\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2215\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2216\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2217\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.93      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2218\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2219\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.838\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2220\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.836\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2221\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.90      0.92      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2222\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2223\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2224\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.94      0.92      0.93      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2225\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 2226\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2227\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.74      0.77      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2228\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2229\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2230\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2231\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2232\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2233\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.812\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.72      0.74      0.73       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 2234\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2235\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2236\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.89      0.90      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2237\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2238\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2239\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2240\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2241\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2242\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2243\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2244\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2245\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.77      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2246\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2247\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2248\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2249\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2250\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.77      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2251\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.81      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2252\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.90      0.91      0.90      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2253\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2254\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.75      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2255\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.92      0.89      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2256\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.845\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2257\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2258\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.82      0.83      3148\n",
      "\n",
      "For max feature: 2259\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.831\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2260\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.823\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2261\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2262\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1014\n",
      "           1       0.93      0.90      0.91      1137\n",
      "           2       0.76      0.78      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2263\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2264\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2265\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2266\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2267\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2268\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2269\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2270\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2271\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2272\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2273\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2274\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.75      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2275\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.821\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2276\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.76      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2277\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2278\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.76      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2279\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2280\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.825\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2281\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.837\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2282\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.843\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.77      0.77      0.77       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2283\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.835\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2284\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.76      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2285\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.829\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2286\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.832\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2287\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.819\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.90      0.90      0.90      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2288\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.833\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2289\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.74      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2290\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.92      0.92      0.92      1137\n",
      "           2       0.76      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2291\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      1014\n",
      "           1       0.92      0.90      0.91      1137\n",
      "           2       0.73      0.75      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2292\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.74      0.75       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2293\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.814\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1014\n",
      "           1       0.90      0.91      0.91      1137\n",
      "           2       0.73      0.72      0.72       997\n",
      "\n",
      "    accuracy                           0.81      3148\n",
      "   macro avg       0.81      0.81      0.81      3148\n",
      "weighted avg       0.81      0.81      0.81      3148\n",
      "\n",
      "For max feature: 2294\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.92      0.91      0.92      1137\n",
      "           2       0.74      0.74      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2295\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.828\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.74      0.77      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2296\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.827\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2297\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.834\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.76      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2298\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.81      0.82      0.81      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2299\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.822\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      1014\n",
      "           1       0.91      0.91      0.91      1137\n",
      "           2       0.73      0.76      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2300\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.826\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1014\n",
      "           1       0.91      0.93      0.92      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.83      0.83      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 2301\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.830\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1014\n",
      "           1       0.91      0.92      0.91      1137\n",
      "           2       0.75      0.75      0.75       997\n",
      "\n",
      "    accuracy                           0.83      3148\n",
      "   macro avg       0.83      0.83      0.83      3148\n",
      "weighted avg       0.83      0.83      0.83      3148\n",
      "\n",
      "For max feature: 2302\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.842\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1014\n",
      "           1       0.91      0.92      0.92      1137\n",
      "           2       0.77      0.76      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n",
      "For max feature: 2303\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.820\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.91      0.90      0.91      1137\n",
      "           2       0.74      0.72      0.73       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n",
      "For max feature: 2304\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.824\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      1014\n",
      "           1       0.92      0.91      0.91      1137\n",
      "           2       0.75      0.73      0.74       997\n",
      "\n",
      "    accuracy                           0.82      3148\n",
      "   macro avg       0.82      0.82      0.82      3148\n",
      "weighted avg       0.82      0.82      0.82      3148\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b85ae1cab673>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmax_feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features = list(range(1,X_train.shape[1]))\n",
    "\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(max_featuresmax_feature)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    print(\"For max feature:\", max_feature)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"501: 84%, 1138: 84.3%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Top Performing Parameters to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1138 , max_depth: 10 , min samples_split: 0.1\n",
      "===== Accuracy Train: 0.766\n",
      "===== Accuracy Test: 0.744\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.61      0.70      1014\n",
      "           1       0.83      0.85      0.84      1137\n",
      "           2       0.61      0.76      0.68       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.76      0.74      0.74      3148\n",
      "weighted avg       0.76      0.74      0.74      3148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimum Samples Leaf is excluded since it underperformed by a great margin in comparison \n",
    "# to the No Hyperparameter Tuning model, in terms of accuracy\n",
    "# For one instance both incorrect wear of face mask and correct wear of face mask classifications are never predicted\n",
    "# Since Incorrect Wear of Face Masks is the top performing classification, and performed worse for this parameter tuning\n",
    "# this parameter was excluded.\n",
    "\n",
    "best_max_depth = 10\n",
    "best_max_feature = 1138\n",
    "best_min_samples_split = 0.1 # consider also excluding due to underperformance in parameter exploration\n",
    "\n",
    "dt = DecisionTreeClassifier(max_features=best_max_feature, max_depth=10, min_samples_split=best_min_samples_split)\n",
    "dt.fit(X_train, y_train)\n",
    "train_pred = dt.predict(X_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"For max feature:\", best_max_feature, \", max_depth:\", best_max_depth, \", min samples_split:\", best_min_samples_split)\n",
    "print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Both `Minimum Samples Leaf` and `Minimum Samples Split` Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1138 , max_depth: 10\n",
      "===== Accuracy Train: 0.958\n",
      "===== Accuracy Test: 0.841\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.78      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimum Samples Leaf is excluded since it underperformed by a great margin in comparison \n",
    "# to the No Hyperparameter Tuning model, in terms of accuracy\n",
    "# For one instance both incorrect wear of face mask and correct wear of face mask classifications are never predicted\n",
    "# Since Incorrect Wear of Face Masks is the top performing classification, and performed worse for this parameter tuning\n",
    "# this parameter was excluded.\n",
    "\n",
    "best_max_depth = 10\n",
    "best_max_feature = 1138\n",
    "\n",
    "# Excluding due to underperformance in parameter exploration\n",
    "# best_min_samples_split = 0.1 \n",
    "\n",
    "dt = DecisionTreeClassifier(max_features=best_max_feature, max_depth=10)\n",
    "dt.fit(X_train, y_train)\n",
    "train_pred = dt.predict(X_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"For max feature:\", best_max_feature, \", max_depth:\", best_max_depth)\n",
    "print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# This set of features perform slightly better than the no hyperparameter tuning model with ~84% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Hyperparameter Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter Tuning Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1014\n",
      "           1       0.92      0.93      0.92      1137\n",
      "           2       0.78      0.74      0.76       997\n",
      "\n",
      "    accuracy                           0.84      3148\n",
      "   macro avg       0.84      0.84      0.84      3148\n",
      "weighted avg       0.84      0.84      0.84      3148\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Confusion Matrix for \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "# Heatmap visualization of accuracy\n",
    "sns.heatmap(cm,annot=True, fmt='.3f', linewidths=.5, square=True,cmap='Greens_r')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "title = 'Accuracy Score Test: {0}'.format(accuracy_score(y_test, y_pred))\n",
    "plt.title(title,size=15)\n",
    "\n",
    "print(\"\\nHyperparameter Tuning Classification Report\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA with Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12589, 157)\n",
      "(12589, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction with Principal Component Analysis (PCA)\n",
    "pca = PCA(0.90) # Preserve 90% of the variance\n",
    "\n",
    "X_transformed = pca.fit_transform(X_train) # Fit the pca transform with X_train\n",
    "X_test_transformed = pca.transform(X_test) # Apply transform to X_test\n",
    "\n",
    "# Training set shape after Principal Component Analysis form\n",
    "print(X_transformed.shape)\n",
    "\n",
    "# Original Training Set Shape\n",
    "# Notice we lose 3,943 features using PCA, while preserving 90% variance\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 1\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.456\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.49      0.50      1014\n",
      "           1       0.46      0.45      0.45      1137\n",
      "           2       0.41      0.42      0.42       997\n",
      "\n",
      "    accuracy                           0.46      3148\n",
      "   macro avg       0.46      0.46      0.46      3148\n",
      "weighted avg       0.46      0.46      0.46      3148\n",
      "\n",
      "For max feature: 2\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.477\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.52      0.52      1014\n",
      "           1       0.50      0.48      0.49      1137\n",
      "           2       0.41      0.43      0.42       997\n",
      "\n",
      "    accuracy                           0.48      3148\n",
      "   macro avg       0.48      0.48      0.48      3148\n",
      "weighted avg       0.48      0.48      0.48      3148\n",
      "\n",
      "For max feature: 3\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.527\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.55      1014\n",
      "           1       0.54      0.55      0.54      1137\n",
      "           2       0.48      0.50      0.49       997\n",
      "\n",
      "    accuracy                           0.53      3148\n",
      "   macro avg       0.53      0.53      0.53      3148\n",
      "weighted avg       0.53      0.53      0.53      3148\n",
      "\n",
      "For max feature: 4\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.580\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59      1014\n",
      "           1       0.64      0.66      0.65      1137\n",
      "           2       0.48      0.50      0.49       997\n",
      "\n",
      "    accuracy                           0.58      3148\n",
      "   macro avg       0.58      0.58      0.58      3148\n",
      "weighted avg       0.58      0.58      0.58      3148\n",
      "\n",
      "For max feature: 5\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.561\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62      1014\n",
      "           1       0.57      0.57      0.57      1137\n",
      "           2       0.49      0.49      0.49       997\n",
      "\n",
      "    accuracy                           0.56      3148\n",
      "   macro avg       0.56      0.56      0.56      3148\n",
      "weighted avg       0.56      0.56      0.56      3148\n",
      "\n",
      "For max feature: 6\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.558\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59      1014\n",
      "           1       0.59      0.58      0.58      1137\n",
      "           2       0.50      0.49      0.50       997\n",
      "\n",
      "    accuracy                           0.56      3148\n",
      "   macro avg       0.56      0.56      0.56      3148\n",
      "weighted avg       0.56      0.56      0.56      3148\n",
      "\n",
      "For max feature: 7\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.579\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61      1014\n",
      "           1       0.60      0.60      0.60      1137\n",
      "           2       0.52      0.53      0.52       997\n",
      "\n",
      "    accuracy                           0.58      3148\n",
      "   macro avg       0.58      0.58      0.58      3148\n",
      "weighted avg       0.58      0.58      0.58      3148\n",
      "\n",
      "For max feature: 8\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.623\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63      1014\n",
      "           1       0.68      0.69      0.69      1137\n",
      "           2       0.54      0.55      0.54       997\n",
      "\n",
      "    accuracy                           0.62      3148\n",
      "   macro avg       0.62      0.62      0.62      3148\n",
      "weighted avg       0.62      0.62      0.62      3148\n",
      "\n",
      "For max feature: 9\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.625\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1014\n",
      "           1       0.68      0.67      0.68      1137\n",
      "           2       0.54      0.56      0.55       997\n",
      "\n",
      "    accuracy                           0.63      3148\n",
      "   macro avg       0.62      0.62      0.62      3148\n",
      "weighted avg       0.63      0.63      0.63      3148\n",
      "\n",
      "For max feature: 10\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.659\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1014\n",
      "           1       0.73      0.70      0.72      1137\n",
      "           2       0.56      0.62      0.59       997\n",
      "\n",
      "    accuracy                           0.66      3148\n",
      "   macro avg       0.66      0.66      0.66      3148\n",
      "weighted avg       0.66      0.66      0.66      3148\n",
      "\n",
      "For max feature: 11\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.601\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      1014\n",
      "           1       0.63      0.65      0.64      1137\n",
      "           2       0.53      0.54      0.53       997\n",
      "\n",
      "    accuracy                           0.60      3148\n",
      "   macro avg       0.60      0.60      0.60      3148\n",
      "weighted avg       0.60      0.60      0.60      3148\n",
      "\n",
      "For max feature: 12\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.639\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65      1014\n",
      "           1       0.69      0.70      0.69      1137\n",
      "           2       0.55      0.57      0.56       997\n",
      "\n",
      "    accuracy                           0.64      3148\n",
      "   macro avg       0.64      0.64      0.64      3148\n",
      "weighted avg       0.64      0.64      0.64      3148\n",
      "\n",
      "For max feature: 13\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.624\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64      1014\n",
      "           1       0.67      0.67      0.67      1137\n",
      "           2       0.55      0.57      0.56       997\n",
      "\n",
      "    accuracy                           0.62      3148\n",
      "   macro avg       0.62      0.62      0.62      3148\n",
      "weighted avg       0.63      0.62      0.62      3148\n",
      "\n",
      "For max feature: 14\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.671\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68      1014\n",
      "           1       0.75      0.75      0.75      1137\n",
      "           2       0.57      0.59      0.58       997\n",
      "\n",
      "    accuracy                           0.67      3148\n",
      "   macro avg       0.67      0.67      0.67      3148\n",
      "weighted avg       0.67      0.67      0.67      3148\n",
      "\n",
      "For max feature: 15\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.665\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68      1014\n",
      "           1       0.73      0.72      0.73      1137\n",
      "           2       0.57      0.58      0.57       997\n",
      "\n",
      "    accuracy                           0.66      3148\n",
      "   macro avg       0.66      0.66      0.66      3148\n",
      "weighted avg       0.67      0.66      0.66      3148\n",
      "\n",
      "For max feature: 16\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.679\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68      1014\n",
      "           1       0.74      0.74      0.74      1137\n",
      "           2       0.60      0.61      0.61       997\n",
      "\n",
      "    accuracy                           0.68      3148\n",
      "   macro avg       0.68      0.68      0.68      3148\n",
      "weighted avg       0.68      0.68      0.68      3148\n",
      "\n",
      "For max feature: 17\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.662\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1014\n",
      "           1       0.73      0.74      0.73      1137\n",
      "           2       0.58      0.59      0.58       997\n",
      "\n",
      "    accuracy                           0.66      3148\n",
      "   macro avg       0.66      0.66      0.66      3148\n",
      "weighted avg       0.66      0.66      0.66      3148\n",
      "\n",
      "For max feature: 18\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.661\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68      1014\n",
      "           1       0.71      0.74      0.72      1137\n",
      "           2       0.57      0.58      0.57       997\n",
      "\n",
      "    accuracy                           0.66      3148\n",
      "   macro avg       0.66      0.66      0.66      3148\n",
      "weighted avg       0.66      0.66      0.66      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 19\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.659\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      1014\n",
      "           1       0.71      0.72      0.71      1137\n",
      "           2       0.56      0.57      0.57       997\n",
      "\n",
      "    accuracy                           0.66      3148\n",
      "   macro avg       0.66      0.66      0.66      3148\n",
      "weighted avg       0.66      0.66      0.66      3148\n",
      "\n",
      "For max feature: 20\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.702\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70      1014\n",
      "           1       0.79      0.78      0.79      1137\n",
      "           2       0.60      0.60      0.60       997\n",
      "\n",
      "    accuracy                           0.70      3148\n",
      "   macro avg       0.70      0.70      0.70      3148\n",
      "weighted avg       0.70      0.70      0.70      3148\n",
      "\n",
      "For max feature: 21\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.633\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1014\n",
      "           1       0.70      0.70      0.70      1137\n",
      "           2       0.55      0.55      0.55       997\n",
      "\n",
      "    accuracy                           0.63      3148\n",
      "   macro avg       0.63      0.63      0.63      3148\n",
      "weighted avg       0.63      0.63      0.63      3148\n",
      "\n",
      "For max feature: 22\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.679\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70      1014\n",
      "           1       0.74      0.72      0.73      1137\n",
      "           2       0.60      0.61      0.60       997\n",
      "\n",
      "    accuracy                           0.68      3148\n",
      "   macro avg       0.68      0.68      0.68      3148\n",
      "weighted avg       0.68      0.68      0.68      3148\n",
      "\n",
      "For max feature: 23\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.691\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70      1014\n",
      "           1       0.77      0.76      0.76      1137\n",
      "           2       0.60      0.62      0.61       997\n",
      "\n",
      "    accuracy                           0.69      3148\n",
      "   macro avg       0.69      0.69      0.69      3148\n",
      "weighted avg       0.69      0.69      0.69      3148\n",
      "\n",
      "For max feature: 24\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.716\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.73      1014\n",
      "           1       0.79      0.76      0.77      1137\n",
      "           2       0.62      0.66      0.64       997\n",
      "\n",
      "    accuracy                           0.72      3148\n",
      "   macro avg       0.72      0.71      0.71      3148\n",
      "weighted avg       0.72      0.72      0.72      3148\n",
      "\n",
      "For max feature: 25\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.730\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72      1014\n",
      "           1       0.79      0.82      0.81      1137\n",
      "           2       0.65      0.64      0.65       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.73      0.73      0.73      3148\n",
      "\n",
      "For max feature: 26\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.714\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72      1014\n",
      "           1       0.80      0.79      0.80      1137\n",
      "           2       0.61      0.63      0.62       997\n",
      "\n",
      "    accuracy                           0.71      3148\n",
      "   macro avg       0.71      0.71      0.71      3148\n",
      "weighted avg       0.72      0.71      0.71      3148\n",
      "\n",
      "For max feature: 27\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.702\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      1014\n",
      "           1       0.76      0.77      0.76      1137\n",
      "           2       0.62      0.61      0.61       997\n",
      "\n",
      "    accuracy                           0.70      3148\n",
      "   macro avg       0.70      0.70      0.70      3148\n",
      "weighted avg       0.70      0.70      0.70      3148\n",
      "\n",
      "For max feature: 28\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.719\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1014\n",
      "           1       0.78      0.80      0.79      1137\n",
      "           2       0.62      0.63      0.63       997\n",
      "\n",
      "    accuracy                           0.72      3148\n",
      "   macro avg       0.72      0.71      0.72      3148\n",
      "weighted avg       0.72      0.72      0.72      3148\n",
      "\n",
      "For max feature: 29\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.701\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70      1014\n",
      "           1       0.77      0.76      0.77      1137\n",
      "           2       0.61      0.64      0.63       997\n",
      "\n",
      "    accuracy                           0.70      3148\n",
      "   macro avg       0.70      0.70      0.70      3148\n",
      "weighted avg       0.70      0.70      0.70      3148\n",
      "\n",
      "For max feature: 30\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.722\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      1014\n",
      "           1       0.79      0.82      0.81      1137\n",
      "           2       0.63      0.60      0.61       997\n",
      "\n",
      "    accuracy                           0.72      3148\n",
      "   macro avg       0.72      0.72      0.72      3148\n",
      "weighted avg       0.72      0.72      0.72      3148\n",
      "\n",
      "For max feature: 31\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.719\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74      1014\n",
      "           1       0.79      0.78      0.78      1137\n",
      "           2       0.62      0.64      0.63       997\n",
      "\n",
      "    accuracy                           0.72      3148\n",
      "   macro avg       0.72      0.72      0.72      3148\n",
      "weighted avg       0.72      0.72      0.72      3148\n",
      "\n",
      "For max feature: 32\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.744\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      1014\n",
      "           1       0.81      0.81      0.81      1137\n",
      "           2       0.66      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 33\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.694\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      1014\n",
      "           1       0.76      0.76      0.76      1137\n",
      "           2       0.60      0.61      0.60       997\n",
      "\n",
      "    accuracy                           0.69      3148\n",
      "   macro avg       0.69      0.69      0.69      3148\n",
      "weighted avg       0.69      0.69      0.69      3148\n",
      "\n",
      "For max feature: 34\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.713\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1014\n",
      "           1       0.78      0.76      0.77      1137\n",
      "           2       0.61      0.63      0.62       997\n",
      "\n",
      "    accuracy                           0.71      3148\n",
      "   macro avg       0.71      0.71      0.71      3148\n",
      "weighted avg       0.71      0.71      0.71      3148\n",
      "\n",
      "For max feature: 35\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.725\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73      1014\n",
      "           1       0.80      0.82      0.81      1137\n",
      "           2       0.63      0.61      0.62       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.72      0.72      0.72      3148\n",
      "weighted avg       0.72      0.73      0.72      3148\n",
      "\n",
      "For max feature: 36\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.738\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75      1014\n",
      "           1       0.80      0.81      0.80      1137\n",
      "           2       0.65      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.73      0.73      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 37\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.734\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1014\n",
      "           1       0.81      0.79      0.80      1137\n",
      "           2       0.64      0.66      0.65       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.74      0.73      0.73      3148\n",
      "\n",
      "For max feature: 38\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.735\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1014\n",
      "           1       0.80      0.80      0.80      1137\n",
      "           2       0.64      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 39\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.724\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      1014\n",
      "           1       0.82      0.81      0.81      1137\n",
      "           2       0.63      0.63      0.63       997\n",
      "\n",
      "    accuracy                           0.72      3148\n",
      "   macro avg       0.72      0.72      0.72      3148\n",
      "weighted avg       0.72      0.72      0.72      3148\n",
      "\n",
      "For max feature: 40\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.724\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1014\n",
      "           1       0.79      0.79      0.79      1137\n",
      "           2       0.62      0.64      0.63       997\n",
      "\n",
      "    accuracy                           0.72      3148\n",
      "   macro avg       0.72      0.72      0.72      3148\n",
      "weighted avg       0.72      0.72      0.72      3148\n",
      "\n",
      "For max feature: 41\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.709\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      1014\n",
      "           1       0.79      0.78      0.78      1137\n",
      "           2       0.62      0.62      0.62       997\n",
      "\n",
      "    accuracy                           0.71      3148\n",
      "   macro avg       0.71      0.71      0.71      3148\n",
      "weighted avg       0.71      0.71      0.71      3148\n",
      "\n",
      "For max feature: 42\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.750\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 43\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.742\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74      1014\n",
      "           1       0.83      0.81      0.82      1137\n",
      "           2       0.65      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 44\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.742\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1014\n",
      "           1       0.82      0.82      0.82      1137\n",
      "           2       0.64      0.66      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 45\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.728\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74      1014\n",
      "           1       0.80      0.80      0.80      1137\n",
      "           2       0.64      0.65      0.64       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.72      0.72      3148\n",
      "weighted avg       0.73      0.73      0.73      3148\n",
      "\n",
      "For max feature: 46\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.748\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1014\n",
      "           1       0.82      0.82      0.82      1137\n",
      "           2       0.65      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 47\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.732\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1014\n",
      "           1       0.79      0.80      0.79      1137\n",
      "           2       0.65      0.63      0.64       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.73      0.73      0.73      3148\n",
      "\n",
      "For max feature: 48\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.66      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 49\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.731\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      1014\n",
      "           1       0.80      0.81      0.81      1137\n",
      "           2       0.64      0.64      0.64       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.73      0.73      0.73      3148\n",
      "\n",
      "For max feature: 50\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.741\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1014\n",
      "           1       0.82      0.81      0.81      1137\n",
      "           2       0.65      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 51\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.741\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1014\n",
      "           1       0.82      0.82      0.82      1137\n",
      "           2       0.64      0.66      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 52\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.733\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      1014\n",
      "           1       0.81      0.81      0.81      1137\n",
      "           2       0.65      0.63      0.64       997\n",
      "\n",
      "    accuracy                           0.73      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.73      0.73      0.73      3148\n",
      "\n",
      "For max feature: 53\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.745\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74      1014\n",
      "           1       0.81      0.83      0.82      1137\n",
      "           2       0.65      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 54\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1014\n",
      "           1       0.86      0.84      0.85      1137\n",
      "           2       0.66      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 55\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.752\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.65      0.66      0.65       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 56\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.82      0.82      0.82      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 57\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.740\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.64      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 58\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.83      0.81      0.82      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 59\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 60\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.743\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75      1014\n",
      "           1       0.82      0.81      0.82      1137\n",
      "           2       0.65      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 61\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.750\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1014\n",
      "           1       0.82      0.83      0.82      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 62\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1014\n",
      "           1       0.86      0.83      0.84      1137\n",
      "           2       0.65      0.69      0.67       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.75      0.76      3148\n",
      "\n",
      "For max feature: 63\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.66      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 64\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.738\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1014\n",
      "           1       0.81      0.81      0.81      1137\n",
      "           2       0.65      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.73      0.73      0.73      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 65\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.740\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74      1014\n",
      "           1       0.83      0.80      0.82      1137\n",
      "           2       0.65      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 66\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.747\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.65      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 67\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 68\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.763\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.68      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 69\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 70\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.67      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 71\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.750\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1014\n",
      "           1       0.85      0.82      0.84      1137\n",
      "           2       0.65      0.68      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 72\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.751\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.65      0.66      0.65       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 73\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.764\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1014\n",
      "           1       0.85      0.82      0.84      1137\n",
      "           2       0.67      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.76      3148\n",
      "\n",
      "For max feature: 74\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 75\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.66      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 76\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.66      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 77\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.771\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.85      0.84      0.84      1137\n",
      "           2       0.67      0.70      0.69       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 78\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.760\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 79\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.763\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.67      0.71      0.69       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.76      3148\n",
      "\n",
      "For max feature: 80\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.748\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.65      0.68      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 81\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.744\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1014\n",
      "           1       0.83      0.84      0.83      1137\n",
      "           2       0.64      0.64      0.64       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max feature: 82\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.775\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.85      0.86      0.85      1137\n",
      "           2       0.68      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.78      0.77      0.77      3148\n",
      "\n",
      "For max feature: 83\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.767\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.69      0.68      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 84\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.766\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 85\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.749\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.65      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 86\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 87\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.67      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 88\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.746\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.65      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 89\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.773\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1014\n",
      "           1       0.85      0.85      0.85      1137\n",
      "           2       0.68      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 90\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.751\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.66      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 91\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.67      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 92\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.764\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1014\n",
      "           1       0.85      0.84      0.84      1137\n",
      "           2       0.67      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.76      3148\n",
      "\n",
      "For max feature: 93\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1014\n",
      "           1       0.82      0.83      0.83      1137\n",
      "           2       0.67      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 94\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.750\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.65      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 95\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.67      0.68      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 96\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.752\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 97\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1014\n",
      "           1       0.84      0.81      0.83      1137\n",
      "           2       0.66      0.69      0.67       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.75      0.75      3148\n",
      "\n",
      "For max feature: 98\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.87      0.84      0.85      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 99\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.66      0.70      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 100\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.65      0.71      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 101\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 102\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.771\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1014\n",
      "           1       0.85      0.85      0.85      1137\n",
      "           2       0.68      0.71      0.70       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 103\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1014\n",
      "           1       0.83      0.84      0.84      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 104\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 105\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.760\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 106\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.765\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.67      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.77      3148\n",
      "\n",
      "For max feature: 107\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 108\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.775\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1014\n",
      "           1       0.85      0.84      0.85      1137\n",
      "           2       0.69      0.70      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 109\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.769\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.85      0.84      0.84      1137\n",
      "           2       0.68      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 110\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.66      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 111\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.764\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 112\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.768\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1014\n",
      "           1       0.85      0.84      0.84      1137\n",
      "           2       0.68      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 113\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.765\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.85      0.85      0.85      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.77      3148\n",
      "\n",
      "For max feature: 114\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.751\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 115\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.67      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 116\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.750\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.66      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 117\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.68      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 118\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.767\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.86      0.84      0.85      1137\n",
      "           2       0.69      0.68      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 119\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.767\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1014\n",
      "           1       0.85      0.84      0.85      1137\n",
      "           2       0.67      0.71      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 120\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.770\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1014\n",
      "           1       0.84      0.84      0.84      1137\n",
      "           2       0.69      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 121\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.761\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 122\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76      1014\n",
      "           1       0.82      0.83      0.83      1137\n",
      "           2       0.67      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 123\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.767\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1014\n",
      "           1       0.83      0.84      0.84      1137\n",
      "           2       0.68      0.68      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 124\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.764\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.76      3148\n",
      "\n",
      "For max feature: 125\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.763\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.83      0.85      0.84      1137\n",
      "           2       0.68      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 126\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.85      0.84      0.85      1137\n",
      "           2       0.65      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 127\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.764\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.85      0.84      0.84      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 128\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.761\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.67      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 129\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.65      0.67      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 130\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 131\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.760\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.67      0.70      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 132\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.745\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.64      0.67      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.74      0.75      3148\n",
      "\n",
      "For max feature: 133\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 134\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.766\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77      1014\n",
      "           1       0.83      0.85      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 135\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.766\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1014\n",
      "           1       0.86      0.84      0.85      1137\n",
      "           2       0.68      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 136\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.746\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.64      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 137\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.85      0.82      0.83      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 138\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.774\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1014\n",
      "           1       0.84      0.85      0.85      1137\n",
      "           2       0.70      0.68      0.69       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 139\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1014\n",
      "           1       0.84      0.81      0.82      1137\n",
      "           2       0.66      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 140\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1014\n",
      "           1       0.85      0.85      0.85      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 141\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.774\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1014\n",
      "           1       0.84      0.85      0.85      1137\n",
      "           2       0.69      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max feature: 142\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.763\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.68      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 143\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.83      0.83      0.83      1137\n",
      "           2       0.67      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 144\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.752\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.66      0.65      0.65       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max feature: 145\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.750\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76      1014\n",
      "           1       0.84      0.81      0.82      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 146\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.762\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.67      0.69      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 147\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 148\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1014\n",
      "           1       0.83      0.82      0.82      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 149\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.761\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 150\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 151\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.66      0.68      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 152\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.748\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.65      0.64      0.65       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 153\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 154\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.67      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max feature: 155\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.748\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.66      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.74      0.74      0.74      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max feature: 156\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.67      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since max features changed with PCA fitting, determine best about of features again\n",
    "max_features = list(range(1,X_transformed.shape[1]))\n",
    "\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "    dt.fit(X_transformed, y_train)\n",
    "    train_pred = dt.predict(X_transformed)\n",
    "    y_pred = dt.predict(X_test_transformed)\n",
    "    \n",
    "    print(\"For max feature:\", max_feature)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 82.2% accuracy with max features 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 1.0\n",
      "===== Accuracy Train: 0.531\n",
      "===== Accuracy Test: 0.522\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.76      0.58      1014\n",
      "           1       0.58      0.77      0.66      1137\n",
      "           2       0.00      0.00      0.00       997\n",
      "\n",
      "    accuracy                           0.52      3148\n",
      "   macro avg       0.35      0.51      0.41      3148\n",
      "weighted avg       0.36      0.52      0.43      3148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 2.0\n",
      "===== Accuracy Train: 0.646\n",
      "===== Accuracy Test: 0.651\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62      1014\n",
      "           1       0.86      0.67      0.75      1137\n",
      "           2       0.51      0.68      0.58       997\n",
      "\n",
      "    accuracy                           0.65      3148\n",
      "   macro avg       0.67      0.65      0.65      3148\n",
      "weighted avg       0.68      0.65      0.66      3148\n",
      "\n",
      "For max depth: 3.0\n",
      "===== Accuracy Train: 0.686\n",
      "===== Accuracy Test: 0.689\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65      1014\n",
      "           1       0.81      0.77      0.79      1137\n",
      "           2       0.55      0.72      0.63       997\n",
      "\n",
      "    accuracy                           0.69      3148\n",
      "   macro avg       0.70      0.69      0.69      3148\n",
      "weighted avg       0.71      0.69      0.69      3148\n",
      "\n",
      "For max depth: 4.0\n",
      "===== Accuracy Train: 0.728\n",
      "===== Accuracy Test: 0.709\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71      1014\n",
      "           1       0.84      0.77      0.80      1137\n",
      "           2       0.59      0.60      0.60       997\n",
      "\n",
      "    accuracy                           0.71      3148\n",
      "   macro avg       0.71      0.71      0.71      3148\n",
      "weighted avg       0.71      0.71      0.71      3148\n",
      "\n",
      "For max depth: 5.0\n",
      "===== Accuracy Train: 0.769\n",
      "===== Accuracy Test: 0.735\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1014\n",
      "           1       0.84      0.79      0.82      1137\n",
      "           2       0.62      0.67      0.65       997\n",
      "\n",
      "    accuracy                           0.74      3148\n",
      "   macro avg       0.74      0.73      0.73      3148\n",
      "weighted avg       0.74      0.74      0.74      3148\n",
      "\n",
      "For max depth: 6.0\n",
      "===== Accuracy Train: 0.795\n",
      "===== Accuracy Test: 0.760\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1014\n",
      "           1       0.88      0.80      0.84      1137\n",
      "           2       0.64      0.75      0.69       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.77      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.76      3148\n",
      "\n",
      "For max depth: 7.0\n",
      "===== Accuracy Train: 0.830\n",
      "===== Accuracy Test: 0.771\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78      1014\n",
      "           1       0.87      0.82      0.85      1137\n",
      "           2       0.70      0.66      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max depth: 8.0\n",
      "===== Accuracy Train: 0.869\n",
      "===== Accuracy Test: 0.778\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1014\n",
      "           1       0.86      0.85      0.86      1137\n",
      "           2       0.69      0.69      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max depth: 9.0\n",
      "===== Accuracy Train: 0.903\n",
      "===== Accuracy Test: 0.780\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78      1014\n",
      "           1       0.87      0.84      0.86      1137\n",
      "           2       0.72      0.66      0.69       997\n",
      "\n",
      "    accuracy                           0.78      3148\n",
      "   macro avg       0.78      0.78      0.78      3148\n",
      "weighted avg       0.78      0.78      0.78      3148\n",
      "\n",
      "For max depth: 10.0\n",
      "===== Accuracy Train: 0.936\n",
      "===== Accuracy Test: 0.774\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      1014\n",
      "           1       0.86      0.84      0.85      1137\n",
      "           2       0.70      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.77      0.77      0.77      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max depth: 11.0\n",
      "===== Accuracy Train: 0.958\n",
      "===== Accuracy Test: 0.768\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.69      0.66      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max depth: 12.0\n",
      "===== Accuracy Train: 0.974\n",
      "===== Accuracy Test: 0.763\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.68      0.65      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 13.0\n",
      "===== Accuracy Train: 0.982\n",
      "===== Accuracy Test: 0.765\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1014\n",
      "           1       0.85      0.82      0.83      1137\n",
      "           2       0.69      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.76      0.76      3148\n",
      "\n",
      "For max depth: 14.0\n",
      "===== Accuracy Train: 0.987\n",
      "===== Accuracy Test: 0.768\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.68      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max depth: 15.0\n",
      "===== Accuracy Train: 0.990\n",
      "===== Accuracy Test: 0.765\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.69      0.67      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.77      0.76      3148\n",
      "\n",
      "For max depth: 16.0\n",
      "===== Accuracy Train: 0.993\n",
      "===== Accuracy Test: 0.764\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.68      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 17.0\n",
      "===== Accuracy Train: 0.994\n",
      "===== Accuracy Test: 0.767\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      1014\n",
      "           1       0.85      0.82      0.84      1137\n",
      "           2       0.68      0.68      0.68       997\n",
      "\n",
      "    accuracy                           0.77      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.77      0.77      0.77      3148\n",
      "\n",
      "For max depth: 18.0\n",
      "===== Accuracy Train: 0.995\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.67      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 19.0\n",
      "===== Accuracy Train: 0.996\n",
      "===== Accuracy Test: 0.759\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.68      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max depth: 20.0\n",
      "===== Accuracy Train: 0.997\n",
      "===== Accuracy Test: 0.753\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.67      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.75      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.75      0.75      0.75      3148\n",
      "\n",
      "For max depth: 21.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.761\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.68      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 22.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.758\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1014\n",
      "           1       0.84      0.83      0.83      1137\n",
      "           2       0.67      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 23.0\n",
      "===== Accuracy Train: 0.998\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.67      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 24.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.66      0.65      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 25.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.763\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.68      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.76      0.76      0.76      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 26.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 27.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.67      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 28.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 29.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.757\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1014\n",
      "           1       0.85      0.83      0.84      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 30.0\n",
      "===== Accuracy Train: 0.999\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      1014\n",
      "           1       0.84      0.83      0.84      1137\n",
      "           2       0.67      0.66      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 31.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.755\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1014\n",
      "           1       0.83      0.82      0.83      1137\n",
      "           2       0.66      0.66      0.66       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n",
      "For max depth: 32.0\n",
      "===== Accuracy Train: 1.000\n",
      "===== Accuracy Test: 0.756\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1014\n",
      "           1       0.84      0.82      0.83      1137\n",
      "           2       0.67      0.67      0.67       997\n",
      "\n",
      "    accuracy                           0.76      3148\n",
      "   macro avg       0.75      0.75      0.75      3148\n",
      "weighted avg       0.76      0.76      0.76      3148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "\n",
    "for depth in max_depths:\n",
    "    # Initialize Classifier with max_depth\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    # Fit Classifier \n",
    "    dt.fit(X_transformed, y_train)\n",
    "    # Train Classifier Prediction\n",
    "    train_pred = dt.predict(X_transformed)\n",
    "    # Test Classifier Prediction\n",
    "    y_pred = dt.predict(X_test_transformed)\n",
    "    \n",
    "    print(\"For max depth:\", depth)\n",
    "    print('===== Accuracy Train: %.3f' % accuracy_score(y_train, train_pred))\n",
    "    print('===== Accuracy Test: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#   Best Performing Depth 77.7%, max-depth=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params\n",
      "=====Accuracy Train PCA: 0.954960679958694\n",
      "=====Accuracy Test PCA: 0.775412960609911\n"
     ]
    }
   ],
   "source": [
    "best_max_depth = 11\n",
    "best_max_feature = 134\n",
    "\n",
    "# Initialize Decision Trees model for PCA instance with best params\n",
    "dt = DecisionTreeClassifier(max_features=best_max_feature, max_depth=best_max_depth)\n",
    "\n",
    "# Use training data to fit Decision Trees model with transformed X_train\n",
    "dt.fit(X_transformed, y_train.values.ravel())\n",
    "\n",
    "# make prediction on entire train data\n",
    "train_pred_pca = dt.predict(X_transformed)\n",
    "y_pred_pca = dt.predict(X_test_transformed)\n",
    "\n",
    "print(\"Best Params\")\n",
    "print(\"=====Accuracy Train PCA:\", accuracy_score(y_train, train_pred_pca))\n",
    "print(\"=====Accuracy Test PCA:\", accuracy_score(y_test, y_pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Decision Trees Classifier performs fairly well for detecting incorrect wear of mask (with ~89-92% accuracy) or no mask wear (with ~80-84% accuracy) categories. However, across the different hyperparameter tuning models, it appears that it underperforms for classifying correct wear of face mask with an accuracy of ~70-76%. In fact, the UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. warning that is thrown several times in the hyperparameter tuning process for this classifier suggests that there are a few cases where label 2, or the correct face mask wear, is never predicted. In other words, given the true target values of the test set, y_test, the prediction class for correctly worn face masks is never predicted in y_pred for the model.\n",
    "\n",
    "A learning goal that arises in the hyperparameter tuning phase for this model is that 100% training accuracy (a.k.a. extreme overfitting) does not improve the model's ability to classify new information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources Referenced for constructing this model:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
